{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNdTtOwvrCzD",
        "outputId": "d8837aba-5d16-4281-9f03-b9fdd5922194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n",
            "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Using cached scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Using cached scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.6.0\n",
            "Found existing installation: scikit-learn 1.6.0\n",
            "Uninstalling scikit-learn-1.6.0:\n",
            "  Successfully uninstalled scikit-learn-1.6.0\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Using cached scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Using cached scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "scikeras 0.13.0 requires scikit-learn>=1.4.2, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.2.2\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1109.7499 - mae: 1109.7499\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1010.5381 - mae: 1010.5381\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 889.6170 - mae: 889.6170\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 748.6412 - mae: 748.6412\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 667.7192 - mae: 667.7192\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 655.5025 - mae: 655.5025\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7703 - mae: 641.7703\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3555 - mae: 640.3555\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2018 - mae: 643.2018\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.6123 - mae: 643.6123\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4024 - mae: 638.4024\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0723 - mae: 642.0723\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.3679 - mae: 637.3679\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3051 - mae: 641.3051\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0888 - mae: 643.0888\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.1525 - mae: 648.1525\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.3730 - mae: 640.3730\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.0292 - mae: 646.0292\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.0281 - mae: 636.0281\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6690 - mae: 643.6690\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1097.0060 - mae: 1097.0060\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1033.9174 - mae: 1033.9174\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 924.1394 - mae: 924.1394\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 799.1991 - mae: 799.1991\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 699.2893 - mae: 699.2893\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 658.8676 - mae: 658.8676\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 652.6066 - mae: 652.6066\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.4783 - mae: 650.4783\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1746 - mae: 644.1746\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.9575 - mae: 645.9575\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.8923 - mae: 648.8923\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.5216 - mae: 651.5216\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.4191 - mae: 647.4191\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7710 - mae: 644.7710\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3072 - mae: 643.3072\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.2552 - mae: 647.2552\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.1286 - mae: 645.1286\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9498 - mae: 643.9498\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1954 - mae: 645.1954\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 652.4374 - mae: 652.4374\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1099.2832 - mae: 1099.2832\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 899.4470 - mae: 899.4470\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 692.2361 - mae: 692.2361\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.6043 - mae: 650.6043\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.5928 - mae: 650.5928\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8663 - mae: 644.8663\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.1373 - mae: 646.1373\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.8558 - mae: 648.8558\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4805 - mae: 648.4805\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7328 - mae: 641.7328\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.8710 - mae: 648.8710\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.3624 - mae: 644.3624\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6956 - mae: 639.6956\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.4216 - mae: 637.4216\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.0374 - mae: 647.0374\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9943 - mae: 642.9943\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.2903 - mae: 649.2903\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0697 - mae: 638.0697\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6012 - mae: 639.6012\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2522 - mae: 640.2522\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1079.2188 - mae: 1079.2188\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 813.0816 - mae: 813.0816\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 656.6825 - mae: 656.6825\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 652.9186 - mae: 652.9186\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6552 - mae: 642.6552\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3406 - mae: 634.3406\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4129 - mae: 642.4129\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3218 - mae: 647.3218\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.5991 - mae: 643.5991\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.9035 - mae: 639.9035\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4836 - mae: 641.4836\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.2948 - mae: 635.2948\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4032 - mae: 641.4032\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.6289 - mae: 635.6289\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 653.6380 - mae: 653.6380\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5734 - mae: 638.5734\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3663 - mae: 638.3663\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 633.5435 - mae: 633.5435\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1713 - mae: 641.1713\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.2870 - mae: 637.2870\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1083.4816 - mae: 1083.4816\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 838.9154 - mae: 838.9154\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 657.9409 - mae: 657.9409\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.7020 - mae: 646.7020\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3904 - mae: 647.3904\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 652.9006 - mae: 652.9006\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2167 - mae: 643.2167\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.5106 - mae: 636.5106\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1465 - mae: 645.1465\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 652.0688 - mae: 652.0688\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.7028 - mae: 641.7028\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 647.2541 - mae: 647.2541\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6824 - mae: 640.6824\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3950 - mae: 641.3950\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.2117 - mae: 646.2117\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.3566 - mae: 644.3566\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2388 - mae: 644.2388\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7538 - mae: 643.7538\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2052 - mae: 639.2052\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3608 - mae: 643.3608\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1082.9116 - mae: 1082.9116\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 805.8699 - mae: 805.8699\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 659.5497 - mae: 659.5497\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 658.3959 - mae: 658.3959\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.6969 - mae: 638.6969\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0712 - mae: 643.0712\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8253 - mae: 638.8253\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7895 - mae: 644.7895\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0366 - mae: 643.0366\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5986 - mae: 640.5986\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.4180 - mae: 636.4180\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9932 - mae: 643.9932\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0203 - mae: 641.0203\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6692 - mae: 648.6692\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3776 - mae: 647.3776\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5242 - mae: 642.5242\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2430 - mae: 641.2430\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2133 - mae: 643.2133\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.1251 - mae: 638.1251\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.7723 - mae: 646.7723\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1068.3080 - mae: 1068.3080\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 675.6863 - mae: 675.6863\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9553 - mae: 642.9553\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 657.6690 - mae: 657.6690\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6889 - mae: 640.6889\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.7006 - mae: 636.7006\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.2128 - mae: 642.2128\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0864 - mae: 643.0864\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5233 - mae: 644.5233\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6287 - mae: 644.6287\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8626 - mae: 643.8626\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0119 - mae: 638.0119\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8395 - mae: 639.8395\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3282 - mae: 639.3282\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.3553 - mae: 636.3553\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4425 - mae: 642.4425\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.9326 - mae: 646.9326\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9658 - mae: 643.9658\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.1745 - mae: 647.1745\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7160 - mae: 643.7160\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1059.9921 - mae: 1059.9921\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 694.6757 - mae: 694.6757\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 651.7818 - mae: 651.7818\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.3569 - mae: 652.3569\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 651.6378 - mae: 651.6378\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.1910 - mae: 647.1910\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0179 - mae: 641.0179\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.5532 - mae: 651.5532\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2896 - mae: 644.2896\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2464 - mae: 643.2464\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.3868 - mae: 637.3868\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6554 - mae: 640.6554\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2156 - mae: 641.2156\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3661 - mae: 639.3661\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9573 - mae: 646.9573\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5877 - mae: 641.5877\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0240 - mae: 644.0240\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3813 - mae: 641.3813\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.6234 - mae: 650.6234\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.9546 - mae: 639.9546\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1071.2848 - mae: 1071.2848\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 727.4511 - mae: 727.4511\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 654.3387 - mae: 654.3387\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.6874 - mae: 643.6874\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.7158 - mae: 647.7158\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1654 - mae: 644.1654\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6442 - mae: 648.6442\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.4841 - mae: 647.4841\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9000 - mae: 640.9000\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8152 - mae: 642.8152\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.4209 - mae: 648.4209\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.7607 - mae: 646.7607\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5476 - mae: 643.5476\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1424 - mae: 642.1424\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.6666 - mae: 636.6666\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7590 - mae: 641.7590\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0369 - mae: 644.0369\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5275 - mae: 640.5275\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1049 - mae: 641.1049\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6391 - mae: 639.6391\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1030.7395 - mae: 1030.7395\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.6306 - mae: 649.6306\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8472 - mae: 641.8472\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2925 - mae: 642.2925\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3427 - mae: 642.3427\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.2263 - mae: 638.2263\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5716 - mae: 642.5716\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6650 - mae: 639.6650\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9418 - mae: 639.9418\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 632.9373 - mae: 632.9373\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.6803 - mae: 637.6803\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.7997 - mae: 633.7997\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0703 - mae: 641.0703\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3384 - mae: 634.3384\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5206 - mae: 642.5206\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8751 - mae: 637.8751\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.1058 - mae: 636.1058\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0416 - mae: 639.0416\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3149 - mae: 636.3149\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4998 - mae: 640.4998\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1013.0826 - mae: 1013.0826\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4684 - mae: 648.4684\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2936 - mae: 643.2936\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2422 - mae: 639.2422\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9053 - mae: 644.9053\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0903 - mae: 642.0903\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4003 - mae: 648.4003\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.7686 - mae: 648.7686\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8899 - mae: 647.8899\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.1482 - mae: 646.1482\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.3566 - mae: 646.3566\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.2390 - mae: 645.2390\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9440 - mae: 640.9440\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.0185 - mae: 646.0185\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6496 - mae: 643.6496\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.9200 - mae: 638.9200\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.4361 - mae: 646.4361\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5715 - mae: 644.5715\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2450 - mae: 642.2450\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.1742 - mae: 649.1742\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1023.3951 - mae: 1023.3951\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4001 - mae: 647.4001\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4854 - mae: 640.4854\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.8632 - mae: 646.8632\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7042 - mae: 644.7042\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4844 - mae: 641.4844\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5731 - mae: 644.5731\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.8748 - mae: 634.8748\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5374 - mae: 642.5374\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5937 - mae: 642.5937\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3679 - mae: 641.3679\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.0925 - mae: 647.0925\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4263 - mae: 643.4263\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8849 - mae: 644.8849\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3858 - mae: 641.3858\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9396 - mae: 643.9396\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5308 - mae: 641.5308\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0082 - mae: 644.0082\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9490 - mae: 644.9490\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6442 - mae: 636.6442\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1010.3790 - mae: 1010.3790\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2396 - mae: 639.2396\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4037 - mae: 642.4037\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.7707 - mae: 638.7707\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.4766 - mae: 633.4766\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1418 - mae: 641.1418\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6855 - mae: 637.6855\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.1178 - mae: 633.1178\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.6268 - mae: 634.6268\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4335 - mae: 640.4335\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3635 - mae: 643.3635\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7010 - mae: 644.7010\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0514 - mae: 640.0514\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0811 - mae: 639.0811\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.9376 - mae: 640.9376\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.5623 - mae: 648.5623\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.0563 - mae: 640.0563\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8495 - mae: 644.8495\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.9072 - mae: 641.9072\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.1392 - mae: 637.1392\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 985.3040 - mae: 985.3040\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.7085 - mae: 647.7085\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7268 - mae: 641.7268\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.9104 - mae: 642.9104\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6486 - mae: 642.6486\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0651 - mae: 643.0651\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1218 - mae: 644.1218\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.3400 - mae: 646.3400\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3549 - mae: 634.3549\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5077 - mae: 647.5077\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9581 - mae: 644.9581\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 640.0027 - mae: 640.0027\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 644.0041 - mae: 644.0041\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 643.6677 - mae: 643.6677\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4984 - mae: 643.4984\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.4763 - mae: 646.4763\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1933 - mae: 642.1933\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.1890 - mae: 646.1890\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.1062 - mae: 648.1062\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.3018 - mae: 650.3018\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 996.7441 - mae: 996.7441\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.5963 - mae: 645.5963\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6502 - mae: 643.6502\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.3064 - mae: 641.3064\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1842 - mae: 645.1842\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0925 - mae: 640.0925\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7082 - mae: 644.7082\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1318 - mae: 641.1318\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.4842 - mae: 646.4842\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8331 - mae: 638.8331\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.7325 - mae: 650.7325\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5805 - mae: 640.5805\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.2365 - mae: 638.2365\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2419 - mae: 644.2419\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8232 - mae: 638.8232\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.9396 - mae: 637.9396\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.9054 - mae: 644.9054\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6883 - mae: 642.6883\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8631 - mae: 641.8631\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6041 - mae: 646.6041\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 942.1646 - mae: 942.1646\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5416 - mae: 639.5416\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8229 - mae: 644.8229\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.4166 - mae: 649.4166\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4199 - mae: 640.4199\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5836 - mae: 642.5836\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7705 - mae: 642.7705\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.7434 - mae: 634.7434\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6273 - mae: 642.6273\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 631.8908 - mae: 631.8908\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4059 - mae: 643.4059\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.6355 - mae: 638.6355\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1888 - mae: 644.1888\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1945 - mae: 639.1945\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3145 - mae: 642.3145\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3300 - mae: 634.3300\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4886 - mae: 639.4886\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9691 - mae: 640.9691\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6047 - mae: 640.6047\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1709 - mae: 640.1709\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 928.9205 - mae: 928.9205\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.1740 - mae: 647.1740\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2102 - mae: 644.2102\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.6429 - mae: 650.6429\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9650 - mae: 646.9650\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1934 - mae: 644.1934\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.3715 - mae: 639.3715\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.6260 - mae: 647.6260\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6690 - mae: 640.6690\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7235 - mae: 642.7235\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9239 - mae: 646.9239\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4881 - mae: 642.4881\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.3270 - mae: 640.3270\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4637 - mae: 646.4637\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6290 - mae: 644.6290\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5183 - mae: 641.5183\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7392 - mae: 642.7392\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9454 - mae: 643.9454\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.9026 - mae: 644.9026\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7399 - mae: 645.7399\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 916.4904 - mae: 916.4904\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9793 - mae: 639.9793\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.1652 - mae: 645.1652\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6388 - mae: 642.6388\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.6185 - mae: 636.6185\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0804 - mae: 645.0804\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.7358 - mae: 638.7358\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.7985 - mae: 647.7985\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.5156 - mae: 645.5156\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.4841 - mae: 638.4841\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.9271 - mae: 649.9271\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6481 - mae: 644.6481\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3094 - mae: 643.3094\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1528 - mae: 642.1528\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.9551 - mae: 644.9551\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5126 - mae: 643.5126\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3732 - mae: 647.3732\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.4299 - mae: 636.4299\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3016 - mae: 643.3016\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4574 - mae: 639.4574\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 846.3034 - mae: 846.3034\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5706 - mae: 638.5706\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2643 - mae: 643.2643\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.0527 - mae: 649.0527\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3381 - mae: 638.3381\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.2654 - mae: 636.2654\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.9610 - mae: 630.9610\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.9614 - mae: 642.9614\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6286 - mae: 643.6286\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.3066 - mae: 637.3066\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9907 - mae: 636.9907\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9166 - mae: 639.9166\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.2625 - mae: 641.2625\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1804 - mae: 640.1804\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7630 - mae: 642.7630\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0271 - mae: 639.0271\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4316 - mae: 638.4316\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6319 - mae: 644.6319\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2189 - mae: 642.2189\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7549 - mae: 637.7549\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 858.3358 - mae: 858.3358\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1376 - mae: 647.1376\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3843 - mae: 645.3843\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9438 - mae: 642.9438\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0052 - mae: 641.0052\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7772 - mae: 644.7772\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.6896 - mae: 642.6896\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5567 - mae: 639.5567\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5789 - mae: 641.5789\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.0301 - mae: 646.0301\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2065 - mae: 644.2065\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.7791 - mae: 635.7791\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.8768 - mae: 640.8768\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.3912 - mae: 641.3912\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.2603 - mae: 648.2603\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3085 - mae: 638.3085\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0201 - mae: 638.0201\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5765 - mae: 644.5765\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 655.1337 - mae: 655.1337\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.3612 - mae: 650.3612\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 859.6421 - mae: 859.6421\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8920 - mae: 637.8920\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0339 - mae: 643.0339\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3257 - mae: 645.3257\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5500 - mae: 641.5500\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6301 - mae: 646.6301\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.8773 - mae: 645.8773\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.7267 - mae: 646.7267\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.3389 - mae: 650.3389\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.2923 - mae: 647.2923\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7969 - mae: 645.7969\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8565 - mae: 637.8565\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9149 - mae: 639.9149\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.0447 - mae: 647.0447\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2714 - mae: 648.2714\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.4529 - mae: 641.4529\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8906 - mae: 644.8906\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4967 - mae: 643.4967\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4965 - mae: 644.4965\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8544 - mae: 644.8544\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 813.2070 - mae: 813.2070\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0961 - mae: 642.0961\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8481 - mae: 640.8481\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.6311 - mae: 647.6311\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3766 - mae: 641.3766\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.9778 - mae: 635.9778\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1963 - mae: 641.1963\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6794 - mae: 642.6794\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4797 - mae: 636.4797\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2098 - mae: 641.2098\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.2800 - mae: 636.2800\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.1031 - mae: 637.1031\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4432 - mae: 639.4432\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6693 - mae: 642.6693\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.5632 - mae: 643.5632\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.1089 - mae: 634.1089\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.4919 - mae: 646.4919\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1610 - mae: 636.1610\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.2978 - mae: 631.2978\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.3580 - mae: 648.3580\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 817.1302 - mae: 817.1302\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6012 - mae: 641.6012\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0467 - mae: 644.0467\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9916 - mae: 642.9916\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5488 - mae: 645.5488\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3035 - mae: 639.3035\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0925 - mae: 644.0925\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2489 - mae: 643.2489\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9036 - mae: 642.9036\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.4515 - mae: 635.4515\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4613 - mae: 643.4613\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.5126 - mae: 646.5126\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.6861 - mae: 644.6861\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1651 - mae: 642.1651\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.6663 - mae: 644.6663\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6271 - mae: 638.6271\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.4932 - mae: 635.4932\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.1102 - mae: 649.1102\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.3145 - mae: 646.3145\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1690 - mae: 645.1690\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 805.9380 - mae: 805.9380\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7914 - mae: 643.7914\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5936 - mae: 643.5936\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0720 - mae: 641.0720\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.9554 - mae: 638.9554\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8639 - mae: 643.8639\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.9186 - mae: 646.9186\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.8436 - mae: 641.8436\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4072 - mae: 641.4072\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9987 - mae: 643.9987\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3057 - mae: 645.3057\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1349 - mae: 641.1349\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8960 - mae: 638.8960\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.4990 - mae: 635.4990\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.9680 - mae: 644.9680\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9574 - mae: 638.9574\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.8626 - mae: 645.8626\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.3257 - mae: 650.3257\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8925 - mae: 640.8925\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0313 - mae: 641.0313\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 879.1751 - mae: 879.1751\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0884 - mae: 637.0884\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8768 - mae: 645.8768\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.0895 - mae: 640.0895\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.5236 - mae: 636.5236\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7148 - mae: 638.7148\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7532 - mae: 645.7532\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1638 - mae: 637.1638\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3459 - mae: 645.3459\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6370 - mae: 637.6370\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5480 - mae: 634.5480\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.9255 - mae: 641.9255\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3026 - mae: 641.3026\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.5757 - mae: 636.5757\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.1689 - mae: 641.1689\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.9818 - mae: 633.9818\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9023 - mae: 639.9023\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5450 - mae: 640.5450\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3860 - mae: 641.3860\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1312 - mae: 638.1312\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 916.4113 - mae: 916.4113\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 647.5552 - mae: 647.5552\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.3403 - mae: 639.3403\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.4163 - mae: 643.4163\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6032 - mae: 644.6032\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 652.0143 - mae: 652.0143\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.7383 - mae: 649.7383\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2222 - mae: 641.2222\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4787 - mae: 641.4787\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0711 - mae: 646.0711\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5185 - mae: 647.5185\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2311 - mae: 644.2311\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4262 - mae: 646.4262\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0307 - mae: 639.0307\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.3165 - mae: 646.3165\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.3698 - mae: 650.3698\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.7493 - mae: 640.7493\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6517 - mae: 645.6517\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4713 - mae: 646.4713\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.5221 - mae: 647.5221\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 931.4061 - mae: 931.4061\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 644.2964 - mae: 644.2964\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0972 - mae: 643.0972\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1671 - mae: 639.1671\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2897 - mae: 642.2897\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5591 - mae: 641.5591\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 646.7376 - mae: 646.7376\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.7301 - mae: 639.7301\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5819 - mae: 639.5819\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.8618 - mae: 645.8618\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9354 - mae: 636.9354\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2552 - mae: 638.2552\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.6293 - mae: 645.6293\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 646.4542 - mae: 646.4542\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7072 - mae: 642.7072\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4694 - mae: 637.4694\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.6249 - mae: 644.6249\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3651 - mae: 642.3651\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8169 - mae: 644.8169\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.3262 - mae: 645.3262\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 862.2578 - mae: 862.2578\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2824 - mae: 643.2824\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5911 - mae: 638.5911\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5552 - mae: 635.5552\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7553 - mae: 642.7553\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.7225 - mae: 635.7225\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2316 - mae: 647.2316\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1692 - mae: 641.1692\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7031 - mae: 640.7031\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6934 - mae: 639.6934\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7236 - mae: 638.7236\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.0059 - mae: 649.0059\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1614 - mae: 643.1614\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5779 - mae: 635.5779\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6157 - mae: 640.6157\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6310 - mae: 637.6310\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2889 - mae: 634.2889\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3349 - mae: 636.3349\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9349 - mae: 639.9349\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3140 - mae: 637.3140\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 843.1613 - mae: 843.1613\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9659 - mae: 643.9659\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6740 - mae: 644.6740\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.9045 - mae: 646.9045\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4925 - mae: 643.4925\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1751 - mae: 644.1751\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.6976 - mae: 646.6976\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0800 - mae: 645.0800\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3497 - mae: 641.3497\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.4985 - mae: 650.4985\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2457 - mae: 638.2457\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.2592 - mae: 648.2592\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.9203 - mae: 641.9203\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 651.3764 - mae: 651.3764\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3762 - mae: 644.3762\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8698 - mae: 640.8698\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2021 - mae: 639.2021\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5994 - mae: 642.5994\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2883 - mae: 641.2883\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7456 - mae: 646.7456\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 839.6686 - mae: 839.6686\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5808 - mae: 647.5808\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1813 - mae: 642.1813\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7815 - mae: 648.7815\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6437 - mae: 640.6437\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4855 - mae: 643.4855\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6893 - mae: 645.6893\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5160 - mae: 643.5160\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8344 - mae: 647.8344\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.5607 - mae: 646.5607\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4091 - mae: 644.4091\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4372 - mae: 641.4372\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.3541 - mae: 644.3541\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3228 - mae: 645.3228\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.3441 - mae: 649.3441\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.0889 - mae: 646.0889\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4758 - mae: 646.4758\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.3720 - mae: 641.3720\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3890 - mae: 638.3890\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0101 - mae: 642.0101\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 774.7193 - mae: 774.7193\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1058 - mae: 640.1058\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0812 - mae: 637.0812\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3255 - mae: 639.3255\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4686 - mae: 645.4686\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.1302 - mae: 638.1302\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3958 - mae: 638.3958\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5173 - mae: 644.5173\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.8107 - mae: 637.8107\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1853 - mae: 642.1853\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.8669 - mae: 640.8669\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8419 - mae: 637.8419\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3801 - mae: 640.3801\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1074 - mae: 642.1074\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3047 - mae: 640.3047\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5948 - mae: 635.5948\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.4777 - mae: 630.4777\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.7896 - mae: 640.7896\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3182 - mae: 635.3182\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.0247 - mae: 641.0247\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 807.0338 - mae: 807.0338\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3452 - mae: 639.3452\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.5256 - mae: 650.5256\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.2545 - mae: 640.2545\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.1418 - mae: 649.1418\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 653.9935 - mae: 653.9935\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.2682 - mae: 648.2682\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1736 - mae: 640.1736\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.9929 - mae: 647.9929\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.3945 - mae: 649.3945\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.5837 - mae: 648.5837\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4058 - mae: 642.4058\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7087 - mae: 643.7087\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.8695 - mae: 640.8695\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8013 - mae: 645.8013\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8659 - mae: 638.8659\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.4670 - mae: 639.4670\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1951 - mae: 640.1951\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0518 - mae: 647.0518\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.1093 - mae: 640.1093\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 789.0687 - mae: 789.0687\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3597 - mae: 639.3597\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5491 - mae: 641.5491\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 639.9913 - mae: 639.9913\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0026 - mae: 640.0026\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1763 - mae: 641.1763\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0257 - mae: 646.0257\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.8235 - mae: 646.8235\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7480 - mae: 642.7480\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1251 - mae: 642.1251\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.1111 - mae: 642.1111\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1749 - mae: 643.1749\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1274 - mae: 643.1274\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1906 - mae: 643.1906\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.8538 - mae: 641.8538\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1489 - mae: 644.1489\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6193 - mae: 645.6193\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.6863 - mae: 645.6863\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0100 - mae: 637.0100\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0894 - mae: 644.0894\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 748.7211 - mae: 748.7211\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0443 - mae: 637.0443\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.0046 - mae: 641.0046\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3719 - mae: 640.3719\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3853 - mae: 644.3853\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8271 - mae: 637.8271\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5561 - mae: 644.5561\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7242 - mae: 642.7242\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9571 - mae: 638.9571\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6867 - mae: 639.6867\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9297 - mae: 635.9297\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6285 - mae: 640.6285\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3418 - mae: 643.3418\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0151 - mae: 643.0151\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 637.9347 - mae: 637.9347\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 644.1899 - mae: 644.1899\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1555 - mae: 642.1555\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5190 - mae: 635.5190\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3005 - mae: 636.3005\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0640 - mae: 638.0640\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 757.1454 - mae: 757.1454\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3470 - mae: 645.3470\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2792 - mae: 646.2792\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7500 - mae: 641.7500\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.5134 - mae: 645.5134\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.3411 - mae: 636.3411\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 645.5028 - mae: 645.5028\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4451 - mae: 644.4451\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5575 - mae: 641.5575\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0021 - mae: 644.0021\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.2745 - mae: 648.2745\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.0374 - mae: 646.0374\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7769 - mae: 648.7769\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4738 - mae: 642.4738\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2221 - mae: 641.2221\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4117 - mae: 642.4117\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9248 - mae: 639.9248\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1249 - mae: 644.1249\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.4199 - mae: 646.4199\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.2609 - mae: 646.2609\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 758.9266 - mae: 758.9266\n",
            "Epoch 2/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2018 - mae: 639.2018\n",
            "Epoch 3/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.4404 - mae: 641.4404\n",
            "Epoch 4/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.8743 - mae: 644.8743\n",
            "Epoch 5/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0598 - mae: 645.0598\n",
            "Epoch 6/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2711 - mae: 636.2711\n",
            "Epoch 7/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8469 - mae: 638.8469\n",
            "Epoch 8/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3615 - mae: 639.3615\n",
            "Epoch 9/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4856 - mae: 643.4856\n",
            "Epoch 10/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 644.9376 - mae: 644.9376\n",
            "Epoch 11/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.5402 - mae: 642.5402\n",
            "Epoch 12/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7513 - mae: 645.7513\n",
            "Epoch 13/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1741 - mae: 636.1741\n",
            "Epoch 14/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3928 - mae: 643.3928\n",
            "Epoch 15/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.7609 - mae: 639.7609\n",
            "Epoch 16/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.4777 - mae: 647.4777\n",
            "Epoch 17/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0395 - mae: 642.0395\n",
            "Epoch 18/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3727 - mae: 637.3727\n",
            "Epoch 19/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1408 - mae: 644.1408\n",
            "Epoch 20/20\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7619 - mae: 646.7619\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1094.6527 - mae: 1094.6527\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 943.9405 - mae: 943.9405\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 734.1585 - mae: 734.1585\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 655.4529 - mae: 655.4529\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4926 - mae: 643.4926\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6107 - mae: 642.6107\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4456 - mae: 644.4456\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2876 - mae: 642.2876\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.0567 - mae: 649.0567\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8179 - mae: 640.8179\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3111 - mae: 646.3111\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.5166 - mae: 650.5166\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4919 - mae: 644.4919\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6258 - mae: 643.6258\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.4441 - mae: 637.4441\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5233 - mae: 641.5233\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5687 - mae: 638.5687\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0461 - mae: 643.0461\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0035 - mae: 632.0035\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 632.8716 - mae: 632.8716\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7064 - mae: 643.7064\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.9363 - mae: 633.9363\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7438 - mae: 640.7438\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4652 - mae: 641.4652\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.1470 - mae: 637.1470\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.5186 - mae: 635.5186\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6692 - mae: 642.6692\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1147 - mae: 639.1147\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.2609 - mae: 640.2609\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.9563 - mae: 640.9563\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.6248 - mae: 643.6248\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.7761 - mae: 638.7761\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6046 - mae: 641.6046\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8426 - mae: 637.8426\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3753 - mae: 642.3753\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8611 - mae: 638.8611\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0369 - mae: 640.0369\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.4557 - mae: 639.4557\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0880 - mae: 641.0880\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8751 - mae: 642.8751\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9590 - mae: 642.9590\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0693 - mae: 638.0693\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7583 - mae: 641.7583\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.5675 - mae: 637.5675\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.3436 - mae: 637.3436\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9703 - mae: 640.9703\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.3506 - mae: 636.3506\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.9409 - mae: 647.9409\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4977 - mae: 639.4977\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7060 - mae: 641.7060\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1094.3824 - mae: 1094.3824\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 940.7947 - mae: 940.7947\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 732.6392 - mae: 732.6392\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 653.7717 - mae: 653.7717\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0776 - mae: 645.0776\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.9314 - mae: 645.9314\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6163 - mae: 645.6163\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5941 - mae: 644.5941\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2686 - mae: 643.2686\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1616 - mae: 642.1616\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.7709 - mae: 648.7709\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.5197 - mae: 649.5197\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4467 - mae: 648.4467\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.8040 - mae: 649.8040\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.3486 - mae: 642.3486\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.6578 - mae: 646.6578\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8568 - mae: 647.8568\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8152 - mae: 641.8152\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4406 - mae: 641.4406\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9040 - mae: 643.9040\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0253 - mae: 645.0253\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9374 - mae: 640.9374\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4238 - mae: 638.4238\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8265 - mae: 638.8265\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.1747 - mae: 642.1747\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2214 - mae: 641.2214\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9055 - mae: 646.9055\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3156 - mae: 648.3156\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 656.9950 - mae: 656.9950\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.8011 - mae: 646.8011\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9666 - mae: 643.9666\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3943 - mae: 648.3943\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1816 - mae: 640.1816\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0577 - mae: 644.0577\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.1227 - mae: 643.1227\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2073 - mae: 644.2073\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.2776 - mae: 647.2776\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.6295 - mae: 638.6295\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4242 - mae: 644.4242\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6157 - mae: 648.6157\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3829 - mae: 638.3829\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.5268 - mae: 646.5268\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5065 - mae: 639.5065\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8785 - mae: 645.8785\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.3734 - mae: 644.3734\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.0009 - mae: 646.0009\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9838 - mae: 642.9838\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3028 - mae: 641.3028\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6157 - mae: 644.6157\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.6566 - mae: 635.6566\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1095.6898 - mae: 1095.6898\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 951.7720 - mae: 951.7720\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 745.9905 - mae: 745.9905\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 653.7065 - mae: 653.7065\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3403 - mae: 645.3403\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.0137 - mae: 649.0137\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.8365 - mae: 648.8365\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5909 - mae: 641.5909\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4422 - mae: 648.4422\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7394 - mae: 643.7394\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5129 - mae: 644.5129\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.4268 - mae: 651.4268\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.8090 - mae: 647.8090\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3698 - mae: 645.3698\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.8430 - mae: 650.8430\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8220 - mae: 641.8220\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3998 - mae: 641.3998\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6456 - mae: 642.6456\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7106 - mae: 637.7106\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8523 - mae: 642.8523\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0421 - mae: 643.0421\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.3497 - mae: 635.3497\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2559 - mae: 639.2559\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9984 - mae: 642.9984\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.2614 - mae: 638.2614\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4100 - mae: 639.4100\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9949 - mae: 642.9949\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3188 - mae: 643.3188\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.2207 - mae: 651.2207\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.5844 - mae: 651.5844\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.6879 - mae: 634.6879\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.1772 - mae: 644.1772\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9814 - mae: 643.9814\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.6254 - mae: 637.6254\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.6133 - mae: 637.6133\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5573 - mae: 643.5573\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.7640 - mae: 647.7640\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.0759 - mae: 646.0759\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0725 - mae: 640.0725\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2218 - mae: 645.2218\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4122 - mae: 640.4122\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9400 - mae: 643.9400\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.9807 - mae: 641.9807\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.1027 - mae: 637.1027\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1317 - mae: 642.1317\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1672 - mae: 643.1672\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.5648 - mae: 645.5648\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.2874 - mae: 638.2874\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3963 - mae: 636.3963\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.2720 - mae: 645.2720\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1086.1699 - mae: 1086.1699\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 833.9460 - mae: 833.9460\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 653.7874 - mae: 653.7874\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.6046 - mae: 647.6046\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5605 - mae: 647.5605\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2693 - mae: 643.2693\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2558 - mae: 641.2558\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3509 - mae: 642.3509\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.1644 - mae: 645.1644\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0976 - mae: 645.0976\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4982 - mae: 644.4982\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 630.9109 - mae: 630.9109\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.9733 - mae: 637.9733\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8518 - mae: 643.8518\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1435 - mae: 642.1435\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5065 - mae: 640.5065\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1969 - mae: 640.1969\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1063 - mae: 637.1063\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.4832 - mae: 643.4832\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.5812 - mae: 636.5812\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 631.6950 - mae: 631.6950\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1828 - mae: 644.1828\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8615 - mae: 639.8615\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.3111 - mae: 635.3111\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0782 - mae: 634.0782\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8358 - mae: 636.8358\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7842 - mae: 640.7842\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.0907 - mae: 648.0907\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0834 - mae: 638.0834\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3737 - mae: 634.3737\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.2001 - mae: 637.2001\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.4008 - mae: 636.4008\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.0869 - mae: 636.0869\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8111 - mae: 637.8111\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2357 - mae: 641.2357\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9103 - mae: 642.9103\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7916 - mae: 641.7916\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3124 - mae: 638.3124\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3895 - mae: 639.3895\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8136 - mae: 641.8136\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5165 - mae: 640.5165\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.3486 - mae: 634.3486\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5755 - mae: 634.5755\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3630 - mae: 637.3630\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.3051 - mae: 642.3051\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.5731 - mae: 636.5731\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 630.2204 - mae: 630.2204\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4724 - mae: 638.4724\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.7380 - mae: 634.7380\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6516 - mae: 640.6516\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1084.9559 - mae: 1084.9559\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 817.8312 - mae: 817.8312\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 653.6050 - mae: 653.6050\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.6886 - mae: 649.6886\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1555 - mae: 642.1555\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.2593 - mae: 648.2593\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4016 - mae: 648.4016\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9606 - mae: 636.9606\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.4083 - mae: 651.4083\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2577 - mae: 640.2577\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1619 - mae: 643.1619\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.7870 - mae: 644.7870\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0055 - mae: 638.0055\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.6052 - mae: 637.6052\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 655.5295 - mae: 655.5295\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3726 - mae: 641.3726\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.9610 - mae: 650.9610\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.3188 - mae: 646.3188\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.0123 - mae: 651.0123\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.4005 - mae: 647.4005\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6804 - mae: 641.6804\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.8521 - mae: 642.8521\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0758 - mae: 642.0758\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.8495 - mae: 648.8495\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.5471 - mae: 648.5471\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6952 - mae: 639.6952\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4167 - mae: 641.4167\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.1669 - mae: 646.1669\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9784 - mae: 641.9784\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2805 - mae: 648.2805\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.2272 - mae: 641.2272\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5409 - mae: 644.5409\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.0198 - mae: 646.0198\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8676 - mae: 642.8676\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0616 - mae: 642.0616\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7794 - mae: 645.7794\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.9382 - mae: 643.9382\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0069 - mae: 641.0069\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4067 - mae: 643.4067\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9868 - mae: 643.9868\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8818 - mae: 647.8818\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8901 - mae: 647.8901\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5941 - mae: 644.5941\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7375 - mae: 640.7375\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7488 - mae: 642.7488\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.6340 - mae: 638.6340\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5015 - mae: 641.5015\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6326 - mae: 646.6326\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8658 - mae: 639.8658\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1122 - mae: 641.1122\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1081.0388 - mae: 1081.0388\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 800.5529 - mae: 800.5529\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 653.5335 - mae: 653.5335\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4754 - mae: 644.4754\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.1240 - mae: 647.1240\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.3992 - mae: 648.3992\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1209 - mae: 645.1209\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5314 - mae: 643.5314\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9263 - mae: 643.9263\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4882 - mae: 644.4882\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1844 - mae: 640.1844\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.2641 - mae: 647.2641\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4774 - mae: 648.4774\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 654.2413 - mae: 654.2413\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0184 - mae: 643.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4899 - mae: 637.4899\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.5335 - mae: 641.5335\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.9078 - mae: 641.9078\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.9997 - mae: 637.9997\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.9583 - mae: 635.9583\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4945 - mae: 640.4945\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.2045 - mae: 640.2045\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.1724 - mae: 641.1724\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4358 - mae: 644.4358\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9645 - mae: 643.9645\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3896 - mae: 640.3896\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.1348 - mae: 637.1348\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3888 - mae: 645.3888\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5444 - mae: 647.5444\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6168 - mae: 640.6168\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0609 - mae: 643.0609\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3811 - mae: 647.3811\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6611 - mae: 642.6611\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8396 - mae: 641.8396\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0366 - mae: 640.0366\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.9373 - mae: 641.9373\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4678 - mae: 639.4678\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6503 - mae: 639.6503\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0082 - mae: 643.0082\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.7549 - mae: 639.7549\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.0599 - mae: 636.0599\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1804 - mae: 645.1804\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8683 - mae: 642.8683\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9690 - mae: 640.9690\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9965 - mae: 641.9965\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.7173 - mae: 643.7173\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.2833 - mae: 651.2833\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0984 - mae: 639.0984\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4186 - mae: 643.4186\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.4321 - mae: 646.4321\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1058.6366 - mae: 1058.6366\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 699.4019 - mae: 699.4019\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.5915 - mae: 651.5915\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.2964 - mae: 645.2964\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7006 - mae: 641.7006\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7471 - mae: 640.7471\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0375 - mae: 643.0375\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8862 - mae: 638.8862\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.9644 - mae: 639.9644\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.3366 - mae: 636.3366\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6227 - mae: 638.6227\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3514 - mae: 637.3514\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.0660 - mae: 647.0660\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.3484 - mae: 635.3484\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3448 - mae: 642.3448\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.6617 - mae: 647.6617\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5247 - mae: 641.5247\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2486 - mae: 644.2486\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.4013 - mae: 637.4013\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9556 - mae: 641.9556\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5887 - mae: 637.5887\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.3591 - mae: 637.3591\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3825 - mae: 647.3825\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6355 - mae: 640.6355\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3556 - mae: 638.3556\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3671 - mae: 647.3671\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.8011 - mae: 649.8011\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.6060 - mae: 634.6060\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9147 - mae: 640.9147\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9550 - mae: 639.9550\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.1287 - mae: 644.1287\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4243 - mae: 640.4243\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 631.3464 - mae: 631.3464\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.0368 - mae: 636.0368\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7134 - mae: 643.7134\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.2113 - mae: 636.2113\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0732 - mae: 644.0732\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4307 - mae: 640.4307\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6238 - mae: 638.6238\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9735 - mae: 639.9735\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.2254 - mae: 643.2254\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0611 - mae: 640.0611\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.7487 - mae: 639.7487\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.5768 - mae: 649.5768\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.8928 - mae: 640.8928\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.9693 - mae: 639.9693\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1179 - mae: 644.1179\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9271 - mae: 642.9271\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3763 - mae: 640.3763\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.0248 - mae: 635.0248\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1059.6046 - mae: 1059.6046\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 698.1303 - mae: 698.1303\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.6401 - mae: 651.6401\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4688 - mae: 641.4688\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8027 - mae: 641.8027\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5259 - mae: 641.5259\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4836 - mae: 643.4836\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7919 - mae: 643.7919\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4799 - mae: 644.4799\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.5690 - mae: 649.5690\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1790 - mae: 645.1790\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.6376 - mae: 646.6376\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6354 - mae: 640.6354\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.8378 - mae: 648.8378\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8463 - mae: 642.8463\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.4044 - mae: 646.4044\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9077 - mae: 644.9077\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6017 - mae: 646.6017\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.3854 - mae: 638.3854\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2474 - mae: 639.2474\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.7853 - mae: 643.7853\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5718 - mae: 640.5718\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.1929 - mae: 648.1929\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1721 - mae: 639.1721\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7783 - mae: 642.7783\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5140 - mae: 639.5140\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6223 - mae: 641.6223\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.3665 - mae: 650.3665\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0692 - mae: 645.0692\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.0590 - mae: 643.0590\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4853 - mae: 641.4853\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.2230 - mae: 640.2230\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.4637 - mae: 645.4637\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4150 - mae: 644.4150\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6620 - mae: 644.6620\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0479 - mae: 638.0479\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6617 - mae: 642.6617\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4828 - mae: 639.4828\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.0231 - mae: 651.0231\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8791 - mae: 638.8791\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6401 - mae: 648.6401\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3611 - mae: 648.3611\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.2900 - mae: 645.2900\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6666 - mae: 641.6666\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8632 - mae: 643.8632\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.7284 - mae: 645.7284\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.1163 - mae: 636.1163\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2330 - mae: 639.2330\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8997 - mae: 642.8997\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1008 - mae: 643.1008\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1063.7748 - mae: 1063.7748\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 729.4262 - mae: 729.4262\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1174 - mae: 642.1174\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.5095 - mae: 646.5095\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5679 - mae: 642.5679\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5311 - mae: 641.5311\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6764 - mae: 644.6764\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3700 - mae: 647.3700\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5400 - mae: 643.5400\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3745 - mae: 643.3745\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5258 - mae: 647.5258\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.2322 - mae: 639.2322\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3576 - mae: 645.3576\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.2781 - mae: 635.2781\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.4080 - mae: 646.4080\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4122 - mae: 641.4122\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1196 - mae: 640.1196\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5927 - mae: 641.5927\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1080 - mae: 648.1080\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0675 - mae: 643.0675\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.3687 - mae: 643.3687\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9550 - mae: 636.9550\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3099 - mae: 642.3099\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2324 - mae: 639.2324\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.4308 - mae: 645.4308\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0393 - mae: 642.0393\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.3066 - mae: 650.3066\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5678 - mae: 639.5678\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5529 - mae: 638.5529\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.9305 - mae: 643.9305\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.7977 - mae: 638.7977\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4553 - mae: 639.4553\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.1203 - mae: 632.1203\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7363 - mae: 641.7363\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4454 - mae: 638.4454\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2361 - mae: 644.2361\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4929 - mae: 640.4929\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4647 - mae: 644.4647\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.3779 - mae: 640.3779\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.6906 - mae: 640.6906\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.2833 - mae: 636.2833\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.3386 - mae: 651.3386\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.2228 - mae: 635.2228\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6211 - mae: 643.6211\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.8138 - mae: 641.8138\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9648 - mae: 643.9648\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.9589 - mae: 638.9589\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.0281 - mae: 637.0281\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8282 - mae: 639.8282\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.8512 - mae: 646.8512\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1017.7708 - mae: 1017.7708\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 653.4000 - mae: 653.4000\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2615 - mae: 638.2615\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.8842 - mae: 642.8842\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8552 - mae: 641.8552\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 644.4296 - mae: 644.4296\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.0081 - mae: 636.0081\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.4590 - mae: 638.4590\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1801 - mae: 646.1801\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0935 - mae: 645.0935\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.0928 - mae: 640.0928\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0026 - mae: 642.0026\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 638.5161 - mae: 638.5161\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9183 - mae: 636.9183\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.6328 - mae: 635.6328\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5415 - mae: 641.5415\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.5918 - mae: 633.5918\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8531 - mae: 635.8531\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4036 - mae: 636.4036\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.5385 - mae: 637.5385\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9547 - mae: 640.9547\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2110 - mae: 643.2110\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.1857 - mae: 634.1857\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 629.3616 - mae: 629.3616\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4164 - mae: 644.4164\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.1499 - mae: 639.1499\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0737 - mae: 640.0737\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.9418 - mae: 638.9418\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3334 - mae: 647.3334\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6282 - mae: 642.6282\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1653 - mae: 635.1653\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9296 - mae: 636.9296\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.1655 - mae: 636.1655\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.8644 - mae: 636.8644\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.8660 - mae: 645.8660\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.4865 - mae: 635.4865\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0292 - mae: 638.0292\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6891 - mae: 639.6891\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5186 - mae: 640.5186\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.3450 - mae: 637.3450\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.4528 - mae: 636.4528\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3311 - mae: 643.3311\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.1631 - mae: 636.1631\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.0027 - mae: 641.0027\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4374 - mae: 643.4374\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1495 - mae: 637.1495\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8237 - mae: 644.8237\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3771 - mae: 643.3771\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.7821 - mae: 635.7821\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4390 - mae: 645.4390\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1021.3275 - mae: 1021.3275\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 656.4556 - mae: 656.4556\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.4629 - mae: 646.4629\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.3293 - mae: 644.3293\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.8263 - mae: 645.8263\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8109 - mae: 644.8109\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7003 - mae: 642.7003\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4414 - mae: 644.4414\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0040 - mae: 642.0040\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.4081 - mae: 639.4081\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.1755 - mae: 641.1755\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.6467 - mae: 643.6467\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0496 - mae: 641.0496\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4375 - mae: 640.4375\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6647 - mae: 643.6647\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.6503 - mae: 634.6503\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9957 - mae: 643.9957\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.8289 - mae: 641.8289\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1540 - mae: 643.1540\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6537 - mae: 641.6537\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7811 - mae: 644.7811\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5226 - mae: 643.5226\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0204 - mae: 642.0204\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.6716 - mae: 640.6716\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2625 - mae: 641.2625\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4874 - mae: 645.4874\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7681 - mae: 643.7681\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5364 - mae: 639.5364\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3877 - mae: 642.3877\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.1483 - mae: 644.1483\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4586 - mae: 639.4586\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8638 - mae: 644.8638\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.8632 - mae: 643.8632\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4763 - mae: 642.4763\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7556 - mae: 638.7556\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4136 - mae: 641.4136\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4679 - mae: 645.4679\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 648.5811 - mae: 648.5811\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5403 - mae: 643.5403\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.4801 - mae: 649.4801\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.3345 - mae: 643.3345\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.7990 - mae: 643.7990\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9445 - mae: 642.9445\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0262 - mae: 640.0262\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2694 - mae: 636.2694\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.0497 - mae: 639.0497\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.4315 - mae: 651.4315\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0365 - mae: 643.0365\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2459 - mae: 641.2459\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9873 - mae: 646.9873\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1011.0311 - mae: 1011.0311\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 651.8661 - mae: 651.8661\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.0891 - mae: 646.0891\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7339 - mae: 640.7339\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.0726 - mae: 650.0726\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.1320 - mae: 647.1320\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7721 - mae: 641.7721\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5333 - mae: 643.5333\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.4501 - mae: 635.4501\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8104 - mae: 643.8104\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4697 - mae: 638.4697\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9853 - mae: 636.9853\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.7722 - mae: 644.7722\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5617 - mae: 641.5617\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.7641 - mae: 633.7641\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4520 - mae: 638.4520\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.1326 - mae: 638.1326\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4296 - mae: 640.4296\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1047 - mae: 640.1047\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.8271 - mae: 635.8271\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4960 - mae: 641.4960\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.0813 - mae: 646.0813\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9957 - mae: 646.9957\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.0352 - mae: 643.0352\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2955 - mae: 639.2955\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.3362 - mae: 646.3362\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7955 - mae: 635.7955\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.2094 - mae: 641.2094\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0464 - mae: 640.0464\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0672 - mae: 643.0672\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6471 - mae: 643.6471\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.9963 - mae: 638.9963\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8524 - mae: 642.8524\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.0563 - mae: 637.0563\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4476 - mae: 644.4476\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7142 - mae: 639.7142\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.9792 - mae: 638.9792\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6092 - mae: 642.6092\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8502 - mae: 644.8502\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8000 - mae: 641.8000\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9329 - mae: 642.9329\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8646 - mae: 638.8646\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0663 - mae: 641.0663\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6162 - mae: 638.6162\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3671 - mae: 638.3671\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 637.9692 - mae: 637.9692\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7017 - mae: 637.7017\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 642.0376 - mae: 642.0376\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5497 - mae: 643.5497\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5114 - mae: 642.5114\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 992.2885 - mae: 992.2885\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7721 - mae: 642.7721\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.5819 - mae: 643.5819\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5031 - mae: 639.5031\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.6234 - mae: 641.6234\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9372 - mae: 634.9372\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.7833 - mae: 637.7833\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5427 - mae: 643.5427\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.1623 - mae: 640.1623\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.5396 - mae: 647.5396\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9970 - mae: 640.9970\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0589 - mae: 640.0589\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4160 - mae: 640.4160\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.5801 - mae: 641.5801\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1281 - mae: 640.1281\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3065 - mae: 647.3065\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.7563 - mae: 647.7563\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.7586 - mae: 635.7586\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3776 - mae: 645.3776\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.7680 - mae: 641.7680\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1983 - mae: 641.1983\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5264 - mae: 637.5264\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7218 - mae: 638.7218\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.6271 - mae: 643.6271\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.9572 - mae: 643.9572\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 631.4861 - mae: 631.4861\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2168 - mae: 641.2168\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.2441 - mae: 637.2441\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8693 - mae: 638.8693\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1727 - mae: 637.1727\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0936 - mae: 645.0936\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0305 - mae: 639.0305\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5303 - mae: 639.5303\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.7734 - mae: 638.7734\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.1735 - mae: 641.1735\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.3149 - mae: 638.3149\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.9257 - mae: 637.9257\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7321 - mae: 636.7321\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4291 - mae: 640.4291\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8345 - mae: 636.8345\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 635.0472 - mae: 635.0472\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0649 - mae: 632.0649\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0928 - mae: 647.0928\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2980 - mae: 639.2980\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.4834 - mae: 636.4834\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9855 - mae: 639.9855\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3311 - mae: 637.3311\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.2017 - mae: 635.2017\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4754 - mae: 646.4754\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5697 - mae: 641.5697\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 981.9528 - mae: 981.9528\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3156 - mae: 641.3156\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.7609 - mae: 642.7609\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.6459 - mae: 647.6459\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8843 - mae: 644.8843\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.1448 - mae: 644.1448\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.5461 - mae: 643.5461\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6599 - mae: 645.6599\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7349 - mae: 642.7349\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.4965 - mae: 645.4965\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.0885 - mae: 640.0885\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.0752 - mae: 650.0752\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3726 - mae: 642.3726\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4061 - mae: 641.4061\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.6304 - mae: 637.6304\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5030 - mae: 639.5030\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.3024 - mae: 650.3024\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1701 - mae: 645.1701\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.1191 - mae: 645.1191\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5942 - mae: 638.5942\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.2936 - mae: 640.2936\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8401 - mae: 643.8401\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3507 - mae: 648.3507\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3541 - mae: 647.3541\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.2926 - mae: 643.2926\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9856 - mae: 642.9856\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8214 - mae: 646.8214\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.9202 - mae: 635.9202\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.1603 - mae: 645.1603\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8494 - mae: 647.8494\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.3427 - mae: 646.3427\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.2202 - mae: 636.2202\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.5107 - mae: 643.5107\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.3848 - mae: 647.3848\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3643 - mae: 635.3643\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.6162 - mae: 640.6162\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.2979 - mae: 640.2979\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3206 - mae: 643.3206\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.4753 - mae: 647.4753\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1052 - mae: 645.1052\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0644 - mae: 638.0644\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6084 - mae: 640.6084\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1434 - mae: 643.1434\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4405 - mae: 640.4405\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 648.1352 - mae: 648.1352\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2045 - mae: 643.2045\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3154 - mae: 639.3154\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.8351 - mae: 640.8351\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3116 - mae: 644.3116\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6816 - mae: 642.6816\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 979.4683 - mae: 979.4683\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3315 - mae: 643.3315\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.2147 - mae: 645.2147\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2731 - mae: 642.2731\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7956 - mae: 638.7956\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8831 - mae: 641.8831\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9070 - mae: 643.9070\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.5171 - mae: 634.5171\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5688 - mae: 641.5688\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.2875 - mae: 645.2875\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7820 - mae: 642.7820\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 649.6255 - mae: 649.6255\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.2272 - mae: 643.2272\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8644 - mae: 640.8644\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.1410 - mae: 636.1410\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1918 - mae: 642.1918\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.8353 - mae: 643.8353\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.3688 - mae: 636.3688\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9644 - mae: 643.9644\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0318 - mae: 638.0318\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0657 - mae: 639.0657\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1381 - mae: 639.1381\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1653 - mae: 644.1653\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 637.9324 - mae: 637.9324\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9252 - mae: 640.9252\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2187 - mae: 642.2187\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.5116 - mae: 648.5116\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.4999 - mae: 634.4999\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.2623 - mae: 638.2623\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2870 - mae: 643.2870\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.1930 - mae: 637.1930\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.8510 - mae: 643.8510\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.7955 - mae: 639.7955\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.6326 - mae: 646.6326\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7917 - mae: 641.7917\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1339 - mae: 639.1339\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.7471 - mae: 641.7471\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.8088 - mae: 640.8088\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.2895 - mae: 634.2895\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4297 - mae: 644.4297\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.9659 - mae: 646.9659\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7449 - mae: 643.7449\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4336 - mae: 639.4336\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.6144 - mae: 636.6144\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.3806 - mae: 641.3806\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6696 - mae: 645.6696\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4919 - mae: 645.4919\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5909 - mae: 642.5909\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.3298 - mae: 648.3298\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.9152 - mae: 636.9152\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 914.3356 - mae: 914.3356\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.7196 - mae: 647.7196\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5048 - mae: 641.5048\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3642 - mae: 642.3642\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9039 - mae: 638.9039\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0829 - mae: 642.0829\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.2820 - mae: 634.2820\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 632.6407 - mae: 632.6407\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.6262 - mae: 636.6262\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8962 - mae: 643.8962\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8950 - mae: 637.8950\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.9411 - mae: 637.9411\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1363 - mae: 639.1363\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0470 - mae: 638.0470\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.3448 - mae: 643.3448\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0410 - mae: 638.0410\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.6080 - mae: 643.6080\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5215 - mae: 639.5215\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.2854 - mae: 643.2854\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.8375 - mae: 644.8375\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7524 - mae: 643.7524\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9372 - mae: 643.9372\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0229 - mae: 639.0229\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3459 - mae: 639.3459\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.9729 - mae: 637.9729\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5375 - mae: 643.5375\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 632.2758 - mae: 632.2758\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5803 - mae: 634.5803\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8126 - mae: 643.8126\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.6447 - mae: 639.6447\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1243 - mae: 642.1243\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.2398 - mae: 642.2398\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.8098 - mae: 634.8098\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.4719 - mae: 638.4719\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.9175 - mae: 632.9175\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.1599 - mae: 645.1599\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.9097 - mae: 637.9097\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.2382 - mae: 645.2382\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.5161 - mae: 639.5161\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.8668 - mae: 638.8668\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.7197 - mae: 646.7197\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.9044 - mae: 643.9044\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.9993 - mae: 633.9993\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1165 - mae: 634.1165\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.9280 - mae: 641.9280\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.5541 - mae: 632.5541\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0828 - mae: 641.0828\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 634.0027 - mae: 634.0027\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.0446 - mae: 634.0446\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4553 - mae: 636.4553\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 938.2841 - mae: 938.2841\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.9700 - mae: 645.9700\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5408 - mae: 647.5408\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9435 - mae: 639.9435\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7928 - mae: 639.7928\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2547 - mae: 641.2547\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.1693 - mae: 645.1693\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6591 - mae: 645.6591\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0813 - mae: 643.0813\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3556 - mae: 642.3556\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1934 - mae: 641.1934\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8228 - mae: 637.8228\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.7794 - mae: 643.7794\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 652.3344 - mae: 652.3344\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 647.5192 - mae: 647.5192\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.9308 - mae: 646.9308\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1039 - mae: 641.1039\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.1190 - mae: 648.1190\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0931 - mae: 640.0931\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5066 - mae: 642.5066\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0618 - mae: 641.0618\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.5242 - mae: 652.5242\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.5273 - mae: 638.5273\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2076 - mae: 647.2076\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0682 - mae: 647.0682\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.9375 - mae: 635.9375\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.2273 - mae: 649.2273\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.1946 - mae: 646.1946\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3543 - mae: 647.3543\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.8000 - mae: 645.8000\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1803 - mae: 640.1803\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2397 - mae: 644.2397\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.6187 - mae: 644.6187\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.5728 - mae: 641.5728\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 648.2388 - mae: 648.2388\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3292 - mae: 645.3292\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.6698 - mae: 647.6698\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9928 - mae: 635.9928\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9899 - mae: 640.9899\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.9092 - mae: 646.9092\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3400 - mae: 647.3400\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7925 - mae: 640.7925\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.2503 - mae: 637.2503\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9189 - mae: 643.9189\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9847 - mae: 638.9847\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.0282 - mae: 642.0282\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.3241 - mae: 640.3241\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.7540 - mae: 639.7540\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 638.4095 - mae: 638.4095\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1910 - mae: 641.1910\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 941.8260 - mae: 941.8260\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.3707 - mae: 643.3707\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8337 - mae: 643.8337\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4352 - mae: 640.4352\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6631 - mae: 641.6631\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.9592 - mae: 634.9592\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0611 - mae: 644.0611\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0283 - mae: 645.0283\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5524 - mae: 641.5524\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.7947 - mae: 643.7947\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.8574 - mae: 641.8574\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4908 - mae: 641.4908\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8678 - mae: 644.8678\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.4086 - mae: 641.4086\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 654.1523 - mae: 654.1523\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2987 - mae: 639.2987\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1411 - mae: 647.1411\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9945 - mae: 640.9945\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6562 - mae: 641.6562\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.4443 - mae: 643.4443\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 647.0242 - mae: 647.0242\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.3284 - mae: 635.3284\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8682 - mae: 638.8682\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9003 - mae: 641.9003\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.5433 - mae: 636.5433\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6644 - mae: 641.6644\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 646.8386 - mae: 646.8386\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.2310 - mae: 645.2310\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.1741 - mae: 648.1741\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7227 - mae: 644.7227\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.0359 - mae: 634.0359\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4351 - mae: 642.4351\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.3214 - mae: 642.3214\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 638.3566 - mae: 638.3566\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.7125 - mae: 641.7125\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8259 - mae: 644.8259\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1243 - mae: 638.1243\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3865 - mae: 645.3865\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.3535 - mae: 639.3535\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.9181 - mae: 641.9181\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 649.3436 - mae: 649.3436\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2941 - mae: 644.2941\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8326 - mae: 639.8326\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.8592 - mae: 645.8592\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.0884 - mae: 641.0884\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.0555 - mae: 640.0555\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.4759 - mae: 638.4759\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.2848 - mae: 647.2848\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9557 - mae: 646.9557\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.0634 - mae: 641.0634\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 859.4902 - mae: 859.4902\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.3778 - mae: 643.3778\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0911 - mae: 644.0911\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.4778 - mae: 642.4778\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8470 - mae: 643.8470\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5954 - mae: 637.5954\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2817 - mae: 644.2817\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6092 - mae: 642.6092\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.4307 - mae: 640.4307\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9686 - mae: 635.9686\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.8452 - mae: 634.8452\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5081 - mae: 638.5081\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 651.0660 - mae: 651.0660\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9174 - mae: 638.9174\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5066 - mae: 642.5066\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4843 - mae: 641.4843\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6635 - mae: 638.6635\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1884 - mae: 642.1884\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1973 - mae: 638.1973\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8085 - mae: 639.8085\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4800 - mae: 642.4800\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.6465 - mae: 641.6465\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3892 - mae: 638.3892\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6470 - mae: 640.6470\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7372 - mae: 639.7372\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6311 - mae: 637.6311\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.8068 - mae: 637.8068\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.9232 - mae: 639.9232\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9551 - mae: 637.9551\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1332 - mae: 639.1332\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9200 - mae: 642.9200\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9751 - mae: 637.9751\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2972 - mae: 643.2972\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4534 - mae: 644.4534\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.6681 - mae: 636.6681\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 636.3391 - mae: 636.3391\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 634.9257 - mae: 634.9257\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.9484 - mae: 636.9484\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2310 - mae: 641.2310\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3528 - mae: 636.3528\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6622 - mae: 641.6622\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.8041 - mae: 637.8041\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1671 - mae: 641.1671\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5491 - mae: 638.5491\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7836 - mae: 638.7836\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7255 - mae: 636.7255\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0042 - mae: 641.0042\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5634 - mae: 643.5634\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.0129 - mae: 634.0129\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.0146 - mae: 649.0146\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 869.1686 - mae: 869.1686\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.7409 - mae: 650.7409\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7610 - mae: 642.7610\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 632.7010 - mae: 632.7010\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2188 - mae: 644.2188\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.6167 - mae: 647.6167\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1555 - mae: 642.1555\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.9597 - mae: 648.9597\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8693 - mae: 641.8693\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.4395 - mae: 647.4395\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.4084 - mae: 635.4084\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1228 - mae: 641.1228\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.1968 - mae: 643.1968\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.9942 - mae: 651.9942\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2916 - mae: 640.2916\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.7291 - mae: 644.7291\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3957 - mae: 644.3957\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.4438 - mae: 644.4438\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8148 - mae: 643.8148\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.3564 - mae: 640.3564\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1087 - mae: 639.1087\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9724 - mae: 643.9724\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.3953 - mae: 643.3953\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5780 - mae: 645.5780\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4888 - mae: 641.4888\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.0231 - mae: 641.0231\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.1898 - mae: 639.1898\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0693 - mae: 645.0693\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.9106 - mae: 647.9106\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6215 - mae: 641.6215\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6491 - mae: 641.6491\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5579 - mae: 644.5579\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.0608 - mae: 650.0608\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6813 - mae: 640.6813\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.2733 - mae: 652.2733\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7256 - mae: 645.7256\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9689 - mae: 645.9689\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 654.7919 - mae: 654.7919\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1757 - mae: 641.1757\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1629 - mae: 635.1629\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7933 - mae: 643.7933\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8502 - mae: 643.8502\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3448 - mae: 636.3448\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6585 - mae: 641.6585\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6784 - mae: 641.6784\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1532 - mae: 641.1532\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.0577 - mae: 645.0577\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.0798 - mae: 636.0798\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7747 - mae: 642.7747\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0583 - mae: 640.0583\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 864.0582 - mae: 864.0582\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3499 - mae: 645.3499\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8541 - mae: 642.8541\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8315 - mae: 642.8315\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.7535 - mae: 644.7535\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4699 - mae: 643.4699\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6788 - mae: 643.6788\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0181 - mae: 641.0181\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2051 - mae: 641.2051\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9650 - mae: 640.9650\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 638.9467 - mae: 638.9467\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9126 - mae: 640.9126\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.5421 - mae: 646.5421\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1741 - mae: 647.1741\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5166 - mae: 642.5166\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.3802 - mae: 640.3802\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7889 - mae: 643.7889\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9994 - mae: 643.9994\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0894 - mae: 640.0894\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.1065 - mae: 640.1065\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1127 - mae: 642.1127\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0983 - mae: 639.0983\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.6733 - mae: 648.6733\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7593 - mae: 642.7593\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 655.9774 - mae: 655.9774\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.3524 - mae: 636.3524\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.9525 - mae: 646.9525\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9836 - mae: 640.9836\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2369 - mae: 644.2369\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4756 - mae: 645.4756\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.6834 - mae: 640.6834\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2447 - mae: 637.2447\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.3492 - mae: 648.3492\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4715 - mae: 640.4715\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0685 - mae: 647.0685\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7433 - mae: 639.7433\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5088 - mae: 642.5088\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1176 - mae: 636.1176\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8795 - mae: 640.8795\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0486 - mae: 645.0486\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9606 - mae: 642.9606\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.4427 - mae: 647.4427\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.9936 - mae: 640.9936\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.7646 - mae: 638.7646\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7770 - mae: 644.7770\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9095 - mae: 639.9095\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7589 - mae: 638.7589\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0801 - mae: 638.0801\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.8599 - mae: 647.8599\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6374 - mae: 642.6374\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 811.2040 - mae: 811.2040\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.0580 - mae: 639.0580\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.7167 - mae: 633.7167\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9294 - mae: 640.9294\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.3171 - mae: 645.3171\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.3812 - mae: 637.3812\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4227 - mae: 638.4227\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5619 - mae: 647.5619\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4311 - mae: 636.4311\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.0467 - mae: 637.0467\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.2980 - mae: 645.2980\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.1620 - mae: 636.1620\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.2391 - mae: 645.2391\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.4208 - mae: 634.4208\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2508 - mae: 636.2508\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7126 - mae: 638.7126\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.8032 - mae: 639.8032\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6607 - mae: 638.6607\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4793 - mae: 647.4793\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4172 - mae: 636.4172\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.0168 - mae: 633.0168\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9887 - mae: 634.9887\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5965 - mae: 641.5965\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.9672 - mae: 640.9672\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.3640 - mae: 643.3640\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4213 - mae: 643.4213\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.1638 - mae: 647.1638\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0757 - mae: 635.0757\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1298 - mae: 643.1298\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.9402 - mae: 636.9402\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0226 - mae: 639.0226\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.3300 - mae: 639.3300\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9174 - mae: 636.9174\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7104 - mae: 642.7104\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.6508 - mae: 632.6508\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6508 - mae: 640.6508\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.5797 - mae: 637.5797\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.4492 - mae: 634.4492\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3074 - mae: 640.3074\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8600 - mae: 639.8600\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6753 - mae: 639.6753\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4104 - mae: 641.4104\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6390 - mae: 640.6390\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8569 - mae: 638.8569\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.7318 - mae: 631.7318\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.0692 - mae: 636.0692\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.4774 - mae: 637.4774\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1292 - mae: 643.1292\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.1011 - mae: 636.1011\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.5288 - mae: 633.5288\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 821.5026 - mae: 821.5026\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.5859 - mae: 648.5859\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.2576 - mae: 648.2576\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2196 - mae: 640.2196\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6321 - mae: 645.6321\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0426 - mae: 640.0426\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9869 - mae: 645.9869\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 651.1536 - mae: 651.1536\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1767 - mae: 640.1767\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.8249 - mae: 639.8249\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3387 - mae: 639.3387\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5153 - mae: 645.5153\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0547 - mae: 640.0547\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 651.2653 - mae: 651.2653\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6511 - mae: 638.6511\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3743 - mae: 646.3743\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.7463 - mae: 637.7463\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4727 - mae: 636.4727\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0387 - mae: 642.0387\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1022 - mae: 641.1022\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.0174 - mae: 647.0174\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7378 - mae: 641.7378\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8616 - mae: 638.8616\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4209 - mae: 642.4209\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.7939 - mae: 635.7939\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0120 - mae: 645.0120\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.3649 - mae: 641.3649\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7514 - mae: 646.7514\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8001 - mae: 639.8001\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9166 - mae: 642.9166\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9677 - mae: 644.9677\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1628 - mae: 644.1628\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.8085 - mae: 642.8085\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.9547 - mae: 642.9547\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1457 - mae: 641.1457\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9834 - mae: 637.9834\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9932 - mae: 637.9932\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1595 - mae: 634.1595\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0661 - mae: 640.0661\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.0336 - mae: 642.0336\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4167 - mae: 643.4167\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6255 - mae: 640.6255\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.2391 - mae: 638.2391\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6433 - mae: 643.6433\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1086 - mae: 644.1086\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0690 - mae: 644.0690\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7040 - mae: 640.7040\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5876 - mae: 642.5876\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9630 - mae: 641.9630\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6396 - mae: 638.6396\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 818.6404 - mae: 818.6404\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.4333 - mae: 642.4333\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6168 - mae: 642.6168\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2520 - mae: 647.2520\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8969 - mae: 646.8969\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.8831 - mae: 641.8831\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4168 - mae: 645.4168\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.6251 - mae: 644.6251\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4598 - mae: 645.4598\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.5230 - mae: 647.5230\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.7899 - mae: 634.7899\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1632 - mae: 644.1632\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5574 - mae: 638.5574\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.5995 - mae: 645.5995\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2841 - mae: 647.2841\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5005 - mae: 638.5005\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.8514 - mae: 648.8514\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4214 - mae: 643.4214\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0327 - mae: 645.0327\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.3570 - mae: 642.3570\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.2010 - mae: 639.2010\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5930 - mae: 645.5930\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6163 - mae: 640.6163\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1743 - mae: 643.1743\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4581 - mae: 639.4581\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6114 - mae: 640.6114\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.0567 - mae: 642.0567\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6218 - mae: 639.6218\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2847 - mae: 646.2847\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0159 - mae: 641.0159\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3021 - mae: 639.3021\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8265 - mae: 645.8265\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4329 - mae: 639.4329\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.4717 - mae: 642.4717\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 648.6100 - mae: 648.6100\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9589 - mae: 641.9589\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3163 - mae: 641.3163\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5709 - mae: 641.5709\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3773 - mae: 646.3773\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1102 - mae: 641.1102\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.8441 - mae: 637.8441\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5937 - mae: 641.5937\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9655 - mae: 644.9655\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.6398 - mae: 645.6398\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.7733 - mae: 649.7733\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5336 - mae: 638.5336\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.8449 - mae: 647.8449\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2889 - mae: 641.2889\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.1896 - mae: 637.1896\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.2356 - mae: 636.2356\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 933.7930 - mae: 933.7930\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 645.9022 - mae: 645.9022\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6954 - mae: 637.6954\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.6010 - mae: 634.6010\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3864 - mae: 647.3864\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7243 - mae: 638.7243\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5748 - mae: 639.5748\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8339 - mae: 638.8339\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.5468 - mae: 637.5468\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.4875 - mae: 633.4875\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1567 - mae: 643.1567\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5905 - mae: 640.5905\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.5443 - mae: 635.5443\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.5247 - mae: 648.5247\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6002 - mae: 640.6002\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5933 - mae: 638.5933\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2426 - mae: 639.2426\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.6811 - mae: 632.6811\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5956 - mae: 643.5956\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5790 - mae: 642.5790\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0590 - mae: 645.0590\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2634 - mae: 641.2634\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5327 - mae: 635.5327\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.2473 - mae: 635.2473\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3366 - mae: 638.3366\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.5395 - mae: 641.5395\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2465 - mae: 639.2465\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0732 - mae: 642.0732\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 631.8874 - mae: 631.8874\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2761 - mae: 638.2761\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4139 - mae: 639.4139\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1951 - mae: 639.1951\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7949 - mae: 646.7949\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.8281 - mae: 638.8281\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1973 - mae: 642.1973\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4802 - mae: 641.4802\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.0151 - mae: 646.0151\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.8271 - mae: 635.8271\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.2070 - mae: 635.2070\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1194 - mae: 636.1194\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3448 - mae: 641.3448\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1553 - mae: 640.1553\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.3517 - mae: 638.3517\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7469 - mae: 636.7469\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7773 - mae: 636.7773\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7808 - mae: 639.7808\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.9883 - mae: 641.9883\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.2021 - mae: 640.2021\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.6425 - mae: 629.6425\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.4564 - mae: 639.4564\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 924.1526 - mae: 924.1526\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8149 - mae: 642.8149\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.3576 - mae: 637.3576\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.4492 - mae: 638.4492\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4487 - mae: 641.4487\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0757 - mae: 642.0757\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1774 - mae: 644.1774\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0253 - mae: 638.0253\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.5552 - mae: 644.5552\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0539 - mae: 642.0539\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.3765 - mae: 649.3765\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7967 - mae: 642.7967\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4537 - mae: 640.4537\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1536 - mae: 641.1536\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9177 - mae: 645.9177\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5572 - mae: 641.5572\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8383 - mae: 637.8383\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9150 - mae: 636.9150\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 655.4258 - mae: 655.4258\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.2604 - mae: 648.2604\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.8190 - mae: 638.8190\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0925 - mae: 645.0925\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7919 - mae: 644.7919\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.4691 - mae: 650.4691\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3499 - mae: 642.3499\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.4895 - mae: 647.4895\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.3896 - mae: 643.3896\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8958 - mae: 641.8958\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1509 - mae: 643.1509\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0737 - mae: 643.0737\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3030 - mae: 639.3030\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8580 - mae: 644.8580\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.1550 - mae: 644.1550\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.5811 - mae: 634.5811\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0554 - mae: 640.0554\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6031 - mae: 638.6031\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.3323 - mae: 644.3323\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5662 - mae: 645.5662\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2388 - mae: 638.2388\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 647.5988 - mae: 647.5988\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8717 - mae: 641.8717\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9893 - mae: 637.9893\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0872 - mae: 646.0872\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1539 - mae: 645.1539\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4608 - mae: 644.4608\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.2261 - mae: 642.2261\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.1335 - mae: 644.1335\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.2919 - mae: 637.2919\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5347 - mae: 642.5347\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.2627 - mae: 649.2627\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 917.3356 - mae: 917.3356\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.3598 - mae: 645.3598\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.1891 - mae: 635.1891\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9111 - mae: 640.9111\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2028 - mae: 644.2028\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1780 - mae: 644.1780\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.9487 - mae: 645.9487\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0770 - mae: 641.0770\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9284 - mae: 637.9284\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.2617 - mae: 642.2617\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6765 - mae: 636.6765\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7333 - mae: 642.7333\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.9533 - mae: 645.9533\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7033 - mae: 640.7033\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.6689 - mae: 636.6689\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0386 - mae: 642.0386\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5469 - mae: 644.5469\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9728 - mae: 637.9728\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4558 - mae: 644.4558\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0076 - mae: 638.0076\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8780 - mae: 639.8780\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8642 - mae: 638.8642\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.5184 - mae: 638.5184\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3062 - mae: 639.3062\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.9631 - mae: 647.9631\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.5242 - mae: 644.5242\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6771 - mae: 638.6771\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4372 - mae: 640.4372\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9847 - mae: 645.9847\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.4794 - mae: 644.4794\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 645.4598 - mae: 645.4598\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.4927 - mae: 648.4927\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6683 - mae: 643.6683\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9332 - mae: 639.9332\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2441 - mae: 644.2441\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6001 - mae: 641.6001\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1058 - mae: 638.1058\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.3581 - mae: 650.3581\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.6331 - mae: 647.6331\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0449 - mae: 645.0449\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2034 - mae: 641.2034\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4517 - mae: 644.4517\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.2339 - mae: 640.2339\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1861 - mae: 636.1861\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8512 - mae: 642.8512\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6517 - mae: 645.6517\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2313 - mae: 646.2313\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6495 - mae: 639.6495\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.3314 - mae: 641.3314\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0396 - mae: 641.0396\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 862.3337 - mae: 862.3337\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1708 - mae: 643.1708\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5158 - mae: 639.5158\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5941 - mae: 635.5941\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2390 - mae: 644.2390\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3263 - mae: 644.3263\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8087 - mae: 639.8087\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9276 - mae: 640.9276\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.7272 - mae: 635.7272\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.5376 - mae: 639.5376\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9276 - mae: 635.9276\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5735 - mae: 645.5735\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7291 - mae: 637.7291\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.1816 - mae: 644.1816\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.6338 - mae: 633.6338\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.2206 - mae: 637.2206\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5398 - mae: 642.5398\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8557 - mae: 644.8557\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.3490 - mae: 632.3490\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0744 - mae: 640.0744\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.4594 - mae: 633.4594\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1954 - mae: 638.1954\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3895 - mae: 638.3895\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6129 - mae: 638.6129\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2109 - mae: 641.2109\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.0576 - mae: 640.0576\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8966 - mae: 641.8966\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.1390 - mae: 643.1390\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.1090 - mae: 633.1090\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.6043 - mae: 642.6043\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.7865 - mae: 635.7865\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.1764 - mae: 638.1764\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1160 - mae: 637.1160\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.4725 - mae: 638.4725\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6461 - mae: 639.6461\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5938 - mae: 641.5938\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9063 - mae: 635.9063\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.6237 - mae: 634.6237\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1479 - mae: 638.1479\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.2949 - mae: 634.2949\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2750 - mae: 641.2750\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5677 - mae: 639.5677\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 629.4495 - mae: 629.4495\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.1710 - mae: 638.1710\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3584 - mae: 640.3584\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4501 - mae: 641.4501\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6629 - mae: 637.6629\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.4460 - mae: 642.4460\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8313 - mae: 637.8313\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6593 - mae: 643.6593\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 849.2853 - mae: 849.2853\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5832 - mae: 640.5832\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.2933 - mae: 646.2933\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2328 - mae: 642.2328\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0623 - mae: 641.0623\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.7141 - mae: 647.7141\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0424 - mae: 639.0424\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6874 - mae: 646.6874\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 652.8041 - mae: 652.8041\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4575 - mae: 643.4575\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9901 - mae: 645.9901\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.0173 - mae: 638.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.3663 - mae: 644.3663\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5928 - mae: 640.5928\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.9015 - mae: 641.9015\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 643.4070 - mae: 643.4070\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6874 - mae: 640.6874\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1945 - mae: 641.1945\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2287 - mae: 640.2287\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9471 - mae: 642.9471\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5338 - mae: 645.5338\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.9727 - mae: 643.9727\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.8550 - mae: 646.8550\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9227 - mae: 644.9227\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7462 - mae: 645.7462\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4594 - mae: 641.4594\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1419 - mae: 643.1419\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.5225 - mae: 637.5225\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3696 - mae: 645.3696\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1021 - mae: 638.1021\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9935 - mae: 646.9935\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0809 - mae: 637.0809\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6811 - mae: 639.6811\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4872 - mae: 640.4872\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3010 - mae: 641.3010\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.8061 - mae: 637.8061\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.7918 - mae: 646.7918\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.9077 - mae: 636.9077\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0455 - mae: 643.0455\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3666 - mae: 645.3666\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3669 - mae: 649.3669\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1479 - mae: 637.1479\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8342 - mae: 644.8342\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4136 - mae: 639.4136\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3470 - mae: 642.3470\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6116 - mae: 646.6116\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.6797 - mae: 641.6797\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3665 - mae: 635.3665\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.8855 - mae: 639.8855\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9897 - mae: 639.9897\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 855.4143 - mae: 855.4143\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5870 - mae: 643.5870\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1028 - mae: 637.1028\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.2060 - mae: 645.2060\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5650 - mae: 640.5650\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.2285 - mae: 642.2285\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.9995 - mae: 647.9995\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8242 - mae: 644.8242\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7797 - mae: 646.7797\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6103 - mae: 644.6103\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5403 - mae: 639.5403\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8116 - mae: 638.8116\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.2387 - mae: 639.2387\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6592 - mae: 645.6592\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3704 - mae: 639.3704\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2383 - mae: 643.2383\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9031 - mae: 640.9031\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1222 - mae: 640.1222\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.9611 - mae: 635.9611\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5720 - mae: 645.5720\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1779 - mae: 641.1779\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0848 - mae: 644.0848\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7481 - mae: 642.7481\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4960 - mae: 642.4960\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0173 - mae: 639.0173\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.9395 - mae: 644.9395\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8987 - mae: 642.8987\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.7222 - mae: 642.7222\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0937 - mae: 640.0937\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.7732 - mae: 633.7732\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6594 - mae: 643.6594\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0211 - mae: 639.0211\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.4562 - mae: 645.4562\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.0284 - mae: 648.0284\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0058 - mae: 640.0058\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.6842 - mae: 633.6842\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3624 - mae: 642.3624\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9960 - mae: 639.9960\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2351 - mae: 645.2351\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6185 - mae: 640.6185\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.7019 - mae: 639.7019\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2945 - mae: 636.2945\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7164 - mae: 646.7164\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3215 - mae: 641.3215\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7684 - mae: 638.7684\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0823 - mae: 644.0823\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.8161 - mae: 638.8161\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.9053 - mae: 647.9053\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2167 - mae: 644.2167\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3155 - mae: 646.3155\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 793.5382 - mae: 793.5382\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.9884 - mae: 632.9884\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1552 - mae: 644.1552\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5892 - mae: 640.5892\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.3857 - mae: 635.3857\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3215 - mae: 637.3215\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2413 - mae: 636.2413\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 652.7500 - mae: 652.7500\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6412 - mae: 636.6412\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5078 - mae: 642.5078\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4403 - mae: 637.4403\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1402 - mae: 640.1402\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.7148 - mae: 634.7148\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.2145 - mae: 645.2145\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.3387 - mae: 633.3387\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8004 - mae: 634.8004\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4014 - mae: 641.4014\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4648 - mae: 643.4648\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.0577 - mae: 633.0577\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4532 - mae: 644.4532\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2538 - mae: 641.2538\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4454 - mae: 643.4454\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5065 - mae: 635.5065\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0490 - mae: 632.0490\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.7541 - mae: 633.7541\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.9426 - mae: 638.9426\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7236 - mae: 635.7236\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.8406 - mae: 640.8406\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8790 - mae: 639.8790\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.5838 - mae: 637.5838\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3657 - mae: 642.3657\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4094 - mae: 641.4094\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8849 - mae: 639.8849\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.5471 - mae: 635.5471\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.9655 - mae: 631.9655\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.5922 - mae: 649.5922\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.0912 - mae: 637.0912\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2105 - mae: 638.2105\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6225 - mae: 639.6225\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.0900 - mae: 639.0900\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2097 - mae: 635.2097\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7786 - mae: 639.7786\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.5878 - mae: 633.5878\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8757 - mae: 643.8757\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5402 - mae: 639.5402\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.9510 - mae: 635.9510\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1495 - mae: 638.1495\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.8171 - mae: 634.8171\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 626.4171 - mae: 626.4171\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.5622 - mae: 632.5622\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 806.5247 - mae: 806.5247\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9240 - mae: 643.9240\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5204 - mae: 647.5204\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3987 - mae: 639.3987\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0646 - mae: 645.0646\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.8314 - mae: 632.8314\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.1193 - mae: 648.1193\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1459 - mae: 648.1459\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8848 - mae: 645.8848\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8275 - mae: 643.8275\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0353 - mae: 641.0353\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9848 - mae: 638.9848\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.8000 - mae: 647.8000\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7690 - mae: 640.7690\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7126 - mae: 644.7126\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.0453 - mae: 642.0453\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8641 - mae: 643.8641\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2573 - mae: 635.2573\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8016 - mae: 641.8016\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3873 - mae: 644.3873\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3990 - mae: 641.3990\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.7567 - mae: 632.7567\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.2104 - mae: 637.2104\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.5005 - mae: 637.5005\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6627 - mae: 646.6627\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1496 - mae: 644.1496\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.2443 - mae: 645.2443\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9621 - mae: 640.9621\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5535 - mae: 642.5535\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6620 - mae: 640.6620\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.8173 - mae: 640.8173\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1180 - mae: 635.1180\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.0979 - mae: 640.0979\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.5365 - mae: 632.5365\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3105 - mae: 640.3105\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.3286 - mae: 645.3286\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6974 - mae: 635.6974\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4782 - mae: 643.4782\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6971 - mae: 638.6971\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.3577 - mae: 640.3577\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.5467 - mae: 631.5467\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9152 - mae: 634.9152\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.7756 - mae: 645.7756\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3024 - mae: 641.3024\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.2229 - mae: 631.2229\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.5776 - mae: 643.5776\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.5069 - mae: 639.5069\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3594 - mae: 639.3594\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3226 - mae: 640.3226\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9318 - mae: 636.9318\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 789.9371 - mae: 789.9371\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.4386 - mae: 645.4386\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.1183 - mae: 651.1183\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5005 - mae: 638.5005\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2398 - mae: 641.2398\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.9391 - mae: 647.9391\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.8306 - mae: 636.8306\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9341 - mae: 638.9341\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.6214 - mae: 637.6214\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1803 - mae: 642.1803\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.5458 - mae: 636.5458\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6348 - mae: 641.6348\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.2876 - mae: 644.2876\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1359 - mae: 646.1359\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.3866 - mae: 645.3866\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.5348 - mae: 637.5348\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5509 - mae: 639.5509\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6468 - mae: 642.6468\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8505 - mae: 636.8505\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.3622 - mae: 647.3622\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2203 - mae: 645.2203\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4683 - mae: 644.4683\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.9677 - mae: 649.9677\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1924 - mae: 640.1924\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5070 - mae: 639.5070\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4773 - mae: 641.4773\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.2616 - mae: 648.2616\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.9869 - mae: 634.9869\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.2650 - mae: 650.2650\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7551 - mae: 641.7551\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6434 - mae: 641.6434\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8778 - mae: 636.8778\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3976 - mae: 638.3976\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.6028 - mae: 644.6028\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1058 - mae: 640.1058\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5203 - mae: 640.5203\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5536 - mae: 641.5536\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0330 - mae: 636.0330\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.0729 - mae: 645.0729\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.0947 - mae: 638.0947\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1110 - mae: 643.1110\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7703 - mae: 638.7703\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1614 - mae: 638.1614\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9550 - mae: 636.9550\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7587 - mae: 642.7587\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7943 - mae: 635.7943\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5518 - mae: 642.5518\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.7675 - mae: 651.7675\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8839 - mae: 639.8839\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2354 - mae: 638.2354\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 748.0123 - mae: 748.0123\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5468 - mae: 639.5468\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1539 - mae: 636.1539\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8127 - mae: 641.8127\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6417 - mae: 636.6417\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3846 - mae: 637.3846\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6357 - mae: 642.6357\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.6742 - mae: 640.6742\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.9042 - mae: 636.9042\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3336 - mae: 640.3336\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1364 - mae: 642.1364\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2071 - mae: 641.2071\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.3014 - mae: 637.3014\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 635.5425 - mae: 635.5425\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.8790 - mae: 635.8790\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 626.9755 - mae: 626.9755\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.7999 - mae: 632.7999\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1268 - mae: 637.1268\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1533 - mae: 640.1533\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9092 - mae: 634.9092\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 629.2168 - mae: 629.2168\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.7510 - mae: 633.7510\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.7020 - mae: 629.7020\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.3887 - mae: 637.3887\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.5955 - mae: 633.5955\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9065 - mae: 642.9065\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.0735 - mae: 632.0735\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8953 - mae: 641.8953\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5056 - mae: 639.5056\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.4326 - mae: 640.4326\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.0481 - mae: 636.0481\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 630.1334 - mae: 630.1334\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0319 - mae: 639.0319\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2087 - mae: 638.2087\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9771 - mae: 635.9771\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6205 - mae: 635.6205\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 632.4775 - mae: 632.4775\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9865 - mae: 634.9865\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.9060 - mae: 632.9060\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.6865 - mae: 633.6865\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.1848 - mae: 632.1848\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.8436 - mae: 632.8436\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.8364 - mae: 629.8364\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2696 - mae: 641.2696\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.2746 - mae: 632.2746\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.4570 - mae: 631.4570\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 629.6072 - mae: 629.6072\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 628.2427 - mae: 628.2427\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.3231 - mae: 630.3231\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.7108 - mae: 633.7108\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 750.1646 - mae: 750.1646\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3535 - mae: 643.3535\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 645.9016 - mae: 645.9016\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2565 - mae: 644.2565\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8911 - mae: 638.8911\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.8329 - mae: 646.8329\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.6043 - mae: 644.6043\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.6173 - mae: 636.6173\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1744 - mae: 640.1744\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.7697 - mae: 647.7697\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6473 - mae: 645.6473\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 645.3560 - mae: 645.3560\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.3569 - mae: 642.3569\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4693 - mae: 638.4693\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.5969 - mae: 647.5969\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4214 - mae: 643.4214\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 642.7535 - mae: 642.7535\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0885 - mae: 643.0885\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0632 - mae: 639.0632\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4628 - mae: 642.4628\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9944 - mae: 642.9944\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4733 - mae: 645.4733\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.4858 - mae: 637.4858\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.8106 - mae: 645.8106\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 639.6384 - mae: 639.6384\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8638 - mae: 640.8638\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4777 - mae: 641.4777\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.1526 - mae: 650.1526\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 650.7264 - mae: 650.7264\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 647.2472 - mae: 647.2472\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8816 - mae: 640.8816\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7912 - mae: 640.7912\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8264 - mae: 635.8264\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 642.6470 - mae: 642.6470\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.6365 - mae: 642.6365\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8632 - mae: 645.8632\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1062 - mae: 644.1062\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4248 - mae: 649.4248\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.7199 - mae: 645.7199\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.1245 - mae: 641.1245\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4407 - mae: 643.4407\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6168 - mae: 638.6168\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1840 - mae: 637.1840\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3937 - mae: 641.3937\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 640.3719 - mae: 640.3719\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.5068 - mae: 634.5068\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9574 - mae: 636.9574\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5933 - mae: 638.5933\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8039 - mae: 638.8039\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.1907 - mae: 632.1907\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 758.3426 - mae: 758.3426\n",
            "Epoch 2/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.6939 - mae: 642.6939\n",
            "Epoch 3/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1525 - mae: 635.1525\n",
            "Epoch 4/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0012 - mae: 639.0012\n",
            "Epoch 5/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.3713 - mae: 639.3713\n",
            "Epoch 6/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.7869 - mae: 641.7869\n",
            "Epoch 7/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.5018 - mae: 651.5018\n",
            "Epoch 8/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8698 - mae: 643.8698\n",
            "Epoch 9/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3185 - mae: 637.3185\n",
            "Epoch 10/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5975 - mae: 639.5975\n",
            "Epoch 11/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3716 - mae: 641.3716\n",
            "Epoch 12/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.4971 - mae: 638.4971\n",
            "Epoch 13/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.3569 - mae: 638.3569\n",
            "Epoch 14/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3915 - mae: 638.3915\n",
            "Epoch 15/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.9138 - mae: 647.9138\n",
            "Epoch 16/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.4523 - mae: 650.4523\n",
            "Epoch 17/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.4441 - mae: 639.4441\n",
            "Epoch 18/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.2787 - mae: 642.2787\n",
            "Epoch 19/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8261 - mae: 643.8261\n",
            "Epoch 20/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.7569 - mae: 631.7569\n",
            "Epoch 21/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3499 - mae: 644.3499\n",
            "Epoch 22/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.6339 - mae: 642.6339\n",
            "Epoch 23/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5464 - mae: 638.5464\n",
            "Epoch 24/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0826 - mae: 639.0826\n",
            "Epoch 25/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.8899 - mae: 647.8899\n",
            "Epoch 26/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9756 - mae: 643.9756\n",
            "Epoch 27/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6841 - mae: 646.6841\n",
            "Epoch 28/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4135 - mae: 638.4135\n",
            "Epoch 29/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.9635 - mae: 638.9635\n",
            "Epoch 30/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.0340 - mae: 645.0340\n",
            "Epoch 31/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.1528 - mae: 631.1528\n",
            "Epoch 32/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.3799 - mae: 634.3799\n",
            "Epoch 33/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4854 - mae: 639.4854\n",
            "Epoch 34/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9340 - mae: 641.9340\n",
            "Epoch 35/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.4573 - mae: 634.4573\n",
            "Epoch 36/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9479 - mae: 639.9479\n",
            "Epoch 37/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1635 - mae: 644.1635\n",
            "Epoch 38/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.2193 - mae: 633.2193\n",
            "Epoch 39/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0458 - mae: 635.0458\n",
            "Epoch 40/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0093 - mae: 644.0093\n",
            "Epoch 41/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.1489 - mae: 642.1489\n",
            "Epoch 42/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.1049 - mae: 632.1049\n",
            "Epoch 43/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.1520 - mae: 637.1520\n",
            "Epoch 44/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.7435 - mae: 636.7435\n",
            "Epoch 45/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.4642 - mae: 634.4642\n",
            "Epoch 46/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7136 - mae: 635.7136\n",
            "Epoch 47/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.9050 - mae: 636.9050\n",
            "Epoch 48/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.5639 - mae: 642.5639\n",
            "Epoch 49/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7706 - mae: 638.7706\n",
            "Epoch 50/50\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4606 - mae: 640.4606\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1086.0402 - mae: 1086.0402\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 913.4323 - mae: 913.4323\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 702.8537 - mae: 702.8537\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.9126 - mae: 647.9126\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.1924 - mae: 646.1924\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.8232 - mae: 644.8232\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6984 - mae: 641.6984\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6996 - mae: 644.6996\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0548 - mae: 644.0548\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.5911 - mae: 637.5911\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 654.3477 - mae: 654.3477\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 628.9447 - mae: 628.9447\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3953 - mae: 643.3953\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7285 - mae: 637.7285\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.7112 - mae: 631.7112\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3180 - mae: 637.3180\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.2695 - mae: 639.2695\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5203 - mae: 640.5203\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.2142 - mae: 647.2142\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.7941 - mae: 640.7941\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.2170 - mae: 641.2170\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5346 - mae: 639.5346\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.7856 - mae: 638.7856\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.4654 - mae: 640.4654\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.4968 - mae: 641.4968\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7966 - mae: 641.7966\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.4027 - mae: 646.4027\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1401 - mae: 639.1401\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5193 - mae: 635.5193\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3369 - mae: 635.3369\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.7384 - mae: 648.7384\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5284 - mae: 642.5284\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1229 - mae: 640.1229\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6872 - mae: 639.6872\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.9373 - mae: 641.9373\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.9559 - mae: 644.9559\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.8364 - mae: 635.8364\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2649 - mae: 639.2649\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5365 - mae: 641.5365\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.8058 - mae: 634.8058\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3654 - mae: 639.3654\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4604 - mae: 639.4604\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 629.1865 - mae: 629.1865\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.2697 - mae: 638.2697\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5229 - mae: 642.5229\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.0793 - mae: 638.0793\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3053 - mae: 643.3053\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.4235 - mae: 633.4235\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.2904 - mae: 635.2904\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1779 - mae: 643.1779\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1962 - mae: 640.1962\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7142 - mae: 645.7142\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.2307 - mae: 635.2307\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.8638 - mae: 636.8638\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.1661 - mae: 632.1661\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.2320 - mae: 634.2320\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8019 - mae: 640.8019\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3280 - mae: 645.3280\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5081 - mae: 638.5081\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9745 - mae: 636.9745\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4080 - mae: 639.4080\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1125 - mae: 643.1125\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.1493 - mae: 638.1493\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8490 - mae: 639.8490\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4100 - mae: 640.4100\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.9362 - mae: 642.9362\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.0724 - mae: 637.0724\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2961 - mae: 639.2961\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.9673 - mae: 640.9673\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8747 - mae: 639.8747\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.7405 - mae: 639.7405\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4312 - mae: 641.4312\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9840 - mae: 640.9840\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.1554 - mae: 639.1554\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.6975 - mae: 641.6975\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.0533 - mae: 635.0533\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5116 - mae: 640.5116\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.6043 - mae: 632.6043\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.5863 - mae: 637.5863\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3697 - mae: 639.3697\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2328 - mae: 635.2328\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5363 - mae: 637.5363\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.6169 - mae: 642.6169\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8470 - mae: 642.8470\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6678 - mae: 640.6678\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.8264 - mae: 639.8264\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.6376 - mae: 638.6376\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9383 - mae: 636.9383\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.1729 - mae: 643.1729\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2762 - mae: 636.2762\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.3469 - mae: 642.3469\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.9537 - mae: 635.9537\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1533 - mae: 643.1533\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 629.3726 - mae: 629.3726\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.1572 - mae: 637.1572\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7362 - mae: 637.7362\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.5256 - mae: 633.5256\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3893 - mae: 639.3893\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2754 - mae: 639.2754\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.8628 - mae: 633.8628\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1090.4243 - mae: 1090.4243\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1003.2933 - mae: 1003.2933\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 820.8018 - mae: 820.8018\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 692.9324 - mae: 692.9324\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.3217 - mae: 649.3217\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1202 - mae: 648.1202\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0349 - mae: 647.0349\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 648.9298 - mae: 648.9298\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.4949 - mae: 650.4949\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 656.7634 - mae: 656.7634\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.1909 - mae: 648.1909\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6737 - mae: 645.6737\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1874 - mae: 645.1874\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3301 - mae: 642.3301\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.1310 - mae: 643.1310\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.8812 - mae: 646.8812\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8177 - mae: 647.8177\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4807 - mae: 645.4807\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3156 - mae: 645.3156\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.1824 - mae: 646.1824\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.7816 - mae: 644.7816\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8453 - mae: 640.8453\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1507 - mae: 646.1507\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.3427 - mae: 647.3427\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.2654 - mae: 645.2654\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.7715 - mae: 650.7715\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.8666 - mae: 643.8666\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1570 - mae: 640.1570\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.0627 - mae: 647.0627\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8036 - mae: 647.8036\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.9213 - mae: 639.9213\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.5841 - mae: 637.5841\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.7410 - mae: 641.7410\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3118 - mae: 648.3118\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.6720 - mae: 644.6720\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2071 - mae: 643.2071\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.0015 - mae: 652.0015\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7269 - mae: 640.7269\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.7953 - mae: 645.7953\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3760 - mae: 638.3760\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.5444 - mae: 649.5444\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6713 - mae: 643.6713\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.9578 - mae: 640.9578\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8948 - mae: 638.8948\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3706 - mae: 644.3706\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.7919 - mae: 650.7919\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.1375 - mae: 640.1375\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.6944 - mae: 647.6944\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.0638 - mae: 645.0638\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.2753 - mae: 644.2753\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3151 - mae: 641.3151\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7729 - mae: 640.7729\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.2703 - mae: 643.2703\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4114 - mae: 643.4114\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 648.2635 - mae: 648.2635\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.8806 - mae: 637.8806\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6945 - mae: 648.6945\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4461 - mae: 648.4461\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0963 - mae: 641.0963\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.9598 - mae: 645.9598\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.0137 - mae: 647.0137\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3001 - mae: 642.3001\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.0469 - mae: 641.0469\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8489 - mae: 645.8489\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9401 - mae: 642.9401\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7979 - mae: 644.7979\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 649.5030 - mae: 649.5030\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.2980 - mae: 649.2980\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 649.8596 - mae: 649.8596\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0485 - mae: 644.0485\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.1802 - mae: 646.1802\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6432 - mae: 640.6432\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.8056 - mae: 649.8056\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.5823 - mae: 647.5823\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.3314 - mae: 646.3314\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4068 - mae: 640.4068\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 640.0682 - mae: 640.0682\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 647.6248 - mae: 647.6248\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0314 - mae: 643.0314\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2427 - mae: 642.2427\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7497 - mae: 641.7497\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 644.1663 - mae: 644.1663\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5115 - mae: 639.5115\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.9485 - mae: 645.9485\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.0164 - mae: 637.0164\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1146 - mae: 641.1146\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1886 - mae: 646.1886\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6208 - mae: 645.6208\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.8287 - mae: 647.8287\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.7590 - mae: 639.7590\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.8312 - mae: 640.8312\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3915 - mae: 643.3915\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.7084 - mae: 645.7084\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9119 - mae: 639.9119\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9773 - mae: 645.9773\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.8951 - mae: 643.8951\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.1842 - mae: 642.1842\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 650.7981 - mae: 650.7981\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.9547 - mae: 636.9547\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4905 - mae: 642.4905\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1090.7770 - mae: 1090.7770\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 904.3575 - mae: 904.3575\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 683.3725 - mae: 683.3725\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6455 - mae: 648.6455\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 649.6230 - mae: 649.6230\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7976 - mae: 645.7976\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2845 - mae: 643.2845\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.5504 - mae: 646.5504\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4177 - mae: 646.4177\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5875 - mae: 642.5875\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.7827 - mae: 639.7827\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8624 - mae: 647.8624\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8510 - mae: 642.8510\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.1344 - mae: 647.1344\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.3428 - mae: 648.3428\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0091 - mae: 638.0091\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9541 - mae: 640.9541\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7949 - mae: 640.7949\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5562 - mae: 642.5562\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5480 - mae: 644.5480\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.3022 - mae: 636.3022\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.7768 - mae: 642.7768\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.9725 - mae: 634.9725\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2423 - mae: 641.2423\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2189 - mae: 646.2189\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.5359 - mae: 638.5359\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8957 - mae: 643.8957\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8956 - mae: 643.8956\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.4948 - mae: 642.4948\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0016 - mae: 640.0016\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2978 - mae: 646.2978\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.2762 - mae: 641.2762\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7744 - mae: 642.7744\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8995 - mae: 647.8995\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7267 - mae: 641.7267\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5389 - mae: 641.5389\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6363 - mae: 643.6363\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9111 - mae: 640.9111\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.8461 - mae: 650.8461\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 637.6052 - mae: 637.6052\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8472 - mae: 642.8472\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7697 - mae: 636.7697\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.2163 - mae: 639.2163\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.0789 - mae: 645.0789\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3948 - mae: 642.3948\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8940 - mae: 641.8940\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8300 - mae: 643.8300\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6342 - mae: 645.6342\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.5153 - mae: 647.5153\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.6108 - mae: 636.6108\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5174 - mae: 642.5174\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.9221 - mae: 650.9221\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2780 - mae: 641.2780\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 649.5524 - mae: 649.5524\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7834 - mae: 638.7834\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6233 - mae: 642.6233\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 632.0724 - mae: 632.0724\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9168 - mae: 641.9168\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.6158 - mae: 636.6158\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.8674 - mae: 645.8674\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8094 - mae: 642.8094\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2953 - mae: 642.2953\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.5184 - mae: 645.5184\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.2084 - mae: 637.2084\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5204 - mae: 635.5204\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.8880 - mae: 634.8880\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3352 - mae: 642.3352\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.2809 - mae: 649.2809\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7066 - mae: 643.7066\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.7542 - mae: 641.7542\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.8983 - mae: 639.8983\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.1472 - mae: 651.1472\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8470 - mae: 644.8470\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.5592 - mae: 641.5592\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1318 - mae: 642.1318\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3818 - mae: 642.3818\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 646.1118 - mae: 646.1118\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.1190 - mae: 643.1190\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3964 - mae: 641.3964\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3158 - mae: 639.3158\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5621 - mae: 645.5621\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.6021 - mae: 641.6021\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.6273 - mae: 644.6273\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9078 - mae: 642.9078\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3340 - mae: 645.3340\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3300 - mae: 639.3300\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2576 - mae: 642.2576\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2112 - mae: 638.2112\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.6627 - mae: 630.6627\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.2020 - mae: 643.2020\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9683 - mae: 644.9683\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.5999 - mae: 643.5999\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5923 - mae: 635.5923\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.7352 - mae: 637.7352\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3801 - mae: 642.3801\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 650.2605 - mae: 650.2605\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2305 - mae: 635.2305\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4640 - mae: 640.4640\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 652.8398 - mae: 652.8398\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.5455 - mae: 648.5455\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1094.7449 - mae: 1094.7449\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 831.7552 - mae: 831.7552\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 652.5765 - mae: 652.5765\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.7762 - mae: 649.7762\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8516 - mae: 640.8516\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8243 - mae: 643.8243\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.2083 - mae: 639.2083\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 650.4542 - mae: 650.4542\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3544 - mae: 640.3544\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.1379 - mae: 635.1379\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.5904 - mae: 634.5904\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2216 - mae: 640.2216\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2371 - mae: 645.2371\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.4915 - mae: 637.4915\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.2128 - mae: 643.2128\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.9504 - mae: 641.9504\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.0661 - mae: 639.0661\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0035 - mae: 641.0035\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7610 - mae: 641.7610\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.8524 - mae: 639.8524\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.0025 - mae: 646.0025\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.1542 - mae: 635.1542\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7785 - mae: 641.7785\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.8186 - mae: 644.8186\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5515 - mae: 642.5515\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3369 - mae: 643.3369\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.1314 - mae: 640.1314\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7261 - mae: 640.7261\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.2557 - mae: 632.2557\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.9183 - mae: 635.9183\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.2585 - mae: 642.2585\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.2683 - mae: 642.2683\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.0760 - mae: 633.0760\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.3564 - mae: 645.3564\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3941 - mae: 643.3941\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7704 - mae: 639.7704\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6984 - mae: 637.6984\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.9409 - mae: 641.9409\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7672 - mae: 638.7672\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6304 - mae: 635.6304\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7776 - mae: 638.7776\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.0332 - mae: 635.0332\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7062 - mae: 640.7062\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.5625 - mae: 635.5625\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.6163 - mae: 634.6163\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2284 - mae: 641.2284\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1567 - mae: 639.1567\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.3105 - mae: 646.3105\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.9846 - mae: 637.9846\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.2524 - mae: 639.2524\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7050 - mae: 640.7050\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.4259 - mae: 648.4259\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 632.8357 - mae: 632.8357\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7915 - mae: 637.7915\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7236 - mae: 638.7236\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1941 - mae: 642.1941\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.1109 - mae: 637.1109\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.7072 - mae: 635.7072\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5812 - mae: 638.5812\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.5490 - mae: 635.5490\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.4652 - mae: 637.4652\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.4290 - mae: 645.4290\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0818 - mae: 640.0818\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8747 - mae: 636.8747\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2384 - mae: 642.2384\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4010 - mae: 641.4010\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.6063 - mae: 634.6063\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.3395 - mae: 640.3395\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.7990 - mae: 639.7990\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.5789 - mae: 639.5789\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.5490 - mae: 636.5490\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8300 - mae: 637.8300\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3130 - mae: 640.3130\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 634.4683 - mae: 634.4683\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.3618 - mae: 639.3618\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.0340 - mae: 639.0340\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.9006 - mae: 642.9006\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.4263 - mae: 640.4263\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0373 - mae: 640.0373\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.5620 - mae: 642.5620\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1832 - mae: 642.1832\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3730 - mae: 639.3730\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.7382 - mae: 638.7382\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.7943 - mae: 642.7943\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 635.8799 - mae: 635.8799\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.0901 - mae: 640.0901\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.9228 - mae: 632.9228\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5052 - mae: 642.5052\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5392 - mae: 644.5392\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.7457 - mae: 638.7457\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0050 - mae: 644.0050\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.9338 - mae: 638.9338\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.9840 - mae: 638.9840\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6602 - mae: 642.6602\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.1002 - mae: 643.1002\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4799 - mae: 643.4799\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5733 - mae: 634.5733\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 636.1224 - mae: 636.1224\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.2756 - mae: 639.2756\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.6326 - mae: 633.6326\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1101.3480 - mae: 1101.3480\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 842.7927 - mae: 842.7927\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 669.3122 - mae: 669.3122\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3315 - mae: 646.3315\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.0178 - mae: 646.0178\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.8654 - mae: 647.8654\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.1846 - mae: 645.1846\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4429 - mae: 644.4429\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6523 - mae: 642.6523\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.6203 - mae: 648.6203\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8542 - mae: 642.8542\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7368 - mae: 639.7368\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1252 - mae: 641.1252\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.2093 - mae: 645.2093\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.8493 - mae: 642.8493\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.2217 - mae: 643.2217\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.7350 - mae: 640.7350\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8646 - mae: 637.8646\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 633.0924 - mae: 633.0924\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.9230 - mae: 651.9230\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4628 - mae: 644.4628\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0884 - mae: 640.0884\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.7260 - mae: 648.7260\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5079 - mae: 647.5079\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5168 - mae: 638.5168\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 651.0731 - mae: 651.0731\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.2612 - mae: 648.2612\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0924 - mae: 645.0924\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.7505 - mae: 647.7505\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.5464 - mae: 649.5464\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7006 - mae: 641.7006\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 633.3538 - mae: 633.3538\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4223 - mae: 638.4223\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.7608 - mae: 641.7608\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1349 - mae: 639.1349\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9417 - mae: 642.9417\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.5515 - mae: 640.5515\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.6790 - mae: 639.6790\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4299 - mae: 645.4299\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.6678 - mae: 645.6678\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 651.5948 - mae: 651.5948\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 648.2934 - mae: 648.2934\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.9109 - mae: 635.9109\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4363 - mae: 644.4363\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4091 - mae: 641.4091\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7285 - mae: 643.7285\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6463 - mae: 643.6463\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7327 - mae: 640.7327\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.2367 - mae: 640.2367\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.6238 - mae: 645.6238\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7352 - mae: 645.7352\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3681 - mae: 643.3681\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.6068 - mae: 637.6068\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.7896 - mae: 639.7896\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3265 - mae: 645.3265\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.1917 - mae: 647.1917\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.5879 - mae: 644.5879\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 647.5194 - mae: 647.5194\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 635.1281 - mae: 635.1281\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.4354 - mae: 639.4354\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8113 - mae: 642.8113\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1703 - mae: 639.1703\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4918 - mae: 644.4918\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.7319 - mae: 641.7319\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.9158 - mae: 639.9158\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 635.7836 - mae: 635.7836\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3864 - mae: 643.3864\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6586 - mae: 643.6586\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.4201 - mae: 641.4201\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.5803 - mae: 646.5803\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8417 - mae: 643.8417\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8737 - mae: 645.8737\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.9977 - mae: 642.9977\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.2057 - mae: 646.2057\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.5819 - mae: 634.5819\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8519 - mae: 643.8519\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.6685 - mae: 643.6685\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.0392 - mae: 638.0392\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3985 - mae: 646.3985\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.1701 - mae: 639.1701\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.6848 - mae: 648.6848\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 635.3048 - mae: 635.3048\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.4177 - mae: 634.4177\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.1752 - mae: 637.1752\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.6360 - mae: 639.6360\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4242 - mae: 642.4242\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4377 - mae: 637.4377\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.3256 - mae: 644.3256\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.0493 - mae: 649.0493\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.9957 - mae: 641.9957\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.0026 - mae: 642.0026\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.7997 - mae: 644.7997\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 651.3475 - mae: 651.3475\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3243 - mae: 646.3243\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.5847 - mae: 647.5847\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8828 - mae: 645.8828\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.2627 - mae: 642.2627\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.2693 - mae: 645.2693\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3925 - mae: 643.3925\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.5371 - mae: 638.5371\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1081.2206 - mae: 1081.2206\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 823.4171 - mae: 823.4171\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 653.1614 - mae: 653.1614\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3915 - mae: 647.3915\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.7483 - mae: 647.7483\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.2061 - mae: 644.2061\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.9810 - mae: 645.9810\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0651 - mae: 640.0651\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6027 - mae: 641.6027\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.9789 - mae: 646.9789\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5392 - mae: 644.5392\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.8085 - mae: 642.8085\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.3619 - mae: 636.3619\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5840 - mae: 639.5840\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 644.0586 - mae: 644.0586\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8088 - mae: 642.8088\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9595 - mae: 640.9595\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6507 - mae: 636.6507\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.6061 - mae: 645.6061\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4941 - mae: 644.4941\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.8419 - mae: 640.8419\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.2140 - mae: 646.2140\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.9951 - mae: 645.9951\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5644 - mae: 640.5644\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8975 - mae: 635.8975\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.0350 - mae: 645.0350\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.6848 - mae: 640.6848\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.5910 - mae: 645.5910\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.8073 - mae: 649.8073\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.6845 - mae: 642.6845\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.1288 - mae: 644.1288\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.1916 - mae: 645.1916\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1819 - mae: 640.1819\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8163 - mae: 638.8163\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 647.6260 - mae: 647.6260\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.4923 - mae: 643.4923\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.4055 - mae: 641.4055\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 649.0486 - mae: 649.0486\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6223 - mae: 646.6223\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3967 - mae: 641.3967\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.0644 - mae: 642.0644\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.4648 - mae: 643.4648\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 653.9380 - mae: 653.9380\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.7004 - mae: 637.7004\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.5446 - mae: 643.5446\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 642.4966 - mae: 642.4966\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.3538 - mae: 643.3538\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.5033 - mae: 636.5033\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6823 - mae: 642.6823\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.3809 - mae: 642.3809\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1790 - mae: 639.1790\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8788 - mae: 643.8788\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.0316 - mae: 641.0316\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.5590 - mae: 634.5590\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7397 - mae: 642.7397\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0610 - mae: 646.0610\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4056 - mae: 643.4056\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.4617 - mae: 634.4617\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.3962 - mae: 639.3962\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.5570 - mae: 640.5570\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.1657 - mae: 638.1657\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 636.7125 - mae: 636.7125\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.0522 - mae: 645.0522\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.0968 - mae: 637.0968\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0579 - mae: 639.0579\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.6217 - mae: 640.6217\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.5815 - mae: 643.5815\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 641.8923 - mae: 641.8923\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.3768 - mae: 645.3768\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.0005 - mae: 644.0005\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.8992 - mae: 636.8992\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3406 - mae: 643.3406\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3000 - mae: 639.3000\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7037 - mae: 640.7037\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.1149 - mae: 643.1149\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.4148 - mae: 644.4148\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 645.7516 - mae: 645.7516\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.5085 - mae: 644.5085\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8243 - mae: 643.8243\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.1201 - mae: 640.1201\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.8854 - mae: 647.8854\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8768 - mae: 640.8768\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4764 - mae: 644.4764\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.3922 - mae: 637.3922\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 640.3030 - mae: 640.3030\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 646.1017 - mae: 646.1017\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 637.8633 - mae: 637.8633\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 639.1076 - mae: 639.1076\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4383 - mae: 640.4383\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5463 - mae: 639.5463\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2933 - mae: 641.2933\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 637.4072 - mae: 637.4072\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.5591 - mae: 641.5591\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 634.5061 - mae: 634.5061\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.4312 - mae: 638.4312\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 641.2748 - mae: 641.2748\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 643.8942 - mae: 643.8942\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5167 - mae: 643.5167\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3158 - mae: 643.3158\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.3391 - mae: 643.3391\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1061.0421 - mae: 1061.0421\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 706.4748 - mae: 706.4748\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 654.8163 - mae: 654.8163\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.8439 - mae: 643.8439\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2224 - mae: 646.2224\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6686 - mae: 641.6686\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.0974 - mae: 648.0974\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2865 - mae: 638.2865\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2866 - mae: 641.2866\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4116 - mae: 644.4116\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0563 - mae: 641.0563\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 638.3292 - mae: 638.3292\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.9008 - mae: 644.9008\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3652 - mae: 643.3652\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 638.4377 - mae: 638.4377\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.8659 - mae: 632.8659\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8693 - mae: 641.8693\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2952 - mae: 646.2952\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9381 - mae: 642.9381\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.5129 - mae: 638.5129\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6725 - mae: 637.6725\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6893 - mae: 639.6893\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7653 - mae: 640.7653\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7623 - mae: 641.7623\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3301 - mae: 640.3301\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9402 - mae: 642.9402\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6652 - mae: 639.6652\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.7433 - mae: 634.7433\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2792 - mae: 644.2792\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.0125 - mae: 636.0125\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.8340 - mae: 636.8340\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3636 - mae: 647.3636\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9197 - mae: 642.9197\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8784 - mae: 642.8784\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.2927 - mae: 638.2927\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.1544 - mae: 645.1544\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.8620 - mae: 634.8620\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5215 - mae: 635.5215\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.8973 - mae: 646.8973\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9780 - mae: 639.9780\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5692 - mae: 637.5692\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1886 - mae: 638.1886\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3685 - mae: 635.3685\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7420 - mae: 641.7420\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.8268 - mae: 629.8268\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1144 - mae: 640.1144\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7372 - mae: 635.7372\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.7919 - mae: 640.7919\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7465 - mae: 642.7465\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2457 - mae: 641.2457\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4485 - mae: 639.4485\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5372 - mae: 639.5372\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.0745 - mae: 638.0745\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.2747 - mae: 642.2747\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9382 - mae: 638.9382\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3293 - mae: 641.3293\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7131 - mae: 643.7131\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2505 - mae: 640.2505\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2501 - mae: 644.2501\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.3731 - mae: 634.3731\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.9537 - mae: 643.9537\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1544 - mae: 636.1544\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0216 - mae: 635.0216\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.6957 - mae: 645.6957\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.4929 - mae: 632.4929\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5042 - mae: 645.5042\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6514 - mae: 638.6514\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.8583 - mae: 637.8583\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4376 - mae: 640.4376\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5196 - mae: 639.5196\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2709 - mae: 640.2709\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2344 - mae: 642.2344\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8588 - mae: 642.8588\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 655.7787 - mae: 655.7787\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1096 - mae: 635.1096\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.0790 - mae: 640.0790\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6028 - mae: 640.6028\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3394 - mae: 637.3394\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7473 - mae: 639.7473\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.4856 - mae: 633.4856\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3535 - mae: 641.3535\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1272 - mae: 638.1272\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3837 - mae: 638.3837\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.9844 - mae: 640.9844\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8784 - mae: 640.8784\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2161 - mae: 647.2161\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1812 - mae: 640.1812\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2439 - mae: 636.2439\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4874 - mae: 642.4874\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8234 - mae: 639.8234\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2484 - mae: 641.2484\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.6054 - mae: 634.6054\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1198 - mae: 634.1198\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6107 - mae: 636.6107\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1531 - mae: 638.1531\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6741 - mae: 642.6741\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3611 - mae: 642.3611\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.7368 - mae: 648.7368\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9546 - mae: 639.9546\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5233 - mae: 639.5233\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1074.2788 - mae: 1074.2788\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 705.7584 - mae: 705.7584\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 649.2132 - mae: 649.2132\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.3151 - mae: 650.3151\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 652.5410 - mae: 652.5410\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4468 - mae: 645.4468\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4819 - mae: 643.4819\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 646.3542 - mae: 646.3542\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0401 - mae: 645.0401\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9528 - mae: 638.9528\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8171 - mae: 647.8171\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5783 - mae: 635.5783\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2755 - mae: 647.2755\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7934 - mae: 644.7934\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7776 - mae: 640.7776\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2515 - mae: 635.2515\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3657 - mae: 636.3657\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3206 - mae: 643.3206\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.5511 - mae: 632.5511\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.3995 - mae: 645.3995\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 643.1824 - mae: 643.1824\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.2820 - mae: 644.2820\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3738 - mae: 639.3738\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1795 - mae: 642.1795\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.3774 - mae: 635.3774\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1793 - mae: 644.1793\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6906 - mae: 644.6906\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5420 - mae: 640.5420\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8605 - mae: 640.8605\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.5083 - mae: 648.5083\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.7800 - mae: 648.7800\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4865 - mae: 645.4865\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4051 - mae: 637.4051\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9337 - mae: 646.9337\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6718 - mae: 641.6718\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4014 - mae: 647.4014\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4870 - mae: 642.4870\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7269 - mae: 645.7269\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2241 - mae: 647.2241\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.4871 - mae: 651.4871\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8312 - mae: 635.8312\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7997 - mae: 645.7997\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7957 - mae: 639.7957\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9040 - mae: 641.9040\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 645.7250 - mae: 645.7250\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4300 - mae: 637.4300\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7637 - mae: 642.7637\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7576 - mae: 646.7576\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1856 - mae: 647.1856\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1694 - mae: 639.1694\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.5506 - mae: 638.5506\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.2121 - mae: 642.2121\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.8875 - mae: 646.8875\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1439 - mae: 642.1439\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6486 - mae: 642.6486\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4158 - mae: 644.4158\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.1940 - mae: 644.1940\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5101 - mae: 636.5101\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 651.9796 - mae: 651.9796\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8845 - mae: 638.8845\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8892 - mae: 640.8892\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0065 - mae: 641.0065\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1283 - mae: 641.1283\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6718 - mae: 638.6718\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6580 - mae: 638.6580\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6924 - mae: 640.6924\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4642 - mae: 636.4642\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4232 - mae: 643.4232\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5663 - mae: 637.5663\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5706 - mae: 640.5706\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9294 - mae: 635.9294\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.0864 - mae: 650.0864\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6484 - mae: 641.6484\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1253 - mae: 645.1253\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4311 - mae: 638.4311\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 645.6592 - mae: 645.6592\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 644.6559 - mae: 644.6559\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2344 - mae: 642.2344\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2498 - mae: 643.2498\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7382 - mae: 640.7382\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0266 - mae: 643.0266\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9662 - mae: 640.9662\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6855 - mae: 639.6855\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1235 - mae: 638.1235\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4800 - mae: 641.4800\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0235 - mae: 645.0235\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.9536 - mae: 639.9536\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.6760 - mae: 642.6760\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4997 - mae: 638.4997\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6097 - mae: 641.6097\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.3771 - mae: 642.3771\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0445 - mae: 644.0445\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7037 - mae: 645.7037\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7006 - mae: 648.7006\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.2079 - mae: 643.2079\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.1124 - mae: 645.1124\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0628 - mae: 639.0628\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.4276 - mae: 642.4276\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.8818 - mae: 632.8818\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8477 - mae: 641.8477\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1056.4247 - mae: 1056.4247\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 703.0652 - mae: 703.0652\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 653.0029 - mae: 653.0029\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2764 - mae: 646.2764\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1830 - mae: 636.1830\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5215 - mae: 638.5215\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4125 - mae: 646.4125\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8341 - mae: 645.8341\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3159 - mae: 640.3159\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 641.7803 - mae: 641.7803\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.2424 - mae: 639.2424\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8686 - mae: 640.8686\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.8159 - mae: 649.8159\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6507 - mae: 637.6507\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2761 - mae: 636.2761\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3137 - mae: 638.3137\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0464 - mae: 641.0464\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0751 - mae: 634.0751\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1591 - mae: 642.1591\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6163 - mae: 641.6163\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4974 - mae: 649.4974\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0780 - mae: 644.0780\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4991 - mae: 643.4991\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9500 - mae: 643.9500\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7021 - mae: 648.7021\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9186 - mae: 646.9186\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2849 - mae: 645.2849\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.6879 - mae: 639.6879\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.0782 - mae: 634.0782\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.4030 - mae: 632.4030\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1098 - mae: 645.1098\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2736 - mae: 644.2736\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9952 - mae: 636.9952\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3050 - mae: 643.3050\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9220 - mae: 638.9220\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4247 - mae: 649.4247\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3840 - mae: 641.3840\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7649 - mae: 646.7649\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1301 - mae: 642.1301\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9083 - mae: 641.9083\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.7733 - mae: 640.7733\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.0329 - mae: 637.0329\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1155 - mae: 635.1155\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1622 - mae: 646.1622\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8662 - mae: 636.8662\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1768 - mae: 639.1768\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7961 - mae: 645.7961\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5297 - mae: 645.5297\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1217 - mae: 634.1217\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4502 - mae: 644.4502\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1315 - mae: 642.1315\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 638.0670 - mae: 638.0670\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9859 - mae: 642.9859\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.2240 - mae: 637.2240\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3167 - mae: 643.3167\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1977 - mae: 642.1977\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.8190 - mae: 644.8190\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3932 - mae: 644.3932\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9890 - mae: 642.9890\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5855 - mae: 642.5855\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.1849 - mae: 642.1849\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.2889 - mae: 649.2889\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.4510 - mae: 640.4510\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0249 - mae: 644.0249\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9564 - mae: 645.9564\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5276 - mae: 642.5276\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7512 - mae: 641.7512\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0723 - mae: 641.0723\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9398 - mae: 639.9398\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.6575 - mae: 647.6575\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6030 - mae: 641.6030\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.3571 - mae: 638.3571\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5037 - mae: 643.5037\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3181 - mae: 640.3181\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.0226 - mae: 648.0226\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4722 - mae: 643.4722\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6676 - mae: 640.6676\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5367 - mae: 636.5367\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.4136 - mae: 634.4136\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0576 - mae: 641.0576\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 642.7430 - mae: 642.7430\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5726 - mae: 641.5726\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4646 - mae: 639.4646\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4747 - mae: 640.4747\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1877 - mae: 642.1877\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.3383 - mae: 632.3383\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3491 - mae: 642.3491\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7219 - mae: 638.7219\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.6728 - mae: 649.6728\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5284 - mae: 642.5284\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4459 - mae: 641.4459\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6097 - mae: 641.6097\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5059 - mae: 641.5059\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5798 - mae: 637.5798\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3962 - mae: 640.3962\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7102 - mae: 646.7102\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2268 - mae: 640.2268\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8212 - mae: 640.8212\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8707 - mae: 634.8707\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2471 - mae: 638.2471\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1025.1470 - mae: 1025.1470\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.8432 - mae: 649.8432\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9201 - mae: 643.9201\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8561 - mae: 642.8561\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3497 - mae: 646.3497\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0728 - mae: 647.0728\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0993 - mae: 643.0993\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5449 - mae: 634.5449\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3932 - mae: 640.3932\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.9398 - mae: 639.9398\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.7921 - mae: 645.7921\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2969 - mae: 641.2969\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4111 - mae: 641.4111\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.6404 - mae: 640.6404\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8252 - mae: 642.8252\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7261 - mae: 640.7261\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.9066 - mae: 636.9066\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6041 - mae: 637.6041\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3190 - mae: 635.3190\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0277 - mae: 641.0277\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5748 - mae: 644.5748\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5153 - mae: 635.5153\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6407 - mae: 642.6407\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8533 - mae: 641.8533\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3865 - mae: 645.3865\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7904 - mae: 636.7904\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.1204 - mae: 635.1204\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1736 - mae: 645.1736\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2907 - mae: 644.2907\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.1128 - mae: 632.1128\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4951 - mae: 647.4951\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9420 - mae: 641.9420\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.0237 - mae: 637.0237\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9407 - mae: 634.9407\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7086 - mae: 641.7086\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1774 - mae: 638.1774\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8445 - mae: 638.8445\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1893 - mae: 641.1893\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7651 - mae: 641.7651\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3432 - mae: 641.3432\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.3833 - mae: 630.3833\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.5233 - mae: 633.5233\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7851 - mae: 637.7851\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1028 - mae: 641.1028\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9053 - mae: 634.9053\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7061 - mae: 645.7061\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.7765 - mae: 637.7765\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3695 - mae: 639.3695\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7226 - mae: 637.7226\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2537 - mae: 644.2537\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8645 - mae: 642.8645\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7289 - mae: 643.7289\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.5895 - mae: 642.5895\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0515 - mae: 643.0515\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6328 - mae: 636.6328\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.0062 - mae: 643.0062\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4341 - mae: 640.4341\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.3888 - mae: 633.3888\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3976 - mae: 637.3976\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8417 - mae: 639.8417\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.0858 - mae: 636.0858\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.4320 - mae: 635.4320\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.2470 - mae: 638.2470\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7708 - mae: 640.7708\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.6406 - mae: 639.6406\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.7951 - mae: 636.7951\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.1166 - mae: 634.1166\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7910 - mae: 642.7910\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6936 - mae: 641.6936\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0173 - mae: 643.0173\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2508 - mae: 640.2508\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0897 - mae: 640.0897\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.9966 - mae: 633.9966\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2125 - mae: 639.2125\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9073 - mae: 643.9073\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2234 - mae: 638.2234\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2336 - mae: 641.2336\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.8496 - mae: 629.8496\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1981 - mae: 638.1981\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2867 - mae: 641.2867\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3640 - mae: 645.3640\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1788 - mae: 638.1788\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9202 - mae: 640.9202\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0194 - mae: 640.0194\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.2740 - mae: 637.2740\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.5067 - mae: 630.5067\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6763 - mae: 638.6763\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1934 - mae: 635.1934\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0095 - mae: 638.0095\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0809 - mae: 637.0809\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5403 - mae: 643.5403\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0473 - mae: 645.0473\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9488 - mae: 635.9488\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2777 - mae: 641.2777\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5101 - mae: 634.5101\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2128 - mae: 643.2128\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.2052 - mae: 633.2052\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7034 - mae: 641.7034\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6925 - mae: 640.6925\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2551 - mae: 639.2551\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1021.7589 - mae: 1021.7589\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.7300 - mae: 647.7300\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9675 - mae: 646.9675\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.0457 - mae: 651.0457\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.6889 - mae: 647.6889\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.7538 - mae: 641.7538\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9126 - mae: 642.9126\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.6526 - mae: 648.6526\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.0408 - mae: 647.0408\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.3862 - mae: 647.3862\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.6740 - mae: 647.6740\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2932 - mae: 644.2932\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7387 - mae: 643.7387\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7858 - mae: 641.7858\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8295 - mae: 638.8295\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8299 - mae: 645.8299\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8451 - mae: 642.8451\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8987 - mae: 636.8987\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.8974 - mae: 651.8974\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8959 - mae: 641.8959\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5660 - mae: 639.5660\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.2017 - mae: 648.2017\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3120 - mae: 647.3120\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6663 - mae: 644.6663\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 651.9965 - mae: 651.9965\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.0904 - mae: 649.0904\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.6628 - mae: 642.6628\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7593 - mae: 645.7593\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4932 - mae: 639.4932\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7014 - mae: 641.7014\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.5558 - mae: 642.5558\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.3452 - mae: 647.3452\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.2913 - mae: 639.2913\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4344 - mae: 646.4344\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5710 - mae: 641.5710\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.7617 - mae: 650.7617\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.4717 - mae: 633.4717\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.7027 - mae: 641.7027\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9112 - mae: 645.9112\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5026 - mae: 642.5026\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8391 - mae: 643.8391\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8405 - mae: 640.8405\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7136 - mae: 640.7136\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.8941 - mae: 646.8941\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4650 - mae: 642.4650\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2508 - mae: 638.2508\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7135 - mae: 643.7135\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.4747 - mae: 643.4747\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0805 - mae: 641.0805\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7333 - mae: 645.7333\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9352 - mae: 640.9352\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.6927 - mae: 646.6927\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0118 - mae: 637.0118\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8552 - mae: 639.8552\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.0058 - mae: 642.0058\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7391 - mae: 642.7391\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8383 - mae: 639.8383\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5114 - mae: 641.5114\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4043 - mae: 637.4043\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 654.4525 - mae: 654.4525\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8275 - mae: 643.8275\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1092 - mae: 643.1092\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0784 - mae: 640.0784\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1741 - mae: 640.1741\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.6111 - mae: 649.6111\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.8044 - mae: 647.8044\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5128 - mae: 643.5128\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0118 - mae: 642.0118\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6213 - mae: 638.6213\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1491 - mae: 641.1491\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2098 - mae: 643.2098\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1693 - mae: 642.1693\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9598 - mae: 645.9598\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8042 - mae: 643.8042\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9717 - mae: 637.9717\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4076 - mae: 639.4076\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6167 - mae: 637.6167\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5391 - mae: 641.5391\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7874 - mae: 643.7874\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1834 - mae: 636.1834\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7180 - mae: 645.7180\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6536 - mae: 640.6536\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4013 - mae: 642.4013\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9413 - mae: 639.9413\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6312 - mae: 638.6312\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7864 - mae: 638.7864\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1998 - mae: 646.1998\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1948 - mae: 635.1948\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3828 - mae: 645.3828\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3798 - mae: 638.3798\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.7143 - mae: 649.7143\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1816 - mae: 640.1816\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2113 - mae: 642.2113\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.9232 - mae: 647.9232\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.8924 - mae: 634.8924\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3529 - mae: 642.3529\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9561 - mae: 642.9561\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0154 - mae: 636.0154\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5056 - mae: 643.5056\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.9655 - mae: 644.9655\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 1027.7314 - mae: 1027.7314\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.3266 - mae: 650.3266\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3638 - mae: 647.3638\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2692 - mae: 647.2692\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.5806 - mae: 648.5806\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5680 - mae: 644.5680\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9376 - mae: 646.9376\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8178 - mae: 642.8178\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6979 - mae: 637.6979\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4234 - mae: 638.4234\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8746 - mae: 643.8746\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7426 - mae: 639.7426\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2686 - mae: 640.2686\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4016 - mae: 645.4016\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7869 - mae: 641.7869\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3102 - mae: 642.3102\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.7645 - mae: 645.7645\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.5933 - mae: 641.5933\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0252 - mae: 643.0252\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.6602 - mae: 649.6602\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 644.7442 - mae: 644.7442\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 634.9003 - mae: 634.9003\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1155 - mae: 639.1155\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4792 - mae: 641.4792\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.5299 - mae: 633.5299\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7851 - mae: 643.7851\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.6039 - mae: 634.6039\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.6495 - mae: 639.6495\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4625 - mae: 643.4625\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7736 - mae: 642.7736\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8899 - mae: 634.8899\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 639.2221 - mae: 639.2221\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.1719 - mae: 647.1719\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9007 - mae: 639.9007\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7981 - mae: 642.7981\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4550 - mae: 640.4550\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3930 - mae: 638.3930\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.4758 - mae: 648.4758\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0534 - mae: 638.0534\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1882 - mae: 635.1882\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4211 - mae: 641.4211\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9688 - mae: 643.9688\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0989 - mae: 640.0989\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 644.4701 - mae: 644.4701\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6891 - mae: 642.6891\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7835 - mae: 642.7835\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.5369 - mae: 645.5369\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0587 - mae: 640.0587\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7714 - mae: 646.7714\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4953 - mae: 645.4953\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7299 - mae: 643.7299\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9748 - mae: 637.9748\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.0275 - mae: 646.0275\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2589 - mae: 639.2589\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8962 - mae: 642.8962\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0845 - mae: 646.0845\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9595 - mae: 640.9595\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.8780 - mae: 649.8780\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9698 - mae: 635.9698\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8587 - mae: 645.8587\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 640.1214 - mae: 640.1214\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1769 - mae: 643.1769\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8608 - mae: 638.8608\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3058 - mae: 639.3058\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.2762 - mae: 637.2762\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.4291 - mae: 635.4291\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.5235 - mae: 631.5235\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4637 - mae: 640.4637\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1462 - mae: 640.1462\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7039 - mae: 645.7039\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3507 - mae: 641.3507\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.0641 - mae: 645.0641\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.1173 - mae: 640.1173\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0097 - mae: 636.0097\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.4589 - mae: 634.4589\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7466 - mae: 643.7466\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7266 - mae: 639.7266\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2721 - mae: 643.2721\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5428 - mae: 637.5428\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1636 - mae: 637.1636\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5936 - mae: 638.5936\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5105 - mae: 635.5105\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4064 - mae: 640.4064\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3865 - mae: 649.3865\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2316 - mae: 646.2316\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6172 - mae: 640.6172\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3030 - mae: 641.3030\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8367 - mae: 639.8367\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.3518 - mae: 647.3518\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7996 - mae: 635.7996\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.5720 - mae: 637.5720\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.8403 - mae: 634.8403\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 633.3563 - mae: 633.3563\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8067 - mae: 641.8067\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6193 - mae: 636.6193\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.4133 - mae: 647.4133\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 639.8415 - mae: 639.8415\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 643.5679 - mae: 643.5679\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0928 - mae: 641.0928\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.6934 - mae: 639.6934\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 991.6096 - mae: 991.6096\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.4159 - mae: 641.4159\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2609 - mae: 642.2609\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0458 - mae: 644.0458\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2620 - mae: 642.2620\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.3018 - mae: 641.3018\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2897 - mae: 638.2897\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2850 - mae: 636.2850\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1478 - mae: 645.1478\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5130 - mae: 640.5130\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8758 - mae: 638.8758\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0280 - mae: 644.0280\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6689 - mae: 640.6689\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9454 - mae: 636.9454\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5855 - mae: 639.5855\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1469 - mae: 634.1469\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4234 - mae: 640.4234\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7377 - mae: 641.7377\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.7402 - mae: 643.7402\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8984 - mae: 642.8984\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5860 - mae: 642.5860\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7960 - mae: 640.7960\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4163 - mae: 643.4163\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6507 - mae: 641.6507\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9261 - mae: 637.9261\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9898 - mae: 637.9898\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4671 - mae: 638.4671\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9490 - mae: 645.9490\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9617 - mae: 642.9617\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6820 - mae: 641.6820\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8531 - mae: 638.8531\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7769 - mae: 643.7769\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4849 - mae: 644.4849\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.8406 - mae: 632.8406\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0335 - mae: 638.0335\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1405 - mae: 641.1405\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6922 - mae: 641.6922\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.5770 - mae: 636.5770\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5737 - mae: 641.5737\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.2668 - mae: 649.2668\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.0667 - mae: 648.0667\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5161 - mae: 635.5161\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0719 - mae: 642.0719\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5919 - mae: 642.5919\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7245 - mae: 640.7245\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0701 - mae: 638.0701\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0272 - mae: 644.0272\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1622 - mae: 635.1622\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7662 - mae: 635.7662\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3212 - mae: 641.3212\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5924 - mae: 637.5924\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9504 - mae: 641.9504\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.5339 - mae: 650.5339\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8506 - mae: 642.8506\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.7120 - mae: 633.7120\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 633.6660 - mae: 633.6660\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7516 - mae: 641.7516\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6147 - mae: 644.6147\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4122 - mae: 642.4122\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2380 - mae: 644.2380\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4623 - mae: 644.4623\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8671 - mae: 642.8671\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0931 - mae: 641.0931\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9431 - mae: 634.9431\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7812 - mae: 643.7812\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7578 - mae: 637.7578\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6787 - mae: 635.6787\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1164 - mae: 642.1164\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5277 - mae: 640.5277\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4163 - mae: 641.4163\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3113 - mae: 638.3113\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3057 - mae: 637.3057\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6777 - mae: 640.6777\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6564 - mae: 642.6564\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2736 - mae: 643.2736\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6299 - mae: 641.6299\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.3151 - mae: 631.3151\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.4665 - mae: 634.4665\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8507 - mae: 639.8507\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3942 - mae: 641.3942\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.0096 - mae: 643.0096\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.2230 - mae: 642.2230\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 633.9323 - mae: 633.9323\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.6186 - mae: 634.6186\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2661 - mae: 638.2661\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0985 - mae: 641.0985\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3201 - mae: 641.3201\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5694 - mae: 636.5694\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2887 - mae: 638.2887\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7817 - mae: 641.7817\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4471 - mae: 641.4471\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6346 - mae: 638.6346\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3741 - mae: 639.3741\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5444 - mae: 641.5444\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8303 - mae: 642.8303\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2545 - mae: 638.2545\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7149 - mae: 636.7149\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.8699 - mae: 633.8699\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0091 - mae: 640.0091\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2145 - mae: 636.2145\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1005.9147 - mae: 1005.9147\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.3481 - mae: 650.3481\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 649.8939 - mae: 649.8939\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.4654 - mae: 650.4654\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2869 - mae: 647.2869\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3358 - mae: 641.3358\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0331 - mae: 637.0331\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9183 - mae: 641.9183\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9545 - mae: 645.9545\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.2747 - mae: 645.2747\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 649.1243 - mae: 649.1243\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.3601 - mae: 648.3601\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.0203 - mae: 642.0203\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4597 - mae: 645.4597\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.6567 - mae: 648.6567\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5779 - mae: 640.5779\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6893 - mae: 640.6893\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0137 - mae: 643.0137\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8927 - mae: 643.8927\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9446 - mae: 641.9446\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6530 - mae: 643.6530\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5627 - mae: 638.5627\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3160 - mae: 641.3160\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.0220 - mae: 648.0220\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7597 - mae: 643.7597\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1964 - mae: 635.1964\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.5315 - mae: 646.5315\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7621 - mae: 648.7621\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9525 - mae: 642.9525\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7559 - mae: 644.7559\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.9344 - mae: 652.9344\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4941 - mae: 645.4941\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9063 - mae: 645.9063\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4816 - mae: 646.4816\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9714 - mae: 646.9714\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0163 - mae: 643.0163\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7903 - mae: 645.7903\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6904 - mae: 642.6904\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7521 - mae: 645.7521\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8712 - mae: 634.8712\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9844 - mae: 645.9844\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2684 - mae: 643.2684\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0991 - mae: 636.0991\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.4072 - mae: 636.4072\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4117 - mae: 643.4117\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5931 - mae: 639.5931\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4097 - mae: 643.4097\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2539 - mae: 648.2539\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2616 - mae: 643.2616\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1531 - mae: 643.1531\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.3111 - mae: 643.3111\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0822 - mae: 641.0822\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.8815 - mae: 633.8815\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8638 - mae: 641.8638\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.7845 - mae: 646.7845\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.0736 - mae: 636.0736\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1476 - mae: 641.1476\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2171 - mae: 642.2171\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3359 - mae: 643.3359\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9615 - mae: 642.9615\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2465 - mae: 643.2465\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4191 - mae: 645.4191\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5934 - mae: 641.5934\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3553 - mae: 644.3553\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9990 - mae: 640.9990\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6423 - mae: 640.6423\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.6335 - mae: 639.6335\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8738 - mae: 643.8738\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.5543 - mae: 646.5543\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.1997 - mae: 636.1997\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 653.6564 - mae: 653.6564\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4766 - mae: 644.4766\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4613 - mae: 639.4613\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4122 - mae: 640.4122\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0294 - mae: 643.0294\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3486 - mae: 637.3486\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7568 - mae: 645.7568\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4544 - mae: 638.4544\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.0433 - mae: 647.0433\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6855 - mae: 637.6855\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2130 - mae: 644.2130\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2742 - mae: 644.2742\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8370 - mae: 636.8370\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3196 - mae: 643.3196\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4448 - mae: 640.4448\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0926 - mae: 646.0926\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.2791 - mae: 650.2791\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6734 - mae: 645.6734\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.5616 - mae: 647.5616\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1277 - mae: 646.1277\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5322 - mae: 644.5322\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1303 - mae: 641.1303\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7562 - mae: 643.7562\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6891 - mae: 640.6891\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.8444 - mae: 648.8444\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7629 - mae: 641.7629\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5769 - mae: 639.5769\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1428 - mae: 644.1428\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9578 - mae: 641.9578\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.3755 - mae: 638.3755\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1017.8419 - mae: 1017.8419\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2135 - mae: 646.2135\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4635 - mae: 642.4635\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.8621 - mae: 638.8621\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3712 - mae: 642.3712\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0176 - mae: 639.0176\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1891 - mae: 646.1891\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2711 - mae: 641.2711\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3106 - mae: 636.3106\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5057 - mae: 634.5057\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.9141 - mae: 648.9141\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1202 - mae: 637.1202\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6481 - mae: 636.6481\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8334 - mae: 646.8334\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9623 - mae: 637.9623\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8179 - mae: 641.8179\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4888 - mae: 646.4888\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7839 - mae: 645.7839\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6257 - mae: 643.6257\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3723 - mae: 638.3723\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 652.0484 - mae: 652.0484\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.3102 - mae: 634.3102\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.9692 - mae: 644.9692\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4907 - mae: 643.4907\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5787 - mae: 645.5787\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.8557 - mae: 650.8557\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4074 - mae: 644.4074\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9709 - mae: 638.9709\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8150 - mae: 642.8150\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1730 - mae: 641.1730\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6382 - mae: 643.6382\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2886 - mae: 640.2886\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5695 - mae: 641.5695\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6186 - mae: 636.6186\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1252 - mae: 643.1252\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4020 - mae: 638.4020\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.1459 - mae: 641.1459\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9754 - mae: 646.9754\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7880 - mae: 641.7880\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.3074 - mae: 640.3074\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5106 - mae: 637.5106\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5189 - mae: 638.5189\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2020 - mae: 640.2020\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1156 - mae: 642.1156\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.1263 - mae: 645.1263\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0143 - mae: 642.0143\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7216 - mae: 642.7216\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3904 - mae: 641.3904\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9078 - mae: 638.9078\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.6976 - mae: 641.6976\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3093 - mae: 637.3093\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3845 - mae: 638.3845\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1498 - mae: 637.1498\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7708 - mae: 637.7708\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3892 - mae: 646.3892\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4057 - mae: 646.4057\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7482 - mae: 642.7482\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3943 - mae: 644.3943\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.2109 - mae: 643.2109\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7737 - mae: 640.7737\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3585 - mae: 643.3585\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6670 - mae: 638.6670\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8417 - mae: 637.8417\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2411 - mae: 642.2411\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2426 - mae: 640.2426\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.7344 - mae: 642.7344\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3633 - mae: 635.3633\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3330 - mae: 643.3330\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3710 - mae: 641.3710\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9154 - mae: 646.9154\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.4661 - mae: 651.4661\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3226 - mae: 638.3226\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8854 - mae: 635.8854\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9959 - mae: 642.9959\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9230 - mae: 642.9230\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4541 - mae: 638.4541\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9537 - mae: 635.9537\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.8070 - mae: 642.8070\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6360 - mae: 640.6360\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6707 - mae: 641.6707\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9047 - mae: 639.9047\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.4802 - mae: 635.4802\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6085 - mae: 642.6085\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6120 - mae: 641.6120\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.9822 - mae: 642.9822\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.0825 - mae: 648.0825\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1647 - mae: 641.1647\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1528 - mae: 640.1528\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.8369 - mae: 642.8369\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3809 - mae: 642.3809\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9231 - mae: 640.9231\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.8832 - mae: 639.8832\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9095 - mae: 642.9095\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8810 - mae: 644.8810\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7983 - mae: 641.7983\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3725 - mae: 642.3725\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9897 - mae: 638.9897\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.6041 - mae: 642.6041\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8142 - mae: 645.8142\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6055 - mae: 642.6055\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 915.2590 - mae: 915.2590\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6889 - mae: 643.6889\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8998 - mae: 641.8998\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0236 - mae: 637.0236\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5085 - mae: 639.5085\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2592 - mae: 639.2592\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.5809 - mae: 630.5809\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6622 - mae: 638.6622\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5644 - mae: 635.5644\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4468 - mae: 639.4468\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0131 - mae: 641.0131\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6370 - mae: 635.6370\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.6759 - mae: 647.6759\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.4033 - mae: 635.4033\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5123 - mae: 635.5123\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7991 - mae: 645.7991\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0641 - mae: 641.0641\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 632.4868 - mae: 632.4868\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.7207 - mae: 631.7207\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3920 - mae: 642.3920\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.6270 - mae: 638.6270\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5117 - mae: 640.5117\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5295 - mae: 641.5295\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3222 - mae: 644.3222\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.9241 - mae: 631.9241\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.2974 - mae: 639.2974\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7153 - mae: 645.7153\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3517 - mae: 635.3517\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.1835 - mae: 649.1835\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.6158 - mae: 640.6158\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9078 - mae: 642.9078\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2473 - mae: 641.2473\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7677 - mae: 641.7677\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5611 - mae: 637.5611\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7311 - mae: 646.7311\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.0848 - mae: 642.0848\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1981 - mae: 637.1981\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2829 - mae: 639.2829\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3389 - mae: 642.3389\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0986 - mae: 643.0986\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6939 - mae: 639.6939\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6912 - mae: 640.6912\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3942 - mae: 642.3942\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0246 - mae: 642.0246\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.5170 - mae: 633.5170\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5354 - mae: 645.5354\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9424 - mae: 639.9424\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4055 - mae: 642.4055\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2502 - mae: 635.2502\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.1444 - mae: 639.1444\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5131 - mae: 639.5131\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8697 - mae: 644.8697\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3392 - mae: 641.3392\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0212 - mae: 638.0212\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3591 - mae: 637.3591\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8228 - mae: 645.8228\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2405 - mae: 641.2405\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6423 - mae: 641.6423\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5272 - mae: 637.5272\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.2771 - mae: 640.2771\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.3906 - mae: 634.3906\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.7062 - mae: 632.7062\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0608 - mae: 636.0608\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.9077 - mae: 638.9077\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.4111 - mae: 637.4111\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.4995 - mae: 640.4995\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5635 - mae: 641.5635\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4017 - mae: 645.4017\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8907 - mae: 641.8907\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.4421 - mae: 634.4421\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4439 - mae: 642.4439\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.8589 - mae: 643.8589\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4777 - mae: 637.4777\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8596 - mae: 638.8596\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8781 - mae: 640.8781\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8113 - mae: 642.8113\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4166 - mae: 640.4166\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.4157 - mae: 643.4157\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6674 - mae: 637.6674\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2487 - mae: 641.2487\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.4078 - mae: 639.4078\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0138 - mae: 635.0138\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6858 - mae: 637.6858\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6738 - mae: 637.6738\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.1738 - mae: 631.1738\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3923 - mae: 636.3923\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.3731 - mae: 631.3731\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7551 - mae: 638.7551\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5413 - mae: 634.5413\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8447 - mae: 645.8447\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.1561 - mae: 631.1561\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.8871 - mae: 632.8871\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9968 - mae: 639.9968\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.8713 - mae: 632.8713\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0715 - mae: 640.0715\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9878 - mae: 639.9878\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3076 - mae: 638.3076\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3456 - mae: 635.3456\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7033 - mae: 636.7033\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4575 - mae: 637.4575\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 945.6989 - mae: 945.6989\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.7562 - mae: 648.7562\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9402 - mae: 646.9402\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.9891 - mae: 648.9891\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.6068 - mae: 650.6068\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9358 - mae: 645.9358\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.2610 - mae: 648.2610\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4571 - mae: 644.4571\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8782 - mae: 641.8782\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0031 - mae: 637.0031\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6110 - mae: 645.6110\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4213 - mae: 641.4213\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9578 - mae: 640.9578\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9778 - mae: 643.9778\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.0880 - mae: 651.0880\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 648.1675 - mae: 648.1675\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1879 - mae: 640.1879\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3011 - mae: 642.3011\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8420 - mae: 640.8420\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8830 - mae: 644.8830\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5124 - mae: 637.5124\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.5830 - mae: 648.5830\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.6875 - mae: 648.6875\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.3542 - mae: 648.3542\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5217 - mae: 639.5217\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7111 - mae: 640.7111\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9083 - mae: 637.9083\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.3303 - mae: 637.3303\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2572 - mae: 639.2572\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9814 - mae: 642.9814\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9052 - mae: 646.9052\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9986 - mae: 644.9986\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5969 - mae: 639.5969\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.0996 - mae: 649.0996\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.8868 - mae: 648.8868\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 654.0775 - mae: 654.0775\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2585 - mae: 643.2585\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7738 - mae: 641.7738\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.2837 - mae: 646.2837\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2015 - mae: 642.2015\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4150 - mae: 647.4150\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0301 - mae: 644.0301\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8645 - mae: 644.8645\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6127 - mae: 645.6127\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3383 - mae: 645.3383\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9460 - mae: 646.9460\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5082 - mae: 641.5082\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.5559 - mae: 652.5559\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1381 - mae: 641.1381\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.3945 - mae: 648.3945\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3177 - mae: 643.3177\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8355 - mae: 647.8355\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5524 - mae: 647.5524\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3231 - mae: 640.3231\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.4076 - mae: 647.4076\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0101 - mae: 645.0101\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3885 - mae: 646.3885\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8972 - mae: 645.8972\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4348 - mae: 641.4348\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9327 - mae: 641.9327\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6527 - mae: 646.6527\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8086 - mae: 639.8086\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1890 - mae: 642.1890\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5946 - mae: 645.5946\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0622 - mae: 644.0622\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.8772 - mae: 645.8772\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3496 - mae: 641.3496\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1249 - mae: 644.1249\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1335 - mae: 643.1335\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.8297 - mae: 635.8297\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7957 - mae: 643.7957\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1154 - mae: 640.1154\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.3851 - mae: 633.3851\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.0668 - mae: 633.0668\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7367 - mae: 642.7367\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3089 - mae: 642.3089\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8165 - mae: 646.8165\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.5778 - mae: 639.5778\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.3480 - mae: 633.3480\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.5905 - mae: 649.5905\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8700 - mae: 637.8700\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8334 - mae: 636.8334\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7148 - mae: 639.7148\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2379 - mae: 642.2379\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8342 - mae: 643.8342\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.6960 - mae: 645.6960\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4702 - mae: 639.4702\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0998 - mae: 645.0998\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9938 - mae: 644.9938\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9695 - mae: 645.9695\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9760 - mae: 641.9760\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9739 - mae: 639.9739\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.0029 - mae: 641.0029\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2391 - mae: 648.2391\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.3564 - mae: 647.3564\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.8678 - mae: 639.8678\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7979 - mae: 643.7979\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6953 - mae: 639.6953\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5900 - mae: 645.5900\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.8967 - mae: 644.8967\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 919.5512 - mae: 919.5512\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 652.9208 - mae: 652.9208\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.6681 - mae: 647.6681\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.1169 - mae: 647.1169\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8836 - mae: 638.8836\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1835 - mae: 644.1835\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.2941 - mae: 637.2941\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1860 - mae: 641.1860\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4101 - mae: 644.4101\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4100 - mae: 642.4100\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5887 - mae: 640.5887\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4383 - mae: 644.4383\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8047 - mae: 646.8047\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7425 - mae: 643.7425\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8049 - mae: 647.8049\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.0620 - mae: 639.0620\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6322 - mae: 643.6322\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7238 - mae: 641.7238\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 634.7739 - mae: 634.7739\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3262 - mae: 639.3262\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4023 - mae: 642.4023\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.4765 - mae: 649.4765\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3436 - mae: 638.3436\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1695 - mae: 641.1695\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3972 - mae: 639.3972\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.8502 - mae: 651.8502\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2566 - mae: 647.2566\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9888 - mae: 642.9888\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1209 - mae: 648.1209\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0773 - mae: 643.0773\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3433 - mae: 639.3433\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.1377 - mae: 645.1377\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3521 - mae: 637.3521\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7615 - mae: 645.7615\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3395 - mae: 640.3395\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9216 - mae: 641.9216\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.8160 - mae: 649.8160\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6629 - mae: 642.6629\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9305 - mae: 638.9305\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9315 - mae: 641.9315\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1484 - mae: 644.1484\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7670 - mae: 641.7670\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 639.3755 - mae: 639.3755\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6491 - mae: 642.6491\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5845 - mae: 645.5845\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1885 - mae: 642.1885\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2434 - mae: 642.2434\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8464 - mae: 642.8464\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6830 - mae: 641.6830\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8365 - mae: 644.8365\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6608 - mae: 638.6608\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.7973 - mae: 644.7973\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2083 - mae: 639.2083\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9675 - mae: 638.9675\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5371 - mae: 642.5371\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3409 - mae: 643.3409\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8798 - mae: 639.8798\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 647.9027 - mae: 647.9027\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.1658 - mae: 633.1658\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4027 - mae: 641.4027\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1987 - mae: 637.1987\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2699 - mae: 643.2699\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5197 - mae: 637.5197\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9966 - mae: 638.9966\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5419 - mae: 639.5419\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1289 - mae: 639.1289\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6402 - mae: 641.6402\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3753 - mae: 643.3753\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.7676 - mae: 647.7676\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7242 - mae: 645.7242\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.0198 - mae: 639.0198\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.0732 - mae: 645.0732\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4865 - mae: 646.4865\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1444 - mae: 646.1444\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0102 - mae: 643.0102\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6626 - mae: 636.6626\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1240 - mae: 643.1240\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5638 - mae: 640.5638\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5146 - mae: 644.5146\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9242 - mae: 638.9242\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0926 - mae: 644.0926\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8265 - mae: 641.8265\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.8565 - mae: 635.8565\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5175 - mae: 640.5175\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9531 - mae: 642.9531\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5724 - mae: 641.5724\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7144 - mae: 642.7144\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0532 - mae: 639.0532\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.2755 - mae: 645.2755\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4012 - mae: 645.4012\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5944 - mae: 641.5944\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.5864 - mae: 635.5864\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2589 - mae: 635.2589\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1868 - mae: 636.1868\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8328 - mae: 641.8328\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2553 - mae: 640.2553\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.7766 - mae: 636.7766\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6530 - mae: 643.6530\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1630 - mae: 642.1630\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3088 - mae: 642.3088\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 870.2166 - mae: 870.2166\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.5239 - mae: 640.5239\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6039 - mae: 636.6039\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3804 - mae: 640.3804\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.2758 - mae: 639.2758\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2158 - mae: 638.2158\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1688 - mae: 641.1688\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3987 - mae: 636.3987\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8915 - mae: 647.8915\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8277 - mae: 639.8277\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1265 - mae: 639.1265\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6016 - mae: 641.6016\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1578 - mae: 643.1578\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.3752 - mae: 637.3752\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5886 - mae: 639.5886\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.5448 - mae: 640.5448\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9640 - mae: 643.9640\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0258 - mae: 638.0258\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0142 - mae: 640.0142\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.7564 - mae: 643.7564\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4056 - mae: 640.4056\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.6684 - mae: 638.6684\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3316 - mae: 641.3316\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5320 - mae: 639.5320\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.4765 - mae: 648.4765\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 643.5068 - mae: 643.5068\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1009 - mae: 642.1009\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7953 - mae: 639.7953\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1544 - mae: 640.1544\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.0040 - mae: 642.0040\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0779 - mae: 643.0779\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4691 - mae: 644.4691\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.2718 - mae: 645.2718\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2159 - mae: 641.2159\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1016 - mae: 640.1016\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3314 - mae: 644.3314\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6130 - mae: 639.6130\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.0721 - mae: 635.0721\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1857 - mae: 644.1857\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6796 - mae: 636.6796\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2926 - mae: 639.2926\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 636.3644 - mae: 636.3644\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3443 - mae: 639.3443\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2429 - mae: 640.2429\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.9413 - mae: 632.9413\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2014 - mae: 641.2014\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8768 - mae: 642.8768\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2187 - mae: 637.2187\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0692 - mae: 644.0692\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5237 - mae: 643.5237\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6407 - mae: 638.6407\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9452 - mae: 641.9452\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.8630 - mae: 631.8630\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3623 - mae: 635.3623\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4846 - mae: 642.4846\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9177 - mae: 634.9177\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9968 - mae: 641.9968\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5480 - mae: 640.5480\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2715 - mae: 641.2715\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6182 - mae: 640.6182\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7271 - mae: 638.7271\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 638.7974 - mae: 638.7974\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0867 - mae: 642.0867\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6247 - mae: 641.6247\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0668 - mae: 644.0668\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1614 - mae: 636.1614\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2825 - mae: 643.2825\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9227 - mae: 638.9227\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0605 - mae: 639.0605\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6916 - mae: 642.6916\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.3145 - mae: 641.3145\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3578 - mae: 639.3578\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1717 - mae: 643.1717\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8602 - mae: 640.8602\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.3318 - mae: 635.3318\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6063 - mae: 636.6063\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4738 - mae: 636.4738\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.1465 - mae: 640.1465\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4174 - mae: 640.4174\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5611 - mae: 637.5611\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5969 - mae: 638.5969\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.2979 - mae: 632.2979\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.4844 - mae: 637.4844\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.7518 - mae: 640.7518\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3231 - mae: 635.3231\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2361 - mae: 642.2361\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4829 - mae: 646.4829\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.4011 - mae: 645.4011\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.7198 - mae: 634.7198\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3674 - mae: 639.3674\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0676 - mae: 635.0676\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.0059 - mae: 636.0059\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3823 - mae: 635.3823\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3217 - mae: 635.3217\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3492 - mae: 640.3492\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.6068 - mae: 638.6068\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.1556 - mae: 635.1556\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.5261 - mae: 630.5261\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.5873 - mae: 631.5873\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 650.8811 - mae: 650.8811\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 860.9266 - mae: 860.9266\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.5367 - mae: 649.5367\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3379 - mae: 645.3379\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 647.6568 - mae: 647.6568\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.7714 - mae: 644.7714\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5497 - mae: 642.5497\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0391 - mae: 643.0391\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 649.0404 - mae: 649.0404\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2583 - mae: 642.2583\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3044 - mae: 646.3044\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0560 - mae: 646.0560\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.5630 - mae: 646.5630\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.9171 - mae: 648.9171\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1605 - mae: 642.1605\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.8264 - mae: 641.8264\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.6790 - mae: 647.6790\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8317 - mae: 641.8317\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8262 - mae: 646.8262\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2819 - mae: 639.2819\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 650.9188 - mae: 650.9188\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6542 - mae: 642.6542\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9519 - mae: 643.9519\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1808 - mae: 646.1808\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 632.8420 - mae: 632.8420\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9956 - mae: 644.9956\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0034 - mae: 646.0034\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0569 - mae: 643.0569\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0975 - mae: 643.0975\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4489 - mae: 646.4489\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4745 - mae: 637.4745\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7808 - mae: 642.7808\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4084 - mae: 649.4084\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.9366 - mae: 647.9366\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.9692 - mae: 648.9692\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7282 - mae: 635.7282\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8375 - mae: 641.8375\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2834 - mae: 644.2834\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3636 - mae: 641.3636\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6711 - mae: 641.6711\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9521 - mae: 642.9521\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 654.1499 - mae: 654.1499\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1050 - mae: 643.1050\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.0069 - mae: 640.0069\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3054 - mae: 638.3054\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.5963 - mae: 636.5963\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4138 - mae: 645.4138\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.4037 - mae: 640.4037\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2045 - mae: 642.2045\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.0195 - mae: 649.0195\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8173 - mae: 639.8173\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 650.4265 - mae: 650.4265\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1665 - mae: 643.1665\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5280 - mae: 642.5280\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9675 - mae: 642.9675\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6927 - mae: 644.6927\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.8607 - mae: 648.8607\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9584 - mae: 643.9584\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.8453 - mae: 645.8453\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2087 - mae: 647.2087\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1334 - mae: 639.1334\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3672 - mae: 644.3672\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7675 - mae: 638.7675\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3496 - mae: 638.3496\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1174 - mae: 644.1174\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4982 - mae: 641.4982\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7953 - mae: 644.7953\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4972 - mae: 643.4972\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0143 - mae: 643.0143\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1547 - mae: 644.1547\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9599 - mae: 642.9599\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5313 - mae: 640.5313\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.7815 - mae: 648.7815\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9831 - mae: 637.9831\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1827 - mae: 641.1827\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4318 - mae: 636.4318\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6683 - mae: 635.6683\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5185 - mae: 641.5185\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9298 - mae: 635.9298\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.0137 - mae: 648.0137\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3019 - mae: 641.3019\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4574 - mae: 647.4574\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8173 - mae: 639.8173\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8453 - mae: 637.8453\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8541 - mae: 634.8541\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7932 - mae: 639.7932\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8958 - mae: 645.8958\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.4536 - mae: 640.4536\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.7668 - mae: 640.7668\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4465 - mae: 638.4465\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5591 - mae: 643.5591\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2886 - mae: 639.2886\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6172 - mae: 643.6172\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1878 - mae: 640.1878\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2512 - mae: 638.2512\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2664 - mae: 644.2664\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9160 - mae: 639.9160\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 640.4025 - mae: 640.4025\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9588 - mae: 645.9588\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.0168 - mae: 643.0168\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.4486 - mae: 640.4486\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 863.6136 - mae: 863.6136\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2909 - mae: 638.2909\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6405 - mae: 645.6405\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2160 - mae: 643.2160\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8599 - mae: 646.8599\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6873 - mae: 643.6873\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 637.3009 - mae: 637.3009\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4276 - mae: 641.4276\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2338 - mae: 639.2338\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0704 - mae: 644.0704\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1171 - mae: 641.1171\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.6132 - mae: 648.6132\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0775 - mae: 645.0775\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1693 - mae: 635.1693\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5717 - mae: 641.5717\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0880 - mae: 644.0880\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.0766 - mae: 646.0766\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0793 - mae: 639.0793\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7203 - mae: 639.7203\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1066 - mae: 644.1066\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7175 - mae: 642.7175\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4177 - mae: 640.4177\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.2701 - mae: 642.2701\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7736 - mae: 640.7736\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7834 - mae: 635.7834\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4622 - mae: 636.4622\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3484 - mae: 642.3484\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7040 - mae: 639.7040\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9893 - mae: 638.9893\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2382 - mae: 642.2382\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.2297 - mae: 641.2297\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2360 - mae: 641.2360\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9547 - mae: 646.9547\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.0040 - mae: 647.0040\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5135 - mae: 638.5135\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.6079 - mae: 646.6079\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6691 - mae: 640.6691\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1705 - mae: 642.1705\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7808 - mae: 641.7808\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8973 - mae: 641.8973\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.7087 - mae: 640.7087\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7792 - mae: 639.7792\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3188 - mae: 635.3188\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.8099 - mae: 649.8099\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1788 - mae: 639.1788\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 648.3154 - mae: 648.3154\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3196 - mae: 643.3196\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.5940 - mae: 646.5940\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9203 - mae: 644.9203\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 644.0270 - mae: 644.0270\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4437 - mae: 637.4437\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4843 - mae: 637.4843\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7050 - mae: 637.7050\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2142 - mae: 646.2142\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9043 - mae: 635.9043\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.6135 - mae: 635.6135\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1113 - mae: 643.1113\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.9155 - mae: 642.9155\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.4227 - mae: 647.4227\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4301 - mae: 639.4301\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8355 - mae: 641.8355\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3948 - mae: 636.3948\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7350 - mae: 642.7350\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8690 - mae: 646.8690\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6448 - mae: 636.6448\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9568 - mae: 645.9568\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9744 - mae: 639.9744\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.2363 - mae: 642.2363\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4582 - mae: 649.4582\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7099 - mae: 641.7099\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.1783 - mae: 635.1783\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2476 - mae: 642.2476\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9318 - mae: 646.9318\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6854 - mae: 638.6854\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9138 - mae: 638.9138\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9876 - mae: 640.9876\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3550 - mae: 642.3550\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6638 - mae: 644.6638\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0012 - mae: 642.0012\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.9373 - mae: 648.9373\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.7598 - mae: 646.7598\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0145 - mae: 640.0145\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6012 - mae: 643.6012\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3358 - mae: 635.3358\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 646.0844 - mae: 646.0844\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 641.5941 - mae: 641.5941\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0536 - mae: 639.0536\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9130 - mae: 640.9130\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.8488 - mae: 641.8488\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9592 - mae: 642.9592\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6136 - mae: 638.6136\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 642.6166 - mae: 642.6166\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6702 - mae: 639.6702\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2454 - mae: 647.2454\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.5699 - mae: 643.5699\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1237 - mae: 642.1237\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9404 - mae: 640.9404\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8197 - mae: 639.8197\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6146 - mae: 642.6146\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.2397 - mae: 649.2397\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 818.9061 - mae: 818.9061\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.7217 - mae: 640.7217\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6667 - mae: 637.6667\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9954 - mae: 636.9954\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7215 - mae: 646.7215\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1799 - mae: 635.1799\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.1812 - mae: 643.1812\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.3042 - mae: 641.3042\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6077 - mae: 640.6077\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.5023 - mae: 630.5023\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6906 - mae: 639.6906\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3637 - mae: 642.3637\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8593 - mae: 641.8593\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.3658 - mae: 637.3658\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.7795 - mae: 646.7795\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4778 - mae: 641.4778\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.5928 - mae: 636.5928\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6293 - mae: 637.6293\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6050 - mae: 646.6050\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6639 - mae: 639.6639\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.5163 - mae: 644.5163\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1977 - mae: 641.1977\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4485 - mae: 645.4485\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1799 - mae: 636.1799\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3048 - mae: 643.3048\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.2808 - mae: 634.2808\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.6851 - mae: 637.6851\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.6656 - mae: 637.6656\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0665 - mae: 638.0665\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7263 - mae: 635.7263\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.5991 - mae: 649.5991\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3718 - mae: 641.3718\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.1766 - mae: 633.1766\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.6384 - mae: 640.6384\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2112 - mae: 635.2112\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7462 - mae: 637.7462\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.8736 - mae: 634.8736\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6620 - mae: 641.6620\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2127 - mae: 641.2127\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 631.9039 - mae: 631.9039\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 629.8062 - mae: 629.8062\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2543 - mae: 635.2543\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4933 - mae: 639.4933\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7171 - mae: 635.7171\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4172 - mae: 641.4172\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7280 - mae: 638.7280\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.0803 - mae: 643.0803\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0522 - mae: 637.0522\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.4929 - mae: 632.4929\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9268 - mae: 637.9268\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9850 - mae: 638.9850\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0413 - mae: 634.0413\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3342 - mae: 636.3342\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.1471 - mae: 641.1471\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8802 - mae: 637.8802\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.9617 - mae: 631.9617\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.5557 - mae: 630.5557\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1440 - mae: 637.1440\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7216 - mae: 640.7216\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.2256 - mae: 640.2256\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.2571 - mae: 637.2571\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.1060 - mae: 638.1060\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1842 - mae: 644.1842\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7826 - mae: 635.7826\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.0704 - mae: 635.0704\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.0974 - mae: 634.0974\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7658 - mae: 637.7658\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9927 - mae: 639.9927\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9238 - mae: 641.9238\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4887 - mae: 637.4887\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.5710 - mae: 632.5710\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.9694 - mae: 634.9694\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.2931 - mae: 637.2931\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5402 - mae: 634.5402\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1837 - mae: 641.1837\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3726 - mae: 641.3726\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.9166 - mae: 635.9166\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 629.8333 - mae: 629.8333\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.0320 - mae: 632.0320\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1973 - mae: 639.1973\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1021 - mae: 639.1021\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2979 - mae: 640.2979\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1688 - mae: 636.1688\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.8488 - mae: 637.8488\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0273 - mae: 641.0273\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.8643 - mae: 633.8643\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2632 - mae: 638.2632\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.2473 - mae: 638.2473\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8774 - mae: 634.8774\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.7334 - mae: 641.7334\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.3560 - mae: 634.3560\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0334 - mae: 642.0334\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1685 - mae: 639.1685\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.6285 - mae: 648.6285\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9564 - mae: 641.9564\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9017 - mae: 634.9017\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.8156 - mae: 631.8156\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.7050 - mae: 636.7050\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.9350 - mae: 633.9350\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1899 - mae: 636.1899\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 811.6215 - mae: 811.6215\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8790 - mae: 641.8790\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1420 - mae: 642.1420\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.9393 - mae: 648.9393\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2320 - mae: 642.2320\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6929 - mae: 638.6929\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0523 - mae: 642.0523\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.6245 - mae: 643.6245\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2685 - mae: 644.2685\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5934 - mae: 643.5934\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.7578 - mae: 652.7578\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9891 - mae: 641.9891\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.3273 - mae: 642.3273\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.9056 - mae: 641.9056\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.7994 - mae: 651.7994\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9784 - mae: 641.9784\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4979 - mae: 643.4979\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2382 - mae: 639.2382\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3892 - mae: 642.3892\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.5020 - mae: 643.5020\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8070 - mae: 640.8070\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1988 - mae: 648.1988\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6835 - mae: 638.6835\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8465 - mae: 643.8465\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4123 - mae: 645.4123\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.2144 - mae: 645.2144\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5842 - mae: 644.5842\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2416 - mae: 642.2416\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9784 - mae: 639.9784\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3198 - mae: 639.3198\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.8668 - mae: 647.8668\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.2085 - mae: 637.2085\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8428 - mae: 637.8428\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2870 - mae: 643.2870\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7784 - mae: 640.7784\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2504 - mae: 644.2504\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7645 - mae: 638.7645\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5020 - mae: 638.5020\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1494 - mae: 643.1494\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3933 - mae: 642.3933\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1599 - mae: 648.1599\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9780 - mae: 641.9780\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0524 - mae: 634.0524\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.1630 - mae: 642.1630\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.2540 - mae: 641.2540\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7628 - mae: 640.7628\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3907 - mae: 644.3907\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1110 - mae: 642.1110\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.4987 - mae: 647.4987\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.2961 - mae: 636.2961\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5235 - mae: 641.5235\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9286 - mae: 640.9286\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7051 - mae: 635.7051\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6390 - mae: 638.6390\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2974 - mae: 637.2974\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4076 - mae: 643.4076\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3938 - mae: 647.3938\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.1204 - mae: 641.1204\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.7786 - mae: 634.7786\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2719 - mae: 647.2719\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4177 - mae: 643.4177\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.6145 - mae: 635.6145\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0919 - mae: 641.0919\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.3013 - mae: 642.3013\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5790 - mae: 644.5790\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5796 - mae: 635.5796\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2108 - mae: 638.2108\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9629 - mae: 642.9629\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8644 - mae: 635.8644\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.0032 - mae: 641.0032\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.4815 - mae: 638.4815\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1133 - mae: 640.1133\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0843 - mae: 641.0843\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4908 - mae: 640.4908\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5624 - mae: 638.5624\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 640.9372 - mae: 640.9372\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2793 - mae: 646.2793\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1070 - mae: 640.1070\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1883 - mae: 643.1883\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.7313 - mae: 646.7313\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.1204 - mae: 648.1204\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4933 - mae: 637.4933\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8953 - mae: 644.8953\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9240 - mae: 641.9240\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8267 - mae: 642.8267\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5712 - mae: 638.5712\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.4347 - mae: 642.4347\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5190 - mae: 639.5190\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7119 - mae: 644.7119\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0486 - mae: 640.0486\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4360 - mae: 636.4360\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.7209 - mae: 645.7209\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8862 - mae: 642.8862\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4665 - mae: 638.4665\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2347 - mae: 638.2347\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5813 - mae: 643.5813\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.0886 - mae: 640.0886\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4666 - mae: 644.4666\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.8926 - mae: 642.8926\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.5330 - mae: 644.5330\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 819.9531 - mae: 819.9531\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1191 - mae: 643.1191\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7860 - mae: 642.7860\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.2629 - mae: 639.2629\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.5823 - mae: 644.5823\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5817 - mae: 641.5817\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9676 - mae: 638.9676\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8527 - mae: 641.8527\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.2551 - mae: 651.2551\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2370 - mae: 648.2370\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.5182 - mae: 637.5182\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1205 - mae: 640.1205\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8681 - mae: 640.8681\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3429 - mae: 635.3429\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6908 - mae: 642.6908\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3800 - mae: 640.3800\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3257 - mae: 643.3257\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.2865 - mae: 642.2865\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2094 - mae: 643.2094\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3293 - mae: 638.3293\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6611 - mae: 637.6611\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6776 - mae: 641.6776\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0760 - mae: 641.0760\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.0023 - mae: 641.0023\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2567 - mae: 641.2567\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3191 - mae: 642.3191\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6961 - mae: 646.6961\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6143 - mae: 637.6143\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8074 - mae: 645.8074\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.4172 - mae: 634.4172\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.0204 - mae: 637.0204\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6538 - mae: 643.6538\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4581 - mae: 636.4581\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.6152 - mae: 632.6152\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4445 - mae: 638.4445\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.9681 - mae: 640.9681\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4456 - mae: 646.4456\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.1055 - mae: 640.1055\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1692 - mae: 644.1692\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7126 - mae: 645.7126\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5594 - mae: 645.5594\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.5042 - mae: 638.5042\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9783 - mae: 637.9783\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.4508 - mae: 635.4508\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.2795 - mae: 648.2795\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8862 - mae: 637.8862\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3572 - mae: 643.3572\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.4718 - mae: 639.4718\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8488 - mae: 639.8488\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9327 - mae: 642.9327\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.9802 - mae: 649.9802\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4080 - mae: 639.4080\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1978 - mae: 635.1978\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8284 - mae: 642.8284\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.7235 - mae: 637.7235\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0639 - mae: 637.0639\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.6036 - mae: 649.6036\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0445 - mae: 634.0445\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2109 - mae: 645.2109\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2731 - mae: 640.2731\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.4090 - mae: 645.4090\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5667 - mae: 641.5667\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.0211 - mae: 635.0211\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3976 - mae: 636.3976\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6674 - mae: 644.6674\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4749 - mae: 646.4749\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.0906 - mae: 639.0906\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.5338 - mae: 637.5338\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.6329 - mae: 643.6329\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5104 - mae: 639.5104\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6630 - mae: 641.6630\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.5078 - mae: 641.5078\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.8808 - mae: 633.8808\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.5001 - mae: 643.5001\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.8654 - mae: 638.8654\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 632.9309 - mae: 632.9309\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4523 - mae: 638.4523\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.1614 - mae: 648.1614\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1050 - mae: 642.1050\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7719 - mae: 638.7719\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5139 - mae: 641.5139\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 630.7464 - mae: 630.7464\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 647.4689 - mae: 647.4689\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2604 - mae: 644.2604\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9798 - mae: 637.9798\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5317 - mae: 640.5317\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.8877 - mae: 643.8877\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.4380 - mae: 637.4380\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 640.7194 - mae: 640.7194\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1865 - mae: 641.1865\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5839 - mae: 641.5839\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2822 - mae: 644.2822\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.3713 - mae: 644.3713\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6000 - mae: 639.6000\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.5446 - mae: 634.5446\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3100 - mae: 643.3100\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1429 - mae: 644.1429\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1675 - mae: 638.1675\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2755 - mae: 635.2755\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.7075 - mae: 641.7075\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 919.6221 - mae: 919.6221\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.8850 - mae: 631.8850\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9149 - mae: 639.9149\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8804 - mae: 635.8804\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1123 - mae: 644.1123\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.6999 - mae: 639.6999\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.5052 - mae: 641.5052\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4280 - mae: 640.4280\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0787 - mae: 641.0787\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9724 - mae: 637.9724\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3569 - mae: 639.3569\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6650 - mae: 639.6650\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.7219 - mae: 637.7219\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0284 - mae: 639.0284\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8380 - mae: 637.8380\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7507 - mae: 639.7507\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9448 - mae: 640.9448\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7534 - mae: 640.7534\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6840 - mae: 635.6840\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1993 - mae: 639.1993\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0075 - mae: 638.0075\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9894 - mae: 644.9894\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5233 - mae: 639.5233\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0151 - mae: 641.0151\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.4108 - mae: 635.4108\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9797 - mae: 636.9797\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2056 - mae: 640.2056\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2278 - mae: 642.2278\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3043 - mae: 641.3043\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6445 - mae: 637.6445\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1765 - mae: 641.1765\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.9503 - mae: 635.9503\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0492 - mae: 642.0492\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4651 - mae: 639.4651\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7956 - mae: 642.7956\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1380 - mae: 637.1380\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.8174 - mae: 645.8174\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.6519 - mae: 645.6519\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2687 - mae: 642.2687\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1458 - mae: 638.1458\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7283 - mae: 639.7283\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8771 - mae: 643.8771\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5175 - mae: 638.5175\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.3730 - mae: 645.3730\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6623 - mae: 640.6623\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3660 - mae: 642.3660\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6949 - mae: 640.6949\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.3126 - mae: 643.3126\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3389 - mae: 643.3389\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9807 - mae: 639.9807\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9209 - mae: 635.9209\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4444 - mae: 638.4444\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0143 - mae: 643.0143\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3873 - mae: 641.3873\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.7083 - mae: 630.7083\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.9582 - mae: 636.9582\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2486 - mae: 639.2486\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4556 - mae: 641.4556\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.5159 - mae: 633.5159\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3116 - mae: 642.3116\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6004 - mae: 639.6004\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2666 - mae: 640.2666\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.0154 - mae: 646.0154\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2098 - mae: 643.2098\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.5887 - mae: 644.5887\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1867 - mae: 637.1867\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7274 - mae: 644.7274\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1712 - mae: 646.1712\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.7816 - mae: 641.7816\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9589 - mae: 635.9589\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8386 - mae: 637.8386\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1585 - mae: 639.1585\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.3210 - mae: 635.3210\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7891 - mae: 638.7891\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.7775 - mae: 643.7775\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.9474 - mae: 633.9474\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2316 - mae: 642.2316\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.7178 - mae: 633.7178\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9310 - mae: 640.9310\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3278 - mae: 635.3278\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.5053 - mae: 634.5053\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.4053 - mae: 646.4053\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.7620 - mae: 635.7620\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0121 - mae: 637.0121\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3857 - mae: 637.3857\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3344 - mae: 645.3344\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4587 - mae: 637.4587\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9025 - mae: 643.9025\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.7872 - mae: 642.7872\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0957 - mae: 639.0957\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2868 - mae: 642.2868\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3235 - mae: 640.3235\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0782 - mae: 636.0782\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.1544 - mae: 645.1544\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.4651 - mae: 644.4651\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.1604 - mae: 634.1604\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3555 - mae: 641.3555\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9561 - mae: 635.9561\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5191 - mae: 642.5191\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4258 - mae: 643.4258\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 932.4747 - mae: 932.4747\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1476 - mae: 647.1476\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.9969 - mae: 652.9969\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6325 - mae: 645.6325\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3552 - mae: 640.3552\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.2953 - mae: 647.2953\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1487 - mae: 643.1487\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9216 - mae: 640.9216\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 653.1148 - mae: 653.1148\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.7345 - mae: 645.7345\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.1587 - mae: 640.1587\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.1721 - mae: 639.1721\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7490 - mae: 641.7490\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4669 - mae: 645.4669\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1144 - mae: 643.1144\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3881 - mae: 644.3881\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3522 - mae: 641.3522\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.3204 - mae: 644.3204\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 653.7867 - mae: 653.7867\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0150 - mae: 644.0150\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8721 - mae: 644.8721\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6620 - mae: 638.6620\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9841 - mae: 642.9841\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2836 - mae: 647.2836\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.3445 - mae: 639.3445\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.9957 - mae: 646.9957\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5369 - mae: 639.5369\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8862 - mae: 639.8862\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1739 - mae: 641.1739\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6230 - mae: 641.6230\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4563 - mae: 644.4563\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.7742 - mae: 640.7742\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0986 - mae: 639.0986\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7362 - mae: 641.7362\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7144 - mae: 642.7144\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3616 - mae: 640.3616\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.8717 - mae: 648.8717\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.9541 - mae: 643.9541\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.6306 - mae: 639.6306\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.2918 - mae: 642.2918\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1540 - mae: 644.1540\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.7992 - mae: 631.7992\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.3069 - mae: 651.3069\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.9147 - mae: 641.9147\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6799 - mae: 643.6799\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3562 - mae: 645.3562\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8492 - mae: 641.8492\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3921 - mae: 645.3921\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5620 - mae: 643.5620\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.1742 - mae: 645.1742\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.4750 - mae: 643.4750\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 652.7826 - mae: 652.7826\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.6495 - mae: 644.6495\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0759 - mae: 644.0759\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1437 - mae: 637.1437\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4850 - mae: 643.4850\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.1079 - mae: 646.1079\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2488 - mae: 640.2488\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3542 - mae: 643.3542\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0565 - mae: 644.0565\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5045 - mae: 647.5045\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4185 - mae: 647.4185\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.8707 - mae: 646.8707\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1219 - mae: 645.1219\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.8696 - mae: 648.8696\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 635.8518 - mae: 635.8518\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.2460 - mae: 633.2460\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9825 - mae: 645.9825\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.6100 - mae: 642.6100\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.2697 - mae: 642.2697\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.2979 - mae: 643.2979\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.9877 - mae: 648.9877\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.1978 - mae: 649.1978\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5313 - mae: 642.5313\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3698 - mae: 645.3698\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.6192 - mae: 646.6192\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1581 - mae: 646.1581\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.8543 - mae: 645.8543\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6954 - mae: 638.6954\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0817 - mae: 640.0817\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.6877 - mae: 643.6877\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.9409 - mae: 642.9409\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.6639 - mae: 642.6639\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5126 - mae: 643.5126\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2766 - mae: 639.2766\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2156 - mae: 644.2156\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9894 - mae: 644.9894\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.5464 - mae: 646.5464\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.1338 - mae: 642.1338\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0233 - mae: 641.0233\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9774 - mae: 640.9774\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3346 - mae: 642.3346\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0816 - mae: 634.0816\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.2678 - mae: 648.2678\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.3401 - mae: 645.3401\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2908 - mae: 636.2908\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2401 - mae: 636.2401\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1182 - mae: 640.1182\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0271 - mae: 640.0271\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0530 - mae: 639.0530\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 915.3655 - mae: 915.3655\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8719 - mae: 637.8719\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4559 - mae: 641.4559\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.0161 - mae: 642.0161\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2358 - mae: 644.2358\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.0016 - mae: 639.0016\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3578 - mae: 643.3578\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7020 - mae: 643.7020\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3473 - mae: 642.3473\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4747 - mae: 644.4747\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3289 - mae: 639.3289\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.7586 - mae: 642.7586\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3646 - mae: 638.3646\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3989 - mae: 638.3989\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.4775 - mae: 645.4775\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7345 - mae: 643.7345\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.1987 - mae: 637.1987\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 649.5748 - mae: 649.5748\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3773 - mae: 643.3773\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 645.5778 - mae: 645.5778\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3519 - mae: 640.3519\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.0719 - mae: 646.0719\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7217 - mae: 643.7217\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.8687 - mae: 636.8687\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.5058 - mae: 638.5058\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1956 - mae: 646.1956\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.7201 - mae: 646.7201\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3749 - mae: 641.3749\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.9438 - mae: 644.9438\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.1963 - mae: 637.1963\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 642.6959 - mae: 642.6959\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8198 - mae: 637.8198\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1161 - mae: 643.1161\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7119 - mae: 637.7119\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2014 - mae: 640.2014\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.5130 - mae: 645.5130\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.3951 - mae: 644.3951\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.8379 - mae: 639.8379\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8721 - mae: 639.8721\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3582 - mae: 646.3582\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8613 - mae: 642.8613\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1841 - mae: 643.1841\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5450 - mae: 640.5450\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.9014 - mae: 636.9014\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.4866 - mae: 646.4866\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.9175 - mae: 640.9175\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1178 - mae: 639.1178\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3725 - mae: 637.3725\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.9869 - mae: 648.9869\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.8470 - mae: 635.8470\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4891 - mae: 636.4891\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.3563 - mae: 642.3563\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.7167 - mae: 643.7167\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.0563 - mae: 649.0563\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7948 - mae: 643.7948\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4755 - mae: 643.4755\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.9255 - mae: 643.9255\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.3735 - mae: 639.3735\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9820 - mae: 642.9820\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.7492 - mae: 639.7492\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3040 - mae: 639.3040\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2606 - mae: 636.2606\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0490 - mae: 642.0490\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9394 - mae: 639.9394\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2031 - mae: 640.2031\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.9042 - mae: 641.9042\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.4924 - mae: 648.4924\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6877 - mae: 635.6877\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.8313 - mae: 640.8313\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.3120 - mae: 646.3120\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.0311 - mae: 646.0311\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.2859 - mae: 644.2859\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9156 - mae: 638.9156\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6605 - mae: 644.6605\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.1094 - mae: 638.1094\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3604 - mae: 636.3604\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.7608 - mae: 637.7608\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.2118 - mae: 635.2118\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2463 - mae: 637.2463\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0227 - mae: 645.0227\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.9039 - mae: 647.9039\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3230 - mae: 637.3230\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.4500 - mae: 645.4500\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.6083 - mae: 636.6083\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9010 - mae: 640.9010\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0293 - mae: 640.0293\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7089 - mae: 643.7089\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5249 - mae: 638.5249\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.5772 - mae: 647.5772\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.4066 - mae: 642.4066\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3660 - mae: 649.3660\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0334 - mae: 637.0334\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1736 - mae: 639.1736\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5652 - mae: 643.5652\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3167 - mae: 639.3167\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.3979 - mae: 640.3979\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.3412 - mae: 638.3412\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6623 - mae: 637.6623\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4349 - mae: 641.4349\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9810 - mae: 637.9810\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 848.3809 - mae: 848.3809\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2334 - mae: 644.2334\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5865 - mae: 640.5865\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.9591 - mae: 644.9591\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5773 - mae: 634.5773\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 650.5687 - mae: 650.5687\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7413 - mae: 638.7413\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6733 - mae: 636.6733\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8474 - mae: 641.8474\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8732 - mae: 640.8732\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 650.8561 - mae: 650.8561\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.9660 - mae: 644.9660\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4145 - mae: 637.4145\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2020 - mae: 644.2020\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8210 - mae: 642.8210\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.0229 - mae: 639.0229\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4806 - mae: 642.4806\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.0157 - mae: 640.0157\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8140 - mae: 639.8140\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2121 - mae: 634.2121\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7322 - mae: 637.7322\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6345 - mae: 636.6345\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.8303 - mae: 640.8303\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.4014 - mae: 635.4014\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.1406 - mae: 643.1406\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.3669 - mae: 641.3669\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.1704 - mae: 638.1704\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6918 - mae: 637.6918\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5330 - mae: 640.5330\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4655 - mae: 640.4655\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.4457 - mae: 642.4457\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.5634 - mae: 633.5634\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4069 - mae: 640.4069\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.5110 - mae: 637.5110\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5864 - mae: 639.5864\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5583 - mae: 640.5583\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9108 - mae: 637.9108\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7897 - mae: 637.7897\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.8565 - mae: 634.8565\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.9464 - mae: 633.9464\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4468 - mae: 638.4468\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3793 - mae: 639.3793\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9704 - mae: 638.9704\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.6229 - mae: 637.6229\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4784 - mae: 641.4784\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.7391 - mae: 637.7391\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5704 - mae: 636.5704\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7679 - mae: 638.7679\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2018 - mae: 641.2018\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4196 - mae: 639.4196\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5898 - mae: 642.5898\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.2863 - mae: 643.2863\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.0679 - mae: 635.0679\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.6837 - mae: 640.6837\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.0196 - mae: 644.0196\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5885 - mae: 642.5885\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7245 - mae: 635.7245\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9019 - mae: 635.9019\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.1842 - mae: 634.1842\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.3950 - mae: 632.3950\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.8092 - mae: 636.8092\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.0237 - mae: 632.0237\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4990 - mae: 636.4990\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7807 - mae: 642.7807\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7636 - mae: 636.7636\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9628 - mae: 637.9628\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.6575 - mae: 633.6575\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0573 - mae: 638.0573\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.7650 - mae: 631.7650\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1449 - mae: 636.1449\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0905 - mae: 638.0905\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4847 - mae: 637.4847\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0930 - mae: 637.0930\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.2819 - mae: 644.2819\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.9494 - mae: 633.9494\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9266 - mae: 638.9266\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0715 - mae: 636.0715\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7622 - mae: 635.7622\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.8478 - mae: 635.8478\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.8923 - mae: 635.8923\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.7959 - mae: 636.7959\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.8318 - mae: 637.8318\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7675 - mae: 644.7675\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9054 - mae: 636.9054\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.6229 - mae: 634.6229\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.3280 - mae: 641.3280\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.4916 - mae: 639.4916\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.2960 - mae: 630.2960\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0079 - mae: 640.0079\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.5400 - mae: 636.5400\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.8478 - mae: 632.8478\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.9116 - mae: 638.9116\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.7686 - mae: 636.7686\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 627.6584 - mae: 627.6584\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0197 - mae: 636.0197\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.7025 - mae: 635.7025\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.3934 - mae: 636.3934\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8878 - mae: 636.8878\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.3948 - mae: 638.3948\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4888 - mae: 641.4888\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 838.3803 - mae: 838.3803\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.2546 - mae: 640.2546\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6039 - mae: 641.6039\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5716 - mae: 636.5716\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.8466 - mae: 642.8466\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.3673 - mae: 643.3673\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.8917 - mae: 636.8917\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8174 - mae: 644.8174\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2527 - mae: 641.2527\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.6868 - mae: 645.6868\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3555 - mae: 644.3555\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.0515 - mae: 646.0515\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.7298 - mae: 640.7298\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.4212 - mae: 643.4212\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.2358 - mae: 647.2358\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4036 - mae: 640.4036\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5011 - mae: 637.5011\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.3872 - mae: 644.3872\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.4029 - mae: 645.4029\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9306 - mae: 640.9306\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.4008 - mae: 647.4008\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9274 - mae: 636.9274\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 651.0272 - mae: 651.0272\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9882 - mae: 643.9882\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.3256 - mae: 645.3256\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.0558 - mae: 637.0558\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.2551 - mae: 646.2551\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4818 - mae: 636.4818\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.8702 - mae: 648.8702\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9177 - mae: 646.9177\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.1756 - mae: 641.1756\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.9291 - mae: 648.9291\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0377 - mae: 644.0377\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0743 - mae: 642.0743\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.6548 - mae: 639.6548\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9446 - mae: 646.9446\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.2157 - mae: 637.2157\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.5922 - mae: 642.5922\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.5175 - mae: 649.5175\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1907 - mae: 641.1907\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7492 - mae: 644.7492\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6735 - mae: 639.6735\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1632 - mae: 647.1632\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7023 - mae: 645.7023\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7430 - mae: 642.7430\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1341 - mae: 635.1341\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4468 - mae: 643.4468\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.5803 - mae: 646.5803\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.8788 - mae: 641.8788\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7629 - mae: 645.7629\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.5358 - mae: 641.5358\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2637 - mae: 639.2637\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1468 - mae: 640.1468\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.0067 - mae: 640.0067\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.2151 - mae: 639.2151\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.6772 - mae: 644.6772\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.0139 - mae: 644.0139\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5333 - mae: 640.5333\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1459 - mae: 639.1459\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.6536 - mae: 643.6536\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.9218 - mae: 641.9218\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.5890 - mae: 640.5890\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.7845 - mae: 639.7845\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.4621 - mae: 632.4621\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.6903 - mae: 646.6903\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.1057 - mae: 639.1057\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1387 - mae: 644.1387\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.1703 - mae: 646.1703\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.1511 - mae: 647.1511\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.1311 - mae: 643.1311\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9552 - mae: 646.9552\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.4738 - mae: 649.4738\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.8533 - mae: 641.8533\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.1175 - mae: 641.1175\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.2564 - mae: 645.2564\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1938 - mae: 638.1938\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.8822 - mae: 641.8822\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2036 - mae: 644.2036\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6164 - mae: 637.6164\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.8329 - mae: 641.8329\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.9496 - mae: 632.9496\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.2570 - mae: 638.2570\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.9153 - mae: 645.9153\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.5452 - mae: 634.5452\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4006 - mae: 643.4006\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.3431 - mae: 646.3431\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.7625 - mae: 636.7625\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0412 - mae: 641.0412\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.2200 - mae: 641.2200\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9882 - mae: 637.9882\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9502 - mae: 643.9502\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.6757 - mae: 636.6757\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.4039 - mae: 640.4039\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 646.4918 - mae: 646.4918\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.1404 - mae: 641.1404\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.0036 - mae: 642.0036\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1277 - mae: 640.1277\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.7926 - mae: 639.7926\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8660 - mae: 644.8660\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8215 - mae: 637.8215\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 866.9861 - mae: 866.9861\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 651.1383 - mae: 651.1383\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 651.2881 - mae: 651.2881\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.7192 - mae: 640.7192\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.0942 - mae: 637.0942\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1177 - mae: 639.1177\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3859 - mae: 638.3859\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.7720 - mae: 639.7720\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5718 - mae: 640.5718\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.1185 - mae: 645.1185\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.8024 - mae: 642.8024\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3306 - mae: 643.3306\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1865 - mae: 646.1865\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6973 - mae: 644.6973\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1691 - mae: 637.1691\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.4485 - mae: 637.4485\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7346 - mae: 641.7346\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4990 - mae: 639.4990\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3724 - mae: 645.3724\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.8704 - mae: 642.8704\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3834 - mae: 641.3834\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5734 - mae: 637.5734\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.0179 - mae: 645.0179\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8152 - mae: 642.8152\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.4266 - mae: 637.4266\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.6877 - mae: 636.6877\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.1651 - mae: 645.1651\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6562 - mae: 641.6562\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7841 - mae: 635.7841\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5604 - mae: 639.5604\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3085 - mae: 644.3085\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 642.6859 - mae: 642.6859\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.6064 - mae: 644.6064\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1328 - mae: 639.1328\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8419 - mae: 641.8419\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.9424 - mae: 639.9424\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8533 - mae: 646.8533\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1060 - mae: 638.1060\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.9727 - mae: 633.9727\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4037 - mae: 637.4037\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8195 - mae: 641.8195\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.8970 - mae: 643.8970\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.8509 - mae: 646.8509\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.4829 - mae: 640.4829\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 632.2953 - mae: 632.2953\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.5217 - mae: 634.5217\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.7491 - mae: 645.7491\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3235 - mae: 640.3235\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.7389 - mae: 647.7389\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.0801 - mae: 643.0801\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5059 - mae: 639.5059\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1350 - mae: 637.1350\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.4778 - mae: 637.4778\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2433 - mae: 637.2433\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0579 - mae: 632.0579\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.7350 - mae: 640.7350\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.2399 - mae: 645.2399\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.2834 - mae: 643.2834\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.5193 - mae: 647.5193\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6063 - mae: 635.6063\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.0704 - mae: 641.0704\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.6417 - mae: 640.6417\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.0606 - mae: 638.0606\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.3506 - mae: 644.3506\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.2377 - mae: 644.2377\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.3337 - mae: 633.3337\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5624 - mae: 640.5624\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.8695 - mae: 644.8695\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3645 - mae: 639.3645\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.5021 - mae: 639.5021\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.8850 - mae: 639.8850\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7985 - mae: 641.7985\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5115 - mae: 640.5115\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0101 - mae: 632.0101\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6978 - mae: 641.6978\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.0185 - mae: 634.0185\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.7802 - mae: 645.7802\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.6122 - mae: 645.6122\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 648.6940 - mae: 648.6940\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.2902 - mae: 631.2902\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1664 - mae: 636.1664\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.4926 - mae: 642.4926\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.1640 - mae: 643.1640\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 634.5440 - mae: 634.5440\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.9344 - mae: 639.9344\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.7160 - mae: 647.7160\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.4794 - mae: 635.4794\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.5577 - mae: 632.5577\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4578 - mae: 636.4578\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.4041 - mae: 640.4041\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.0400 - mae: 635.0400\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.1810 - mae: 645.1810\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5932 - mae: 638.5932\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.2386 - mae: 639.2386\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.1412 - mae: 642.1412\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.2094 - mae: 639.2094\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 630.1537 - mae: 630.1537\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 635.9274 - mae: 635.9274\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6128 - mae: 636.6128\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5741 - mae: 635.5741\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 798.6818 - mae: 798.6818\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0380 - mae: 639.0380\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7860 - mae: 638.7860\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.1008 - mae: 642.1008\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2568 - mae: 635.2568\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.8926 - mae: 636.8926\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 644.2808 - mae: 644.2808\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1517 - mae: 640.1517\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.7665 - mae: 631.7665\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.6055 - mae: 633.6055\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.1344 - mae: 640.1344\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0782 - mae: 638.0782\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3367 - mae: 649.3367\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5375 - mae: 638.5375\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7101 - mae: 638.7101\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.6100 - mae: 638.6100\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.2943 - mae: 639.2943\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.9136 - mae: 638.9136\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.3582 - mae: 634.3582\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.3798 - mae: 640.3798\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2712 - mae: 636.2712\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4316 - mae: 640.4316\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.2745 - mae: 643.2745\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.6023 - mae: 643.6023\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3332 - mae: 639.3332\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8522 - mae: 643.8522\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0085 - mae: 636.0085\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1849 - mae: 640.1849\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.3472 - mae: 631.3472\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.5737 - mae: 645.5737\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.7746 - mae: 639.7746\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5356 - mae: 639.5356\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.9908 - mae: 637.9908\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9102 - mae: 640.9102\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.4081 - mae: 634.4081\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.6511 - mae: 637.6511\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9565 - mae: 639.9565\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 632.5840 - mae: 632.5840\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0442 - mae: 638.0442\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.0182 - mae: 643.0182\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2052 - mae: 636.2052\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.2642 - mae: 630.2642\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.3384 - mae: 635.3384\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.0207 - mae: 635.0207\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 640.4270 - mae: 640.4270\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.8420 - mae: 629.8420\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4474 - mae: 637.4474\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7023 - mae: 638.7023\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.4882 - mae: 642.4882\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 631.7196 - mae: 631.7196\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7651 - mae: 640.7651\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.7879 - mae: 637.7879\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.9713 - mae: 633.9713\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.2087 - mae: 630.2087\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 628.9018 - mae: 628.9018\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.1273 - mae: 643.1273\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 633.9164 - mae: 633.9164\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6733 - mae: 637.6733\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.4600 - mae: 632.4600\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.5239 - mae: 630.5239\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7693 - mae: 636.7693\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.4500 - mae: 640.4500\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.0641 - mae: 635.0641\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9188 - mae: 640.9188\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.4224 - mae: 633.4224\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8976 - mae: 636.8976\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.3489 - mae: 634.3489\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.5791 - mae: 632.5791\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.2435 - mae: 640.2435\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.0972 - mae: 641.0972\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.5059 - mae: 635.5059\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8207 - mae: 636.8207\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0942 - mae: 638.0942\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1984 - mae: 638.1984\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.6215 - mae: 642.6215\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.6770 - mae: 635.6770\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.7947 - mae: 643.7947\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.2399 - mae: 632.2399\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.7715 - mae: 636.7715\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1666 - mae: 638.1666\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.3035 - mae: 636.3035\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1068 - mae: 636.1068\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.6395 - mae: 631.6395\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.1707 - mae: 630.1707\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.3609 - mae: 633.3609\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.7104 - mae: 635.7104\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5673 - mae: 637.5673\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2441 - mae: 635.2441\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.0201 - mae: 633.0201\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.4061 - mae: 631.4061\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 628.5776 - mae: 628.5776\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 631.5828 - mae: 631.5828\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2609 - mae: 637.2609\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0696 - mae: 636.0696\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.3852 - mae: 630.3852\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.3317 - mae: 634.3317\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.4017 - mae: 631.4017\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.6183 - mae: 636.6183\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8288 - mae: 642.8288\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.2005 - mae: 630.2005\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 804.3455 - mae: 804.3455\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7839 - mae: 642.7839\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.1188 - mae: 643.1188\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5847 - mae: 639.5847\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1879 - mae: 642.1879\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1321 - mae: 643.1321\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.4440 - mae: 639.4440\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1927 - mae: 646.1927\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.3145 - mae: 641.3145\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.7001 - mae: 643.7001\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2605 - mae: 636.2605\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.8610 - mae: 639.8610\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.1619 - mae: 637.1619\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.8788 - mae: 646.8788\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6068 - mae: 642.6068\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.8829 - mae: 649.8829\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.3170 - mae: 644.3170\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3279 - mae: 649.3279\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.0500 - mae: 638.0500\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.0280 - mae: 646.0280\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.9103 - mae: 642.9103\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.5808 - mae: 646.5808\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1663 - mae: 642.1663\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.7373 - mae: 644.7373\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.3712 - mae: 642.3712\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.8540 - mae: 643.8540\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.6370 - mae: 643.6370\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.5455 - mae: 644.5455\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7790 - mae: 641.7790\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.5229 - mae: 638.5229\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3026 - mae: 645.3026\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.2525 - mae: 638.2525\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.3940 - mae: 637.3940\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.3859 - mae: 640.3859\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1568 - mae: 638.1568\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3365 - mae: 641.3365\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.7221 - mae: 641.7221\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.4619 - mae: 634.4619\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.2136 - mae: 647.2136\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.2087 - mae: 637.2087\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0798 - mae: 641.0798\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7054 - mae: 644.7054\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4655 - mae: 637.4655\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.8849 - mae: 644.8849\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.8038 - mae: 642.8038\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.9771 - mae: 636.9771\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0729 - mae: 641.0729\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.7562 - mae: 640.7562\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1971 - mae: 640.1971\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.4962 - mae: 637.4962\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.0326 - mae: 643.0326\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 649.0596 - mae: 649.0596\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.2557 - mae: 636.2557\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7342 - mae: 641.7342\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.3231 - mae: 645.3231\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0251 - mae: 640.0251\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.1663 - mae: 638.1663\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.7722 - mae: 635.7722\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.8754 - mae: 641.8754\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5923 - mae: 639.5923\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4710 - mae: 641.4710\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6163 - mae: 636.6163\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.1086 - mae: 639.1086\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.1834 - mae: 635.1834\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3317 - mae: 638.3317\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.9319 - mae: 642.9319\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.5674 - mae: 637.5674\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3185 - mae: 645.3185\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.3712 - mae: 637.3712\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.9517 - mae: 636.9517\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 631.1656 - mae: 631.1656\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.8221 - mae: 633.8221\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.5716 - mae: 640.5716\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 630.6391 - mae: 630.6391\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7007 - mae: 641.7007\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.0762 - mae: 637.0762\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.3123 - mae: 640.3123\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.0219 - mae: 631.0219\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.9963 - mae: 634.9963\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.1970 - mae: 643.1970\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.4240 - mae: 636.4240\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.2562 - mae: 639.2562\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 635.0822 - mae: 635.0822\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9775 - mae: 636.9775\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.2047 - mae: 635.2047\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8156 - mae: 638.8156\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.5392 - mae: 649.5392\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7997 - mae: 635.7997\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.1166 - mae: 640.1166\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.3171 - mae: 646.3171\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2480 - mae: 637.2480\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.0504 - mae: 639.0504\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.9682 - mae: 636.9682\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.0304 - mae: 634.0304\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.2505 - mae: 635.2505\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.7198 - mae: 631.7198\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.7859 - mae: 637.7859\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 633.5964 - mae: 633.5964\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.9811 - mae: 635.9811\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.3050 - mae: 635.3050\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 790.1598 - mae: 790.1598\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.4543 - mae: 644.4543\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 640.7923 - mae: 640.7923\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4821 - mae: 641.4821\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4220 - mae: 644.4220\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 645.3981 - mae: 645.3981\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.8696 - mae: 642.8696\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.5323 - mae: 644.5323\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 644.4293 - mae: 644.4293\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8497 - mae: 639.8497\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.1738 - mae: 644.1738\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.6470 - mae: 641.6470\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1509 - mae: 644.1509\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.6321 - mae: 641.6321\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.5378 - mae: 638.5378\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.1867 - mae: 641.1867\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2576 - mae: 637.2576\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.1810 - mae: 636.1810\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5408 - mae: 642.5408\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.9091 - mae: 646.9091\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.5698 - mae: 645.5698\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.7374 - mae: 642.7374\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.3141 - mae: 646.3141\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.4055 - mae: 646.4055\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.2906 - mae: 644.2906\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5067 - mae: 636.5067\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.2543 - mae: 635.2543\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 627.9028 - mae: 627.9028\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3401 - mae: 639.3401\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.7625 - mae: 642.7625\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.4255 - mae: 637.4255\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.6772 - mae: 634.6772\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.4224 - mae: 640.4224\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.4378 - mae: 644.4378\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1104 - mae: 640.1104\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.9382 - mae: 647.9382\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 642.5250 - mae: 642.5250\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.3517 - mae: 636.3517\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.1100 - mae: 639.1100\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 645.8492 - mae: 645.8492\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2408 - mae: 634.2408\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0505 - mae: 641.0505\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4305 - mae: 645.4305\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7374 - mae: 636.7374\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.0856 - mae: 646.0856\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.3088 - mae: 643.3088\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.5812 - mae: 642.5812\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.5403 - mae: 638.5403\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.6238 - mae: 646.6238\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7479 - mae: 635.7479\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.5266 - mae: 637.5266\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9645 - mae: 637.9645\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 644.1992 - mae: 644.1992\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7833 - mae: 638.7833\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.8156 - mae: 642.8156\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0316 - mae: 644.0316\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 636.9392 - mae: 636.9392\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.9177 - mae: 645.9177\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.8690 - mae: 638.8690\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 646.1001 - mae: 646.1001\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.4785 - mae: 647.4785\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.7989 - mae: 632.7989\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.9015 - mae: 635.9015\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.2653 - mae: 640.2653\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 642.5892 - mae: 642.5892\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627.5861 - mae: 627.5861\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.2175 - mae: 636.2175\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5071 - mae: 643.5071\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.4943 - mae: 641.4943\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.4739 - mae: 636.4739\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.5381 - mae: 643.5381\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.5071 - mae: 639.5071\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.1426 - mae: 638.1426\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.2565 - mae: 641.2565\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.1852 - mae: 633.1852\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.1453 - mae: 639.1453\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.3016 - mae: 641.3016\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9556 - mae: 640.9556\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.3601 - mae: 637.3601\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.5798 - mae: 636.5798\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.5867 - mae: 633.5867\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.8650 - mae: 637.8650\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6175 - mae: 642.6175\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 639.3297 - mae: 639.3297\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.8759 - mae: 637.8759\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8460 - mae: 638.8460\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.4613 - mae: 635.4613\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 641.1010 - mae: 641.1010\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.2006 - mae: 631.2006\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.6096 - mae: 638.6096\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.7297 - mae: 633.7297\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.6984 - mae: 632.6984\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.6808 - mae: 630.6808\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.6187 - mae: 634.6187\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.4020 - mae: 634.4020\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.8785 - mae: 639.8785\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.1611 - mae: 634.1611\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.3784 - mae: 630.3784\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 628.4638 - mae: 628.4638\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 630.7487 - mae: 630.7487\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 760.3643 - mae: 760.3643\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.1262 - mae: 635.1262\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.9240 - mae: 643.9240\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.1428 - mae: 644.1428\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.2711 - mae: 638.2711\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.3925 - mae: 640.3925\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 640.8608 - mae: 640.8608\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.4369 - mae: 641.4369\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.1281 - mae: 639.1281\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.3392 - mae: 638.3392\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.6367 - mae: 638.6367\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.0759 - mae: 636.0759\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.3393 - mae: 638.3393\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.7959 - mae: 636.7959\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.4344 - mae: 643.4344\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.5128 - mae: 641.5128\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.2194 - mae: 634.2194\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.5642 - mae: 639.5642\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2308 - mae: 639.2308\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 649.0206 - mae: 649.0206\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.9822 - mae: 637.9822\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.6138 - mae: 638.6138\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 633.7705 - mae: 633.7705\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.5836 - mae: 633.5836\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.2939 - mae: 639.2939\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.4731 - mae: 638.4731\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9945 - mae: 637.9945\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.3305 - mae: 634.3305\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7585 - mae: 635.7585\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.1492 - mae: 635.1492\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.3128 - mae: 639.3128\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.9996 - mae: 643.9996\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.8752 - mae: 640.8752\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 637.3261 - mae: 637.3261\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 638.6672 - mae: 638.6672\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.9938 - mae: 632.9938\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2443 - mae: 634.2443\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.3052 - mae: 631.3052\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.0312 - mae: 638.0312\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.6086 - mae: 634.6086\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.2977 - mae: 636.2977\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.7082 - mae: 638.7082\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.5248 - mae: 643.5248\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.3829 - mae: 631.3829\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 635.7768 - mae: 635.7768\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.0088 - mae: 636.0088\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6569 - mae: 635.6569\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.3160 - mae: 631.3160\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 636.1817 - mae: 636.1817\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.3116 - mae: 633.3116\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.5648 - mae: 632.5648\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 628.3497 - mae: 628.3497\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.6868 - mae: 633.6868\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 631.3640 - mae: 631.3640\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.7183 - mae: 635.7183\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 631.1249 - mae: 631.1249\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 630.5370 - mae: 630.5370\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 628.3683 - mae: 628.3683\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.4788 - mae: 631.4788\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.5245 - mae: 629.5245\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 637.0007 - mae: 637.0007\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 627.4734 - mae: 627.4734\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 625.3552 - mae: 625.3552\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 625.0068 - mae: 625.0068\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627.5236 - mae: 627.5236\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 619.8853 - mae: 619.8853\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 622.7437 - mae: 622.7437\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 618.0673 - mae: 618.0673\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 626.7084 - mae: 626.7084\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 621.1433 - mae: 621.1433\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 617.0981 - mae: 617.0981\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.1922 - mae: 635.1922\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 626.7324 - mae: 626.7324\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 619.1608 - mae: 619.1608\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 622.5132 - mae: 622.5132\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 623.6522 - mae: 623.6522\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 621.9277 - mae: 621.9277\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 617.7552 - mae: 617.7552\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 623.1331 - mae: 623.1331\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 617.1721 - mae: 617.1721\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 607.8148 - mae: 607.8148\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 620.7809 - mae: 620.7809\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 610.4308 - mae: 610.4308\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 622.2287 - mae: 622.2287\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 616.6683 - mae: 616.6683\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 617.1983 - mae: 617.1983\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 612.2373 - mae: 612.2373\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 612.9666 - mae: 612.9666\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 615.8221 - mae: 615.8221\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 612.6548 - mae: 612.6548\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 618.6780 - mae: 618.6780\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 610.8915 - mae: 610.8915\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 610.8771 - mae: 610.8771\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 610.6121 - mae: 610.6121\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 612.3015 - mae: 612.3015\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 610.6351 - mae: 610.6351\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 613.9325 - mae: 613.9325\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 606.6946 - mae: 606.6946\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 612.8958 - mae: 612.8958\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 608.1764 - mae: 608.1764\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 756.9943 - mae: 756.9943\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 647.1600 - mae: 647.1600\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 648.8925 - mae: 648.8925\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 649.3437 - mae: 649.3437\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8640 - mae: 643.8640\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 647.2538 - mae: 647.2538\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.5744 - mae: 642.5744\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.2700 - mae: 640.2700\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.4846 - mae: 637.4846\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.6227 - mae: 644.6227\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 638.0407 - mae: 638.0407\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.3640 - mae: 644.3640\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 642.0118 - mae: 642.0118\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 646.4662 - mae: 646.4662\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.9761 - mae: 640.9761\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 643.8411 - mae: 643.8411\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.3530 - mae: 641.3530\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 643.4515 - mae: 643.4515\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.0532 - mae: 645.0532\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 644.9801 - mae: 644.9801\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 642.1814 - mae: 642.1814\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4507 - mae: 643.4507\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.2689 - mae: 641.2689\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.5096 - mae: 640.5096\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 640.4677 - mae: 640.4677\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 650.2515 - mae: 650.2515\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 644.7760 - mae: 644.7760\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.1988 - mae: 637.1988\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9224 - mae: 637.9224\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.5316 - mae: 645.5316\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 643.6304 - mae: 643.6304\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.3950 - mae: 633.3950\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.6511 - mae: 637.6511\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.0148 - mae: 641.0148\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 633.6188 - mae: 633.6188\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 643.4500 - mae: 643.4500\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 639.5399 - mae: 639.5399\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.3973 - mae: 647.3973\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.4125 - mae: 641.4125\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 631.0147 - mae: 631.0147\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.9047 - mae: 639.9047\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 643.6685 - mae: 643.6685\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.0858 - mae: 636.0858\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2574 - mae: 634.2574\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.0019 - mae: 635.0019\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 647.2062 - mae: 647.2062\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 634.3765 - mae: 634.3765\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.5908 - mae: 640.5908\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 637.2169 - mae: 637.2169\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.8157 - mae: 635.8157\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 627.8674 - mae: 627.8674\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.1544 - mae: 636.1544\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.7263 - mae: 629.7263\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.9886 - mae: 635.9886\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.8840 - mae: 636.8840\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 632.2650 - mae: 632.2650\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 632.9286 - mae: 632.9286\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.0405 - mae: 632.0405\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.8326 - mae: 633.8326\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 625.0170 - mae: 625.0170\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 629.3998 - mae: 629.3998\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 637.7024 - mae: 637.7024\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 628.0705 - mae: 628.0705\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627.3462 - mae: 627.3462\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 626.6965 - mae: 626.6965\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 620.9900 - mae: 620.9900\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 627.5919 - mae: 627.5919\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 630.8236 - mae: 630.8236\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 624.0255 - mae: 624.0255\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 624.3391 - mae: 624.3391\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 624.1898 - mae: 624.1898\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 615.4630 - mae: 615.4630\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 623.4836 - mae: 623.4836\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 619.5297 - mae: 619.5297\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 621.8777 - mae: 621.8777\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 623.5395 - mae: 623.5395\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 618.3169 - mae: 618.3169\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 627.2745 - mae: 627.2745\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 622.4529 - mae: 622.4529\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 617.3788 - mae: 617.3788\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 619.7596 - mae: 619.7596\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 614.3893 - mae: 614.3893\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 617.2493 - mae: 617.2493\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 624.4726 - mae: 624.4726\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 608.4847 - mae: 608.4847\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 614.4432 - mae: 614.4432\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 621.4159 - mae: 621.4159\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 615.4570 - mae: 615.4570\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 617.1254 - mae: 617.1254\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 615.0344 - mae: 615.0344\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 617.4407 - mae: 617.4407\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 610.5278 - mae: 610.5278\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 610.7324 - mae: 610.7324\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 611.2991 - mae: 611.2991\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 609.1262 - mae: 609.1262\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 607.8765 - mae: 607.8765\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 615.3784 - mae: 615.3784\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 604.6352 - mae: 604.6352\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 613.0989 - mae: 613.0989\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 611.0561 - mae: 611.0561\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 760.4976 - mae: 760.4976\n",
            "Epoch 2/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 649.3705 - mae: 649.3705\n",
            "Epoch 3/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 652.0261 - mae: 652.0261\n",
            "Epoch 4/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 646.1899 - mae: 646.1899\n",
            "Epoch 5/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 646.6618 - mae: 646.6618\n",
            "Epoch 6/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.1295 - mae: 641.1295\n",
            "Epoch 7/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 647.1824 - mae: 647.1824\n",
            "Epoch 8/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 654.9268 - mae: 654.9268\n",
            "Epoch 9/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.9814 - mae: 636.9814\n",
            "Epoch 10/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.6683 - mae: 641.6683\n",
            "Epoch 11/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.7036 - mae: 641.7036\n",
            "Epoch 12/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.0684 - mae: 644.0684\n",
            "Epoch 13/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.9948 - mae: 645.9948\n",
            "Epoch 14/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9496 - mae: 638.9496\n",
            "Epoch 15/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.6283 - mae: 637.6283\n",
            "Epoch 16/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.5674 - mae: 636.5674\n",
            "Epoch 17/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.4379 - mae: 638.4379\n",
            "Epoch 18/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 641.0302 - mae: 641.0302\n",
            "Epoch 19/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.6760 - mae: 642.6760\n",
            "Epoch 20/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 644.5085 - mae: 644.5085\n",
            "Epoch 21/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 640.7384 - mae: 640.7384\n",
            "Epoch 22/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.2420 - mae: 640.2420\n",
            "Epoch 23/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 643.4514 - mae: 643.4514\n",
            "Epoch 24/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.2093 - mae: 634.2093\n",
            "Epoch 25/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.1196 - mae: 640.1196\n",
            "Epoch 26/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.3413 - mae: 642.3413\n",
            "Epoch 27/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.7877 - mae: 641.7877\n",
            "Epoch 28/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.7861 - mae: 633.7861\n",
            "Epoch 29/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.0137 - mae: 640.0137\n",
            "Epoch 30/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.3883 - mae: 639.3883\n",
            "Epoch 31/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.2214 - mae: 645.2214\n",
            "Epoch 32/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.2383 - mae: 638.2383\n",
            "Epoch 33/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 645.4438 - mae: 645.4438\n",
            "Epoch 34/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 639.3557 - mae: 639.3557\n",
            "Epoch 35/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9018 - mae: 638.9018\n",
            "Epoch 36/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.6354 - mae: 639.6354\n",
            "Epoch 37/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9881 - mae: 638.9881\n",
            "Epoch 38/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 633.4250 - mae: 633.4250\n",
            "Epoch 39/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.4899 - mae: 644.4899\n",
            "Epoch 40/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.2932 - mae: 632.2932\n",
            "Epoch 41/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.8159 - mae: 636.8159\n",
            "Epoch 42/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 642.9337 - mae: 642.9337\n",
            "Epoch 43/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 641.6441 - mae: 641.6441\n",
            "Epoch 44/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 635.9066 - mae: 635.9066\n",
            "Epoch 45/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 640.3643 - mae: 640.3643\n",
            "Epoch 46/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.8143 - mae: 638.8143\n",
            "Epoch 47/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 637.9202 - mae: 637.9202\n",
            "Epoch 48/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.1879 - mae: 641.1879\n",
            "Epoch 49/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.6099 - mae: 636.6099\n",
            "Epoch 50/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 634.4292 - mae: 634.4292\n",
            "Epoch 51/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.6808 - mae: 636.6808\n",
            "Epoch 52/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.3101 - mae: 637.3101\n",
            "Epoch 53/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.1959 - mae: 634.1959\n",
            "Epoch 54/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 632.0008 - mae: 632.0008\n",
            "Epoch 55/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 634.9980 - mae: 634.9980\n",
            "Epoch 56/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 631.1249 - mae: 631.1249\n",
            "Epoch 57/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 632.8460 - mae: 632.8460\n",
            "Epoch 58/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 636.3456 - mae: 636.3456\n",
            "Epoch 59/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 629.0101 - mae: 629.0101\n",
            "Epoch 60/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 629.3266 - mae: 629.3266\n",
            "Epoch 61/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 635.6840 - mae: 635.6840\n",
            "Epoch 62/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 629.4114 - mae: 629.4114\n",
            "Epoch 63/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.6241 - mae: 631.6241\n",
            "Epoch 64/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 633.3367 - mae: 633.3367\n",
            "Epoch 65/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 638.9086 - mae: 638.9086\n",
            "Epoch 66/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 625.5008 - mae: 625.5008\n",
            "Epoch 67/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 627.6076 - mae: 627.6076\n",
            "Epoch 68/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 627.3271 - mae: 627.3271\n",
            "Epoch 69/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 631.7736 - mae: 631.7736\n",
            "Epoch 70/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 636.4377 - mae: 636.4377\n",
            "Epoch 71/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 629.5676 - mae: 629.5676\n",
            "Epoch 72/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627.9094 - mae: 627.9094\n",
            "Epoch 73/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 625.8936 - mae: 625.8936\n",
            "Epoch 74/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 632.1838 - mae: 632.1838\n",
            "Epoch 75/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 634.2455 - mae: 634.2455\n",
            "Epoch 76/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 627.5515 - mae: 627.5515\n",
            "Epoch 77/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 629.0244 - mae: 629.0244\n",
            "Epoch 78/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 627.5162 - mae: 627.5162\n",
            "Epoch 79/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 629.1789 - mae: 629.1789\n",
            "Epoch 80/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 619.7150 - mae: 619.7150\n",
            "Epoch 81/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 628.7681 - mae: 628.7681\n",
            "Epoch 82/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 623.9731 - mae: 623.9731\n",
            "Epoch 83/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 616.3765 - mae: 616.3765\n",
            "Epoch 84/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 621.1322 - mae: 621.1322\n",
            "Epoch 85/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 622.0267 - mae: 622.0267\n",
            "Epoch 86/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 626.5485 - mae: 626.5485\n",
            "Epoch 87/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 615.3608 - mae: 615.3608\n",
            "Epoch 88/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 627.5146 - mae: 627.5146\n",
            "Epoch 89/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 626.8704 - mae: 626.8704\n",
            "Epoch 90/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 619.5955 - mae: 619.5955\n",
            "Epoch 91/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 620.3304 - mae: 620.3304\n",
            "Epoch 92/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 620.1895 - mae: 620.1895\n",
            "Epoch 93/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 615.5026 - mae: 615.5026\n",
            "Epoch 94/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 615.7223 - mae: 615.7223\n",
            "Epoch 95/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 617.4436 - mae: 617.4436\n",
            "Epoch 96/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 615.9570 - mae: 615.9570\n",
            "Epoch 97/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 620.5759 - mae: 620.5759\n",
            "Epoch 98/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 609.0848 - mae: 609.0848\n",
            "Epoch 99/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 607.7148 - mae: 607.7148\n",
            "Epoch 100/100\n",
            "\u001b[1m834/834\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 607.9942 - mae: 607.9942\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 723.4875 - mae: 723.4875\n",
            "Epoch 2/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 648.0833 - mae: 648.0833\n",
            "Epoch 3/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 646.8074 - mae: 646.8074\n",
            "Epoch 4/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 644.6545 - mae: 644.6545\n",
            "Epoch 5/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 641.9765 - mae: 641.9765\n",
            "Epoch 6/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 642.9158 - mae: 642.9158\n",
            "Epoch 7/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8492 - mae: 639.8492\n",
            "Epoch 8/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 643.1406 - mae: 643.1406\n",
            "Epoch 9/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 646.0588 - mae: 646.0588\n",
            "Epoch 10/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 638.1224 - mae: 638.1224\n",
            "Epoch 11/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 641.5506 - mae: 641.5506\n",
            "Epoch 12/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 641.7559 - mae: 641.7559\n",
            "Epoch 13/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 637.0638 - mae: 637.0638\n",
            "Epoch 14/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.8479 - mae: 636.8479\n",
            "Epoch 15/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.9595 - mae: 638.9595\n",
            "Epoch 16/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 645.2180 - mae: 645.2180\n",
            "Epoch 17/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 641.9108 - mae: 641.9108\n",
            "Epoch 18/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 642.5260 - mae: 642.5260\n",
            "Epoch 19/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 639.8414 - mae: 639.8414\n",
            "Epoch 20/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 644.7981 - mae: 644.7981\n",
            "Epoch 21/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 644.4342 - mae: 644.4342\n",
            "Epoch 22/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 645.0855 - mae: 645.0855\n",
            "Epoch 23/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 642.0739 - mae: 642.0739\n",
            "Epoch 24/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 645.2739 - mae: 645.2739\n",
            "Epoch 25/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 642.6835 - mae: 642.6835\n",
            "Epoch 26/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.7684 - mae: 637.7684\n",
            "Epoch 27/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 639.4676 - mae: 639.4676\n",
            "Epoch 28/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 638.2368 - mae: 638.2368\n",
            "Epoch 29/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 639.2238 - mae: 639.2238\n",
            "Epoch 30/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 638.2188 - mae: 638.2188\n",
            "Epoch 31/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 637.9780 - mae: 637.9780\n",
            "Epoch 32/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 638.7588 - mae: 638.7588\n",
            "Epoch 33/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 636.4496 - mae: 636.4496\n",
            "Epoch 34/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 638.2493 - mae: 638.2493\n",
            "Epoch 35/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 646.0262 - mae: 646.0262\n",
            "Epoch 36/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 644.3559 - mae: 644.3559\n",
            "Epoch 37/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 640.0079 - mae: 640.0079\n",
            "Epoch 38/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 637.7075 - mae: 637.7075\n",
            "Epoch 39/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 639.9374 - mae: 639.9374\n",
            "Epoch 40/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 639.0889 - mae: 639.0889\n",
            "Epoch 41/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 636.2708 - mae: 636.2708\n",
            "Epoch 42/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 633.2633 - mae: 633.2633\n",
            "Epoch 43/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 640.0086 - mae: 640.0086\n",
            "Epoch 44/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 638.0780 - mae: 638.0780\n",
            "Epoch 45/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 640.0602 - mae: 640.0602\n",
            "Epoch 46/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 635.3254 - mae: 635.3254\n",
            "Epoch 47/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 638.0887 - mae: 638.0887\n",
            "Epoch 48/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 635.0068 - mae: 635.0068\n",
            "Epoch 49/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 627.4378 - mae: 627.4378\n",
            "Epoch 50/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 632.1192 - mae: 632.1192\n",
            "Best Score: -0.048843236468861205\n",
            "Best Params: {'epochs': 50, 'model__Layers': 3, 'model__neuron': 128}\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==1.2.2 # Downgrade scikit-learn to 1.2.2\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n",
        "\n",
        "data=pd.read_csv('Dataset_After_PCA.csv')\n",
        "import numpy as np\n",
        "\n",
        "X=data.iloc[:, :-1]\n",
        "y=data['Premium Amount']\n",
        "\n",
        "## Split the data in training and tetsing sets\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "# Define the model creation function\n",
        "def create_model(neuron=32, Layers=1):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(Layers - 1):\n",
        "        model.add(Dense(neuron, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Wrap with KerasRegressor\n",
        "# Remove model__neuron and model__layers from KerasRegressor initialization\n",
        "model_hptunned = KerasRegressor(build_fn=create_model, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "# Parameter Grid\n",
        "# Update param_grid keys to match function arguments\n",
        "param_grid = {\n",
        "    \"model__neuron\": [16,32,64,128],\n",
        "    \"model__Layers\": [1, 2,3],\n",
        "    \"epochs\": [20,50,100]\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "grid = GridSearchCV(estimator=model_hptunned, param_grid=param_grid, cv=3, verbose=1)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Best Results\n",
        "print(f\"Best Score: {grid_result.best_score_}\")\n",
        "print(f\"Best Params: {grid_result.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "754cX0IEsA7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
